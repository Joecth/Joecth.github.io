---
layout: post
categories: BigData_java
tag: []
date: 2021-1-8
---





#### 缺條腿方案

只有動態的接收者，沒有動態的處理者

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gom2jms4yvj21440aqwih.jpg" alt="image-20210316213105971" style="zoom:67%;" />



#### 完整的流！

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1gom2j1rh7lj21540aqgpc.jpg" alt="image-20210316213032834" style="zoom:50%;" />

透過structure-streaming可以實時處理，還可以被下個kfk topic收集，可以透過kfk console看接受到了哪些新的data，或是下游連的另個收集方讀取著。



- input 就是一串data的組合
- Schema相對於kfk consumer會多一點
  - key
  - Value
  - topic 會標明這條msg是從哪個topic來的
  - partition：當接收到data時，會有個recorded metadata, 之前有個callback去讀，知道當前的msg在哪個topic的哪個partition的哪個offset。
    - 但這邊不用再去解析，這邊直接給
  - offset　↑
  - timestamp: 到我kfk的時間；而eventtime還是得去msg的編碼裡面找
  - timestampType: Integer；Epoch time, 是大多數情況，10位就是in secs; 13位就是mili-seconds
-  key是：
  - Default不設為None時就是round-robin
  - 就是往kfk發數據時，有兩個field, 一個就是key，可以按指定hashvalue 方式發去指定的kfk cluster上；key就是個record的key；只要是一樣的key，就是去到相同機器
- value是: 就是真的內容
  - 實際pull到的那些msg
  - 如整個 Json的tweet，就是整個msg！
  - 需要通過Spark datatype 進行解碼；序列化　（kfk的自帶API會自己帶，但現在得自己手動）
    - <img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gomw6v6anhj30ae00r0sz.jpg" alt="image-20210317143646216" style="zoom: 67%;" />
    - 轉化類型當中，做了反序列化操作
    - 要是直接讀進來print的row，會有topic, partition, 但key, value都是二進制encoding
  - 解碼也不夠，因為是個json obj，個人的id, retweet這類的
    - 我還需要extract json，去轉成了json obj再操作
  - 每次對應的obj可能是多行row... 不如直接用spark方法直接parse, 可進行結構化定義
    - <img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gomwdvlo67j30kw062wh3.jpg" alt="image-20210317144332554" style="zoom:50%;" />
    - 可以對增量操作而不是每條額外的操作
    - 我的input已經是個純結構化的了，json就是結構了，我不需要再把一整行再轉化出來，我只需要去extract當中需要的三個column，剩下的就可以在讀取並轉化的過程中扔了！讓整個obj也變得非常輕便
    - 要是json是好幾層，也完全是可以的；structure type就得要多define幾層
- 相同點 (kfk consumer VS structure-streaming consumer)
  - 之前的consumer app會有auto offset reset <> startingOffset (會去拉最早的data而不是把最早的給忽略了)
  - Topic <> subscribe; 我想要subscribe的　是哪個topic
  - Bootstrap.servers <> kafka.bootstrap.server
  - consumer.poll <> maxOffsetPerTrigger 就是每次的micro-batch我要拉幾條，通過這樣的設定，就可以明顯設這次的拉出幾條
- 不同點
  - ss不支持group_id；我要是自己控制group_id還要知道哪幾台機器在pull什麼data，還要控制consumer app的個數 <= partition 個數，不然就浪費；所以ss就自己內部管理；SS會根據job數去管理、平衡。
    - 官網doc上會說我也是可以硬 overwrite group_id 
      - １但大家都很不推薦自己define group_id
      - ２因為沒有如kfk那套所對應的key的serializer & deserializer, SS用的是自己的一套
      - ３SS會忽略kfk的auto commit，這類的async當時用kfk consumer時那套得自己處理；它有自己的commit log，SS會在executor, driver紀錄自己處理到了哪個kfk partition的第幾個offset。所以SS就直接忽略kfk的auto commit。省掉了auto commit和我們要實現那auto commit的難處





## Structure-streaming's output sink

TODO: 要把kfk API consumer改成structure-streaming consumer



- 之前在 kfk裡的，而ss包了的：
  - processID:
    - Itempotency
    - only commit once, if jbo failure, 要確認要做的不在 processID裡
  - ctrl + C時
    - 該處理一堆在consumer cache裡的，elegantly 善後
  - 管理 commit
    - ss 處理完才commit
    - 由於 spark 本質就是只處理commit 完的 msg, 所以仍是依賴spark自己的 offset, 決定當有 Ctrl + C時怎麼commit msg，而不是當被強迫退出了，還是去commit已pull下來的msg
- poll也被ss的getStreamingData取代了
- curID也是for idempotency的



- producer打印出來，到json online parser看下，才知道data什麼樣，我在ss裡define才不會define錯

- Nested field:

  <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38ab3ff1pj20fd03z3yk.jpg" alt="image-20210318163250985" style="zoom: 67%;" />

- input 有個增量，是個已被CAST過的value, input有個col裡面是 json obj：

  <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38ab5sch7j20mn04w751.jpg" alt="image-20210318163832389" style="zoom:67%;" />

- as data　要是沒有的話↓

  ![image-20210318163953648](https://tva1.sinaimg.cn/large/008eGmZEly1goo5dat8ugj30gl02ct9i.jpg)





<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38ab8myhwj20pi01kjrp.jpg" alt="image-20210318175941292" style="zoom:67%;" />



- run producer

![image-20210318181047094](https://tva1.sinaimg.cn/large/008eGmZEly1goo7zussqmj30q202uwgd.jpg)



- Flatten into data frame, 所以就不需要 StringIntoJsonObj這個function
  - 就得到了 transformedTweet, 而且會發現也不需要 ExtractObjIntoDataframe了！
  - 刪除沒有ID的Tweet, 並把當前的Tweet簡單地clean up!
- withColumn: lit
  - 填一col, 如當前的cur time stamp
    - <img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38abbxe0kj20wi07w0tg.jpg" alt="image-20210328235740991" style="zoom:50%;" />
  - repalce
    - <img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gp02fx9333j315q0380t7.jpg" alt="image-20210329000527131" style="zoom:50%;" />





- Nested Schema	<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38abctu5ej20na0863yu.jpg" alt="image-20210329001059779" style="zoom:67%;" />



Hank

1. mySQL --> aqoformat(?!) --> HDFS
2. mySQL --> Enterprise Warehouse (Hive)
3. Platform engineer; Infra Engineer



- DS: query 已經生成的Data, which is generated by platform eng. or Infra eng.，
- 生成後存在HDFS/DB裡；Stat 建模

說是Best Practice(?!)