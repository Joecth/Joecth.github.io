<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">401</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">70</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Awaken Desparado</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2022/06/01/ParallelProg/HighPerf%20UTA%201/">ParallelProg/HighPerf UTA 1</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-06-01</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/HighPerf/">HighPerf</a></span><div class="content"><p><strong>HW requirements</strong></p>
<ul>
<li>Intel architectures: Haswell, Broadwell, Skylake, Kaby Lake, Coffee Lake.</li>
<li>AMD architectures: Ryzen/Epyc</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/content/drive/MyDrive/mySIMD<span class="comment"># gcc -march=native -Q --help=target|grep march</span></span><br><span class="line">  -march=                               haswell</span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">content/drive/MyDrive/mySIMD<span class="comment"># more /proc/cpuinfo</span></span><br><span class="line">processor       : 0</span><br><span class="line">vendor_id       : GenuineIntel</span><br><span class="line">cpu family      : 6</span><br><span class="line">model           : 63</span><br><span class="line">model name      : Intel(R) Xeon(R) CPU @ 2.30GHz</span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/content/drive/MyDrive/mySIMD/repos/LAFF-On-PfHP/Assignments/Week0/C<span class="comment"># make HelloWorld </span></span><br><span class="line">gcc driver.o FLA_Clock.o MaxAbsDiff.o RandomMatrix.o /root/blis/lib/libblis.a -o driver.x -lpthread -m64 -lm -fopenmp </span><br><span class="line"><span class="built_in">echo</span> </span><br><span class="line"></span><br><span class="line">./driver.x</span><br><span class="line">Hello World</span><br><span class="line">Hello World</span><br></pre></td></tr></table></figure>



<p>Understand how alg and architectures interact</p>
<p>Using e.g. of matrix-matrix multiply </p>
<h3 id="GEMM-GEneral-Matrix-Multiplication"><a href="#GEMM-GEneral-Matrix-Multiplication" class="headerlink" title="GEMM - GEneral Matrix Multiplication"></a>GEMM - GEneral Matrix Multiplication</h3><p>$$<br>\begin{equation<em>}<br>A =<br>\left(\begin{array}{cccc}<br>\alpha_{0,0} &amp; \alpha_{0,1} &amp; \cdots &amp; \alpha_{0,k-1} \<br>\alpha_{1,0} &amp; \alpha_{1,1} &amp; \cdots &amp; \alpha_{1,k-1} \<br>\vdots &amp; \vdots &amp; &amp; \vdots \<br>\alpha_{m-1,0} &amp; \alpha_{m-1,1} &amp; \cdots &amp; \alpha_{m-1,k-1}<br>\end{array}\right),<br>B =<br>\left(\begin{array}{cccc}<br>\beta_{0,0} &amp; \beta_{0,1} &amp; \cdots &amp; \beta_{0,n-1} \<br>\beta_{1,0} &amp; \beta_{1,1} &amp; \cdots &amp; \beta_{1,n-1} \<br>\vdots &amp; \vdots &amp; &amp; \vdots \<br>\beta_{k-1,0} &amp; \beta_{k-1,1} &amp; \cdots &amp; \beta_{k-1,n-1}<br>\end{array}\right)<br>\end{equation</em>}<br>$$</p>
<p>$$<br>\begin{equation<em>}<br>C =<br>\left(\begin{array}{cccc}<br>\gamma_{0,0} &amp; \gamma_{0,1} &amp; \cdots &amp; \gamma_{0,n-1} \<br>\gamma_{1,0} &amp; \gamma_{1,1} &amp; \cdots &amp; \gamma_{1,n-1} \<br>\vdots &amp; \vdots &amp; &amp; \vdots \<br>\gamma_{m-1,0} &amp; \gamma_{m-1,1} &amp; \cdots &amp; \gamma_{m-1,n-1}<br>\end{array}\right).<br>\end{equation</em>}<br>$$</p>
<p>$C := A B + C \text{.}$</p>
<p>$$<br>\begin{equation}<br>\gamma_{i,j} :=  \sum_{p=0}^{k-1} \alpha_{i,p} \beta_{p,j} + \gamma_{i,j}\label{week1-eqn-gamma}\tag{1.1.1}<br>\end{equation}<br>$$</p>
<p>$$<br>\begin{equation*}<br>\begin{array}{l}<br>{\bf for~} i := 0, \ldots , m-1  \</p>
<p><del>~ {\bf for</del>} j := 0, \ldots , n-1  \</p>
<p><del>~ {\bf for</del>} p := 0, \ldots , k-1  \</p>
<pre><code class="\gamma_{i,j}">~~~~~~{\bf end} \\
~~~{\bf end} \\
{\bf end}
\end{array}
\end{equation*}
$$

### Pseudo Code to C code

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> alpha( i,j ) A[ (j)*ldA + i ]   <span class="comment">// map alpha( i,j ) to array A </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> beta( i,j )  B[ (j)*ldB + i ]   <span class="comment">// map beta( i,j )  to array B</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> gamma( i,j ) C[ (j)*ldC + i ]   <span class="comment">// map gamma( i,j ) to array C</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">MyGemm</span><span class="params">( <span class="keyword">int</span> m, <span class="keyword">int</span> n, <span class="keyword">int</span> k, <span class="keyword">double</span> *A, <span class="keyword">int</span> ldA,</span></span></span><br><span class="line"><span class="function"><span class="params">	     <span class="keyword">double</span> *B, <span class="keyword">int</span> ldB, <span class="keyword">double</span> *C, <span class="keyword">int</span> ldC )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span> ( <span class="keyword">int</span> i=<span class="number">0</span>; i&lt;m; i++ )</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> j=<span class="number">0</span>; j&lt;n; j++ )</span><br><span class="line">      <span class="keyword">for</span> ( <span class="keyword">int</span> p=<span class="number">0</span>; p&lt;k; p++ )</span><br><span class="line">        gamma( i,j ) += alpha( i,p ) * beta( p,j );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



Gemm &quot;Gemm&quot; is a commonly used acronym that stands for &quot;Ge&quot;neral &quot;m&quot;atrix &quot;m&quot;ultiplication.

The term &quot;driver&quot; is typically used for a main program that exercises (tests and/or times) functionality implemented in a routine. In our case, the driver tests a range of problem sizes by creating random matrices C , A , and B . 



execution time as a function of the problem size!



### GFLOPS

![image-20230608013934605](https://p.ipic.vip/us5l1t.png)



&lt;img src=&quot;https://p.ipic.vip/pgaej9.png&quot; alt=&quot;image-20230608014505513&quot; style=&quot;zoom:67%;&quot; /&gt;

![image-20230608014348331](https://p.ipic.vip/tcasfw.png)





Mapping Matrices to memory

- Row major order (X)
- Col major order (V)
  - B.C Computational science used to used the Fortran programming language to program, and the Fortan programming language chose to store matrices by `columns major order`
  - ![image-20230608111535626](https://p.ipic.vip/qj1dak.png)&lt;img src=&quot;https://p.ipic.vip/pzjxnb.png&quot; alt=&quot;image-20230608111832859&quot; style=&quot;zoom:67%;&quot; /&gt;



The leading dimension

- ![5x4 matrix](https://p.ipic.vip/4p52nk.png)
  - The leading dimension of the boxed submatrix is : 5





 A convention regarding the letter used for the loop index

- why do the two implementations with better performance do better?
  1. They access matrices by columns in the inner loop.
  2. We store matrices in column-major order.
  3. Accessing data contiguously usually improves performance.





Nototion
$$
A =
          \left( \begin{array}{r r r}
          -2 &amp; -3 &amp; -1 \\
          2 &amp; 0 &amp; 1 \\
          3 &amp; -2 &amp; 2 \\
          \end{array}
          \right).
$$


- $$\alpha_{1,2} = 1$$

- $$a_{0} =       \left( \begin{array}{r r r}       -2 \\       2 \\       3        \end{array}       \right)$$

- $$\widetilde a_{2}^T       =       \left( \begin{array}{r r r}       3 &amp; -2 &amp; 2        \end{array}       \right)$$





Dot Product
$$
\begin{array}{l c r}
          {\tt A[0]} &amp; \longrightarrow &amp; -1 \\
          &amp;&amp;0 \\
          &amp;&amp; 2 \\
          &amp;&amp; 3 \\
          &amp;&amp; -1 \\
          &amp;&amp; 1 \\
          &amp;&amp; 4 \\
          &amp;&amp; -1 \\
          &amp;&amp; 3 \\
          &amp;&amp; 5 
          \end{array}
$$

- Dots( 3, &amp;A[1], 4, &amp;A[3], 1, &amp;gamma ) = $$1 + \left( \begin{array}{r}       0 \\       1 \\       5        \end{array} \right)^T       \left( \begin{array}{r}       3 \\       -1 \\       1        \end{array} \right)       =       1 + (0) \times (3) + (1) \times (-1) + (5) \times (1)       = 5.$$

&gt; In particular, the stride when accessing a row of a matrix is ldA when the matrix is stored in column-major order with leading dimension ldA,

- \#define alpha(i,j) A[ (j)*ldA + (i)] to address the matrix in a more natural way





Matrix-vector multiplication via dot-product

![image-20230608152820750](https://p.ipic.vip/mv01r4.png)

&lt;img src=&quot;https://p.ipic.vip/1ylxqs.png&quot; alt=&quot;image-20230608154753003&quot; style=&quot;zoom:80%;&quot; /&gt;





Axpy

- alpha times x plus y
  - where alpha times x is a &quot;broadcast&quot; operation





Matrix-vector multiplication via axpy operations

## ![image-20230608155913443](https://p.ipic.vip/jrsjlx.png)

General form
$$
\begin{equation*}
\begin{array}{rcl}
y :=
\left( \begin{array}{c | c | c | c}
a_0  a_1  \cdots  a_{n-1} 
\end{array} \right)
\left( \begin{array}{c}
\chi_0 \\ \hline
\chi_1 \\ \hline
\vdots \\ \hline
\chi_{n-1}
\end{array}
\right) + y \\
=
\chi_0 a_0 + \chi_1 a_1 + \cdots + \chi_{n-1} a_{n-1} + y.
\end{array}
\end{equation*}
$$
![image-20230608161328342](https://p.ipic.vip/z8nmcl.png)



Gemm in terms of Gemv

![image-20230608161910223](https://p.ipic.vip/8r9a9l.png)



![image-20230608162233030](https://p.ipic.vip/t3qcip.png)





## Layering Matrix-Matrix Multiplication

rank-1 update by columns

Matrix-matrix multiplication via rank-1 updates

&lt;img src=&quot;https://p.ipic.vip/09jkbw.png&quot; alt=&quot;img&quot; style=&quot;zoom: 50%;&quot; /&gt;

- notice that here we&apos;re actually adding to a matrix. And it&apos;s called rank-1 update because an **`outer product` has a rank of at most 1**
  - e,g, 
    - A = [1, 2, 3] B = [4, 5, 6], A ⊗ B = [ 4, 5, 6 ] [ 8, 10, 12 ] [12, 15, 18 ], and the 1st row can represent the remaining 2 rows, so the 2nd and 3rd are not linear independent to 1st row, so rank is one!







### Row-times-matrix multiplications







ref: 

[1] https://www.cs.utexas.edu/users/flame/laff/pfhp/week0-what-should-we-know.html</code></pre>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2022/05/31/DevOps-Clouds/GCE/">DevOps-Clouds/GCE</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-05-31</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/AWS-Hhigh-Traffic/">AWS-Hhigh-Traffic</a></span><div class="content"><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2t0isr14wj217u0u078o.jpg" alt="image-20220601202443727" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2t8n0bqu9j216d0u0q6o.jpg" alt="image-20220602010534184" style="zoom: 67%;" />







<h2 id="Instances-Info"><a href="#Instances-Info" class="headerlink" title="Instances Info"></a>Instances Info</h2><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2ybyez808j20w00u0wkm.jpg" alt="image-20220606104809298" style="zoom:67%;" />

<p><a href="https://gcpinstances.doit-intl.com/" target="_blank" rel="noopener">https://gcpinstances.doit-intl.com/</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2022/05/30/Concurrency/2022-05-30%20High%20Traffic%20&amp;%20High%20Concurrency/">Concurrency/2022-05-30 High Traffic &amp; High Concurrency</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-05-30</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Concurrency/">Concurrency</a></span><div class="content"><h1 id="High-Concurrency"><a href="#High-Concurrency" class="headerlink" title="High Concurrency"></a>High Concurrency</h1><p><img src="https://p.ipic.vip/oeedft.png" alt="image-20230530103719241"></p>
<h2 id="High-Concurrency-1"><a href="#High-Concurrency-1" class="headerlink" title="High Concurrency"></a>High Concurrency</h2><ul>
<li>System design faces the ultimate challenge of handling high-concurrency traffic.</li>
<li>System is divided into four layers, with the top layer experiencing the highest pressure and the bottom layer having the weakest capacity.</li>
<li>System architecture should be hierarchical, with flow control implemented at each level.</li>
</ul>
<h3 id="Service-Gateway-Layer"><a href="#Service-Gateway-Layer" class="headerlink" title="Service Gateway Layer:"></a>Service Gateway Layer:</h3><ul>
<li>Acts as the entry point for all user traffic and handles load balancing to distribute the load across multiple physical nodes.</li>
<li>Implements user authentication and rate limiting to filter out invalid traffic.</li>
<li>Includes security measures to protect against DDoS attacks.</li>
</ul>
<h3 id="Business-Layer"><a href="#Business-Layer" class="headerlink" title="Business Layer:"></a>Business Layer:</h3><ul>
<li>Provides various business functionalities to users.</li>
<li>Implements “separation of concerns” or “frontend-backend separation” to improve user interface rendering and user experience through page caching.</li>
<li>Receives user requests and delegates the relevant operations to backend service layer.</li>
<li>Uses asynchronous design and message queues to handle user requests, reducing the pressure on the service layer.</li>
<li>Implements circuit breaker mechanisms and service degradation to prevent system cascading failures.</li>
</ul>
<h3 id="Service-Layer"><a href="#Service-Layer" class="headerlink" title="Service Layer:"></a>Service Layer:</h3><ul>
<li>Handles business operations and database interactions.</li>
<li>Deploys on multiple nodes using cloud-based deployment for horizontal scaling to handle complex business operations.</li>
<li>Utilizes elastic scaling to automatically adjust the number of nodes based on the workload, reducing operational costs.</li>
<li>Implements service degradation by returning fallback data instead of querying the database under high pressure situations.</li>
<li>Uses distributed caching to alleviate pressure on the database.</li>
</ul>
<h3 id="Database-Layer"><a href="#Database-Layer" class="headerlink" title="Database Layer:"></a>Database Layer:</h3><ul>
<li>Implements read-write separation by separating production and query databases for optimized performance.</li>
<li>Implements sharding to distribute the write workload across multiple databases and mitigate disk I/O bottlenecks.</li>
<li>Utilizes NoSQL databases and big data platforms for data analysis and optimization.</li>
</ul>
<p><strong>高併發</strong></p>
<p>在面對億級流盤時，系統設計的每一個環節都是一個終極考驗，必預做到極致，我們通過分層將系統劃分成了四個</p>
<p>層次，然而這時我們發現，上層抗壓能力強，底層抗壓能力弱，形成了一個倒三角的態勢。因此，對於系統整體架</p>
<p>構來說，應當做到系統分層、逐級限流</p>
<p>在這四個層次中，最上層的服務網關，系統壓力是最大的，所有用戶壓力都要經過它。這時，服務網關首先要做的</p>
<p>是負載均衡，將所有壓力均勻地分布到許多物理節點上來共同扛佳壓力。然而，服務網關不能將所有的流量直接轉</p>
<p>發給下游，它常要通過限流，將最終有效的流量轉發給下游。因此，它常要用戶身份鑒權，陽止不合法的用戶流</p>
<p>量；還需要有限流措施，當業務流量超過系統設計能力時，將過載的那部分流量拒絕掉，以保護下游的穩定運行；</p>
<p>還需要有安全防護，保護系統免受DDos等互聯網攻擊。</p>
<p>接著就到了業務層，面向的是為用戶提供的各項業務功能。這個層次要承擔用戶界面繪制，展現UI界面，因此需</p>
<p>要”動靜分離”或”前後端分離〞，通過頁面緩存更加流暢地展現用戶界面，提高用戶體驗。同時，當用戶在界面中進</p>
<p>行各種操作時，由它來接收用戶請求，但不由它完成相關操作，而是調用後台服務層的服務去完成。所以，前端業</p>
<p>務層的抗壓能力是比較強的，而後端服務層的抗壓能力比較弱，因為它們除了完成各種業務操作，還要讀寫數據</p>
<p>庫。因此，業務層通過異步化設計，先受理用戶請求，然後發送給消息隊列。這樣的設計，既可以讓業務層獲得更</p>
<p>大的吞吐量，又可以降低服務層的壓力，讓服務層能從容地完成各項業務，當下游的服務層快扛不住流量壓力而大</p>
<p>量超時的時候，業務層通過熔斷機制及時進行」服務降級」來防止系統雪崩。</p>
<p>下游的服務層，除了要完成各種業務操作以外，還需要讀寫數據庫，因此讀寫數據庫成了它們最大的瓶頸。為了扛</p>
<p>住複雜業務給服務層帶來的系統壓力，服務層通過雲端部署，將業務分散於更多的節點中進行橫向擴容，從而扛街</p>
<p>業務壓力。通過雲平台的彈性可伸縮，當壓力大時自動擴展到更多節點，而當壓力小時自動收縮，就能很好地應對</p>
<p>互聯網壓力的彈性變化，從而降低系統的運營成本。</p>
<p>此外，服務層的最大瓶頸是對數據庫的讀寫。當系統壓力過大、數據庫扛不住時，服務層就會啓動服務降級。查詢</p>
<p>的服務降級，就是通過不查詢數據而返回兜底數據來降低數據庫壓力；寫操作的服務降級，就是不再去寫數據庫，</p>
<p>而是切換為寫Redis內存數據庫加異步寫庫，從而扛住系統壓力。此外，分布式緩存也是服務層降低數據庫壓力的</p>
<p>有效措施之一。</p>
<p>最後一層是抗壓能力最差的數據庫。通過讀寫分離將數據庫分為生產庫與查詢庫，分別予以系統優化；通過橫向、</p>
<p>縱向的數據分庫分散生產庫的寫入壓力，緩解磁盤1/0的瓶頸；通過NoSQL數據庫與大數據平台實現數據分析與查</p>
<p>詢的優化。這些都是解決數據層系統壓力、提升吞吐量的有效措施。</p>
<p>一主多從</p>
<p>表分庫抵抗寫的壓力，TIDB</p>
<p>TDB是一個開源的NewSQL資料庫，可作為mysq的從服務，作橫向分庫分表</p>
<h2 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h2><ul>
<li>System design should be able to tolerate single point failures.</li>
<li>Implement multiple data centers and utilize DNS round-robin for gateway access to ensure availability even if one data center goes down.</li>
<li>Service gateways should achieve high availability through load balancing (e.g. Nginx master-slave synchronization) and distribution across multiple gateways.</li>
<li>Application and service layers should deploy on multiple nodes using Kubernetes for cloud-based deployment.</li>
<li>Failed nodes should be replaced, and unfinished tasks should be transferred to other nodes through failover to maintain high availability.</li>
<li>Data nodes (caches, message queues, databases) should utilize master-slave replication for high availability.</li>
<li></li>
</ul>
<h2 id="High-Reliability"><a href="#High-Reliability" class="headerlink" title="High Reliability"></a>High Reliability</h2><ul>
<li>Ensure non-loss operation of data in high-concurrency systems.</li>
<li>Strengthen design to prevent data loss during automatic master-slave switching moments.</li>
<li>Move towards decentralized architectures to eliminate the distinction between master and slave nodes and enable data replication across multiple nodes.</li>
<li>Increase capacity or allow dynamic resource allocation to improve reliability.</li>
</ul>
<p><strong>高可用</strong></p>
<p>高可用要求，即使在面對高井發時個別節點宕機，整個系統對於用戶來說仍是可用的，用戶的所有請求都將予以逃</p>
<p>理，並最終反饋給用戶。在系統面對高併發時，任何一個節點任何時候都可能出現宕機。因此系統設計應當具備</p>
<p>“單點故障可容忍”的特性，並將該特性體現在系統設計的每一個環節。</p>
<p>首先，網關層在面對互聯網的時候，可能因為網絡故障而造成整個機房不可用。因此，系統建設必須是多機房，並</p>
<p>且通過DNS的輪詢實現多機房的訪問。這樣，即使一個機房出了問題，還有另一個機房可用。接著，服務網關也</p>
<p>要實現高可用，即首先保證負載均街的高可用（如Nginx的主從同步），然後負載到多個服務網關。這樣，即使一</p>
<p>個股務網關不可用，還有其他服務網關，系統依然保持高可用。</p>
<p>然後是應用層與服務層的高可用。通過Kubernetes雲端部香，每個服務都至少部零在兩個以上節點。如果系統運</p>
<p>行過程中一個節點不可用，那麼就在另一個地方再啓動一個節點。失效的那個節點沒有完成的任務，通過故障轉移</p>
<p>交給另一個節點，雖然會增加一點延遲，但任務最終會完成並返回給用戶，系統還是高可用的。</p>
<p>最後是數據節點，包括緩存、消息隊列、數據庫。這些節點的高可用主要是通過主從同步來實現的，當主節點失效</p>
<p>以後就會自動切換到從節點，將從節點升級為主節點，就能保證高可用。</p>
<p><strong>高可靠</strong></p>
<p>這裡的高可靠，特指數據的高可菲運行不丟失，這對於億級高併發系統來說也是非常重要的。在面對高併發壓力</p>
<p>時，個別節點宕機時常發生。但是，節點宕機而自動進行主從切換的瞬間，容易造成數據的丟失。因此，就需要通</p>
<p>過加強設計保證數據的可靠。問題多發生於主從切換，所以未來會越來越多地朝若「去中心化」”的設計發展，即未來</p>
<p>的集群不再有主從之分，或者互為主從，我備份你的數據的同時，你也在備份我的數據，實現數據的多節點複製。</p>
<p>有了這樣的機制，集群中即使某個節點失效，數據也不會丟失，就能更好地保障數據的高可靠運營。</p>
<p>可以多買capacity、或需要時，讓系統自己分配</p>
<h1 id="Second-Kill"><a href="#Second-Kill" class="headerlink" title="Second Kill"></a><strong>Second Kill</strong></h1><p>前端靜態、cache、</p>
<p>讀多寫少時別去db查，因為db的連接資源有限，用cache去擋</p>
<p><strong>cache iussue</strong></p>
<p>在redis放info，但這裡是不完全可靠的，用戶是要傳商品id，在redis裡被查</p>
<p><strong>cache</strong> <strong>擊穿</strong></p>
<p>後來又造成db掛、加鎖</p>
<p><strong>cache**</strong>預熱**</p>
<p><strong>cache**</strong>穿透**</p>
<p>加鎖的處理性能不好呀! 有無更好的解決方案？ –&gt; 布隆過濾器先查商品id看有沒有存在；但redis如果一更新，要跟著更新，這是個新議題</p>
<p><img src="https://p.ipic.vip/nzekgc.png" alt="image-20230530110803915"></p>
<h2 id="Redis分布式锁"><a href="#Redis分布式锁" class="headerlink" title="Redis分布式锁"></a>Redis分布式锁</h2><p>Ref: </p>
<p><a href="https://www.bilibili.com/video/BV1fk4y1p7na/?spm_id_from=333.999.0.0&vd_source=a446d08c42a016c121a1c8007fc3ce42" target="_blank" rel="noopener">亿级流量架构设计-高可用，高可靠_哔哩哔哩_bilibili</a></p>
<p><a href="https://www.bilibili.com/video/BV1dP411w7Wt/?spm_id_from=333.788&vd_source=a446d08c42a016c121a1c8007fc3ce42" target="_blank" rel="noopener">阿里三面：秒杀系统如何设计？竟然败在这题了。。。_哔哩哔哩_bilibili</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2022/05/29/Deeplearning/2022-05-29-AWS%20GPU%20usage/">Deeplearning/2022-05-29-AWS GPU usage</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-05-29</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/DevOps/">DevOps</a></span><div class="content"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">2  sudo apt-get update</span><br><span class="line"> 3  wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda_11.7.0_515.43.04_linux.run	  </span><br><span class="line"> 6  sudo sh cuda_11.7.0_515.43.04_linux.run</span><br><span class="line">11  wget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh</span><br><span class="line">13  sh Miniconda3-py39_4.12.0-Linux-x86_64.sh</span><br><span class="line">16  vi ~/.bashrc	<span class="comment"># LD_LIBRARY_PATH=/usr/local/cuda-11.7/lib64</span></span><br><span class="line">18  <span class="built_in">source</span> ~/.bashrc</span><br><span class="line">19  conda create -n dl37 python=3.7 pip</span><br><span class="line">20  conda activate dl37</span><br><span class="line">21  pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113</span><br><span class="line"><span class="comment"># 可看到 pytorch 2G，比 cuda還要大! 也是相當厲害…</span></span><br><span class="line">22  wget https://zh-v2.d2l.ai/d2l-zh.zip</span><br><span class="line">23  sudo apt-get install unzip</span><br><span class="line">33  pip install -U d2l jupyter</span><br><span class="line">34  jupyter notebook</span><br></pre></td></tr></table></figure>





<h2 id="jupyter-notebook"><a href="#jupyter-notebook" class="headerlink" title="jupyter notebook"></a>jupyter notebook</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -i ~/.ssh/emr-key-A.pem -L8888:localhost:8888 ubuntu@ec2-54-159-193-111.compute-1.amazonaws.com</span><br></pre></td></tr></table></figure>





<h2 id="nvidia-smi"><a href="#nvidia-smi" class="headerlink" title="nvidia-smi"></a>nvidia-smi</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">(base) ubuntu@ip-192-168-81-198:~$ nvidia-smi</span><br><span class="line">Mon May 30 09:58:50 2022</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N/A   32C    P0    27W /  70W |   2751MiB / 15360MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0   N/A  N/A     11902      C   ...nda3/envs/dl37/bin/python     2747MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">(base) ubuntu@ip-192-168-81-198:~$ nvidia-smi</span><br><span class="line">Mon May 30 09:59:31 2022</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N/A   33C    P0    27W /  70W |    335MiB / 15360MiB |      6%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0   N/A  N/A     12017      C   ...nda3/envs/dl37/bin/python      331MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">(base) ubuntu@ip-192-168-81-198:~$ nvidia-smi</span><br><span class="line">Mon May 30 09:59:38 2022</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N/A   37C    P0    79W /  70W |   2749MiB / 15360MiB |     98%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0   N/A  N/A     12017      C   ...nda3/envs/dl37/bin/python     2745MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">(base) ubuntu@ip-192-168-81-198:~$ nvidia-smi</span><br><span class="line">Mon May 30 09:59:42 2022</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 515.43.04    Driver Version: 515.43.04    CUDA Version: 11.7     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N/A   38C    P0    68W /  70W |   2749MiB / 15360MiB |     97%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0   N/A  N/A     12017      C   ...nda3/envs/dl37/bin/python     2745MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>





<h2 id="InfoGPU"><a href="#InfoGPU" class="headerlink" title="InfoGPU"></a>InfoGPU</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.current_device()</span><br><span class="line">torch.cuda.device_count()</span><br><span class="line">torch.cuda.get_device_name(<span class="number">0</span>)</span><br><span class="line">torch.cuda.is_available()</span><br></pre></td></tr></table></figure>

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38arz9jvxj20u00ue42e.jpg" alt="image-20220530192309711" style="zoom:50%;" />

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.version.cuda</span><br><span class="line"><span class="string">'11.3'</span></span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>



<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qots3vvfj213c0ac3zt.jpg" alt="image-20220530200847113" style="zoom:50%;" />

<p>​                </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dl37rmbg) ubuntu@ip<span class="number">-192</span><span class="number">-168</span><span class="number">-81</span><span class="number">-198</span>:~/codes/rm-bg-test$ pip list | grep onnx</span><br><span class="line">onnxruntime                  <span class="number">1.11</span><span class="number">.1</span></span><br><span class="line">(dl37rmbg) ubuntu@ip<span class="number">-192</span><span class="number">-168</span><span class="number">-81</span><span class="number">-198</span>:~/codes/rm-bg-test$</span><br></pre></td></tr></table></figure>





<h3 id="Before"><a href="#Before" class="headerlink" title="Before"></a>Before</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"> * Debug mode: off</span><br><span class="line">2022-05-30 12:01:59 INFO      * Running on all addresses (0.0.0.0)</span><br><span class="line">   WARNING: This is a development server. Do not use it in a production deployment.</span><br><span class="line"> * Running on http://127.0.0.1:5005</span><br><span class="line"> * Running on http://192.168.81.198:5005 (Press CTRL+C to quit)</span><br><span class="line">2022-05-30 12:02:06 INFO     49.216.44.45 - - [30/May/2022 12:02:06] "GET / HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:02:06 INFO     49.216.44.45 - - [30/May/2022 12:02:06] "GET /favicon.ico HTTP/1.1" 404 -</span><br><span class="line">2022-05-30 12:02:14 INFO     49.216.44.45 - - [30/May/2022 12:02:14] "OPTIONS /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:02:15 INFO     Using algorithm -- u2</span><br><span class="line">2022-05-30 12:02:15 INFO     in get_prediction!!!!</span><br><span class="line">2022-05-30 12:02:15 INFO     dict_keys(['image'])</span><br><span class="line">2022-05-30 12:02:15 INFO     Time spent for successfully uploaded usr img img4predict_20220530-12:02:15.jpeg to S3 : 0.7874946594238281</span><br><span class="line">2022-05-30 12:02:15 INFO     Acquiring U2 Lock... Waiting...</span><br><span class="line">2022-05-30 12:02:15 INFO     Time spent for Acquiring U2 Lock: 6.9141387939453125e-06</span><br><span class="line">2022-05-30 12:02:15 INFO     Start predicting with U2</span><br><span class="line">2022-05-30 12:02:15 INFO     Acquired Lock for U2!</span><br><span class="line">2022-05-30 12:02:15 INFO     Time spent for reading image from S3 by cv2! : 0.06653761863708496</span><br><span class="line">Downloading...</span><br><span class="line">From: https://drive.google.com/uc?id=1tCU5MM1LhRgGou5OpmpjBQbSrYIUoYab</span><br><span class="line">To: /home/ubuntu/.u2net/u2net.onnx</span><br><span class="line"><span class="meta">100%</span><span class="bash">|████████████████████████████████████████████| 176M/176M [00:01&lt;00:00, 104MB/s]</span></span><br><span class="line">2022-05-30 12:02:19 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model.detect: 3.3960742950439453</span><br><span class="line">2022-05-30 12:02:19 INFO     Time spent for U2: 3.4032671451568604</span><br><span class="line">2022-05-30 12:02:19 INFO     uploaded_name: removed_back_U2_20220530-12:02:15.png</span><br><span class="line">2022-05-30 12:02:19 INFO     Time spent for upload_file to S3: 0.09176993370056152</span><br><span class="line">2022-05-30 12:02:19 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model: 3.5619876384735107</span><br><span class="line">2022-05-30 12:02:19 INFO     Released Lock for U2!</span><br><span class="line">2022-05-30 12:02:19 INFO     49.216.44.45 - - [30/May/2022 12:02:19] "POST /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:02:37 INFO     49.216.44.45 - - [30/May/2022 12:02:37] "OPTIONS /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:02:37 INFO     Using algorithm -- u2</span><br><span class="line">2022-05-30 12:02:37 INFO     in get_prediction!!!!</span><br><span class="line">2022-05-30 12:02:40 INFO     dict_keys(['image'])</span><br><span class="line">2022-05-30 12:02:41 INFO     Time spent for successfully uploaded usr img img4predict_20220530-12:02:40.jpeg to S3 : 3.314974784851074</span><br><span class="line">2022-05-30 12:02:41 INFO     Acquiring U2 Lock... Waiting...</span><br><span class="line">2022-05-30 12:02:41 INFO     Time spent for Acquiring U2 Lock: 5.245208740234375e-06</span><br><span class="line">2022-05-30 12:02:41 INFO     Start predicting with U2</span><br><span class="line">2022-05-30 12:02:41 INFO     Acquired Lock for U2!</span><br><span class="line">2022-05-30 12:02:41 INFO     Time spent for reading image from S3 by cv2! : 0.13377881050109863</span><br><span class="line">2022-05-30 12:02:43 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model.detect: 2.55837082862854</span><br><span class="line">2022-05-30 12:02:43 INFO     Time spent for U2: 2.6617114543914795</span><br><span class="line">2022-05-30 12:02:43 INFO     uploaded_name: removed_back_U2_20220530-12:02:40.png</span><br><span class="line">2022-05-30 12:02:44 INFO     Time spent for upload_file to S3: 0.1535935401916504</span><br><span class="line">2022-05-30 12:02:44 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model: 2.9496042728424072</span><br><span class="line">2022-05-30 12:02:44 INFO     Released Lock for U2!</span><br><span class="line">2022-05-30 12:02:44 INFO     49.216.44.45 - - [30/May/2022 12:02:44] "POST /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:04:49 INFO     49.216.44.45 - - [30/May/2022 12:04:49] "OPTIONS /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:04:49 INFO     Using algorithm -- u2</span><br><span class="line">2022-05-30 12:04:49 INFO     in get_prediction!!!!</span><br><span class="line">2022-05-30 12:04:51 INFO     dict_keys(['image'])</span><br><span class="line">2022-05-30 12:04:52 INFO     Time spent for successfully uploaded usr img img4predict_20220530-12:04:51.jpeg to S3 : 2.766263723373413</span><br><span class="line">2022-05-30 12:04:52 INFO     Acquiring U2 Lock... Waiting...</span><br><span class="line">2022-05-30 12:04:52 INFO     Time spent for Acquiring U2 Lock: 6.67572021484375e-06</span><br><span class="line">2022-05-30 12:04:52 INFO     Start predicting with U2</span><br><span class="line">2022-05-30 12:04:52 INFO     Acquired Lock for U2!</span><br><span class="line">2022-05-30 12:04:52 INFO     Time spent for reading image from S3 by cv2! : 0.07762646675109863</span><br><span class="line">2022-05-30 12:04:54 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model.detect: 1.9941890239715576</span><br><span class="line">2022-05-30 12:04:54 INFO     Time spent for U2: 2.0525596141815186</span><br><span class="line">2022-05-30 12:04:54 INFO     uploaded_name: removed_back_U2_20220530-12:04:51.png</span><br><span class="line">2022-05-30 12:04:54 INFO     Time spent for upload_file to S3: 0.11681175231933594</span><br><span class="line">2022-05-30 12:04:54 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model: 2.2475361824035645</span><br><span class="line">2022-05-30 12:04:54 INFO     Released Lock for U2!</span><br><span class="line">2022-05-30 12:04:54 INFO     49.216.44.45 - - [30/May/2022 12:04:54] "POST /predict/u2 HTTP/1.1" 200 -</span><br></pre></td></tr></table></figure>



<h3 id="After"><a href="#After" class="headerlink" title="After"></a>After</h3><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qoyzgd0cj20xo0d876d.jpg" alt="image-20220530201339682" style="zoom:50%;" />

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"> * Debug mode: off</span><br><span class="line">2022-05-30 12:14:18 INFO      * Running on all addresses (0.0.0.0)</span><br><span class="line">   WARNING: This is a development server. Do not use it in a production deployment.</span><br><span class="line"> * Running on http://127.0.0.1:5005</span><br><span class="line"> * Running on http://192.168.81.198:5005 (Press CTRL+C to quit)</span><br><span class="line">2022-05-30 12:14:59 INFO     49.216.44.45 - - [30/May/2022 12:14:59] "OPTIONS /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:15:00 INFO     Using algorithm -- u2</span><br><span class="line">2022-05-30 12:15:00 INFO     in get_prediction!!!!</span><br><span class="line">2022-05-30 12:15:02 INFO     dict_keys(['image'])</span><br><span class="line">2022-05-30 12:15:03 INFO     Time spent for successfully uploaded usr img img4predict_20220530-12:15:02.jpeg to S3 : 3.0525119304656982</span><br><span class="line">2022-05-30 12:15:03 INFO     Acquiring U2 Lock... Waiting...</span><br><span class="line">2022-05-30 12:15:03 INFO     Time spent for Acquiring U2 Lock: 6.198883056640625e-06</span><br><span class="line">2022-05-30 12:15:03 INFO     Start predicting with U2</span><br><span class="line">2022-05-30 12:15:03 INFO     Acquired Lock for U2!</span><br><span class="line">2022-05-30 12:15:03 INFO     Time spent for reading image from S3 by cv2! : 0.10718274116516113</span><br><span class="line">2022-05-30 12:15:03.755888640 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:526 CreateExecutionProviderInstance] Failed to create TensorrtExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html#requirements to ensure all dependencies are met.</span><br><span class="line">2022-05-30 12:15:03.755924162 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:552 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/reference/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.</span><br><span class="line">2022-05-30 12:15:05 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model.detect: 2.503098249435425</span><br><span class="line">2022-05-30 12:15:05 INFO     Time spent for U2: 2.5608794689178467</span><br><span class="line">2022-05-30 12:15:05 INFO     uploaded_name: removed_back_U2_20220530-12:15:02.png</span><br><span class="line">2022-05-30 12:15:05 INFO     Time spent for upload_file to S3: 0.0716698169708252</span><br><span class="line">2022-05-30 12:15:05 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model: 2.740231990814209</span><br><span class="line">2022-05-30 12:15:05 INFO     Released Lock for U2!</span><br><span class="line">2022-05-30 12:15:05 INFO     49.216.44.45 - - [30/May/2022 12:15:05] "POST /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:15:50 INFO     49.216.44.45 - - [30/May/2022 12:15:50] "OPTIONS /predict/u2 HTTP/1.1" 200 -</span><br><span class="line">2022-05-30 12:15:50 INFO     Using algorithm -- u2</span><br><span class="line">2022-05-30 12:15:50 INFO     in get_prediction!!!!</span><br><span class="line">2022-05-30 12:15:53 INFO     dict_keys(['image'])</span><br><span class="line">2022-05-30 12:15:53 INFO     Time spent for successfully uploaded usr img img4predict_20220530-12:15:53.jpeg to S3 : 2.71683931350708</span><br><span class="line">2022-05-30 12:15:53 INFO     Acquiring U2 Lock... Waiting...</span><br><span class="line">2022-05-30 12:15:53 INFO     Time spent for Acquiring U2 Lock: 6.67572021484375e-06</span><br><span class="line">2022-05-30 12:15:53 INFO     Start predicting with U2</span><br><span class="line">2022-05-30 12:15:53 INFO     Acquired Lock for U2!</span><br><span class="line">2022-05-30 12:15:53 INFO     Time spent for reading image from S3 by cv2! : 0.09477829933166504</span><br><span class="line">2022-05-30 12:15:54.261673705 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:526 CreateExecutionProviderInstance] Failed to create TensorrtExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html#requirements to ensure all dependencies are met.</span><br><span class="line">2022-05-30 12:15:54.261700073 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:552 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/reference/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.</span><br><span class="line">2022-05-30 12:15:55 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model.detect: 1.9362876415252686</span><br><span class="line">2022-05-30 12:15:55 INFO     Time spent for U2: 2.035747528076172</span><br><span class="line">2022-05-30 12:15:55 INFO     uploaded_name: removed_back_U2_20220530-12:15:53.png</span><br><span class="line">2022-05-30 12:15:56 INFO     Time spent for upload_file to S3: 0.16250967979431152</span><br><span class="line">2022-05-30 12:15:56 INFO     &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Time spent for U2 model: 2.2935831546783447</span><br><span class="line">2022-05-30 12:15:56 INFO     Released Lock for U2!</span><br><span class="line">2022-05-30 12:15:56 INFO     49.216.44.45 - - [30/May/2022 12:15:56] "POST /predict/u2 HTTP/1.1" 200 -</span><br></pre></td></tr></table></figure>

<h4 id="To-be-Debugged…"><a href="#To-be-Debugged…" class="headerlink" title="To be Debugged…"></a>To be Debugged…</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(dl37) ubuntu@ip-192-168-81-198:~/codes/rm-bg-test$ nvcc</span><br><span class="line">Command 'nvcc' not found, but can be installed with:</span><br><span class="line">sudo apt install nvidia-cuda-toolkit</span><br><span class="line">(dl37) ubuntu@ip-192-168-81-198:~/codes/rm-bg-test$ sudo apt install nvidia-cuda-toolkit</span><br></pre></td></tr></table></figure>

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qwhz0066j21bg0r6wk6.jpg" alt="image-20220531003424795" style="zoom:50%;" />



<p>still issue:</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qxq59vu7j21l60u0q9d.jpg" alt="image-20220531011651588"></p>
<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2ribc6nnkj21jl0u0tdh.jpg" alt="image-20220531130858981" style="zoom:80%;" />





<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2rrsnyp4cj22280pgtev.jpg" alt="image-20220531183707169" style="zoom:67%;" />





<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38as3hkw7j20zq03swet.jpg" alt="image-20220601201815869" style="zoom:70%;" />



<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38as53kxxj21om0te0z5.jpg" alt="image-20220602130731483" style="zoom:67%;" />





<h3 id="Fixed"><a href="#Fixed" class="headerlink" title="Fixed!"></a>Fixed!</h3><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2tuku93g7j21a70u0n2c.jpg" alt="image-20220602134439595"  />



<h3 id="T4-8TFLOPS"><a href="#T4-8TFLOPS" class="headerlink" title="T4: 8TFLOPS"></a>T4: 8TFLOPS</h3><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38as95071j20ws0f80tt.jpg" alt="image-20220530175459347" style="zoom:50%;" />





<p>vs </p>
<h2 id="Desktop"><a href="#Desktop" class="headerlink" title="Desktop"></a>Desktop</h2><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38asbbp5qj21060u041a.jpg" alt="image-20220530190225031" style="zoom:67%;" />



<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qmxf3k38j213g0mmwg7.jpg" alt="image-20220530190314249" style="zoom:50%;" />



<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38asf5hnbj215e0l4q7e.jpg" alt="image-20220530190425812" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38ash054dj20zy0l6juc.jpg" alt="image-20220530190343502" style="zoom:67%;" />





<h2 id="Others-白嫖平台"><a href="#Others-白嫖平台" class="headerlink" title="Others 白嫖平台"></a>Others 白嫖平台</h2><p>Colab</p>
<p>Kabble</p>
<p>AI Studio</p>
<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qn0jg4rhj21090u0din.jpg" alt="image-20220530190615177" style="zoom:67%;" />







<p>ref: <a href="https://www.bilibili.com/video/BV1MA411L78X?t=493" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1MA411L78X?t=493</a></p>
<h2 id="CUDAs"><a href="#CUDAs" class="headerlink" title="CUDAs"></a>CUDAs</h2><p>2</p>
<p><code>torch.version.cuda</code> is just defined as a string. It doesn’t query anything. It doesn’t tell you which version of CUDA you have installed. It only tells you that the PyTorch you have installed is meant for that (<code>10.2</code>) version of CUDA. But the version of CUDA you are actually running on your system is <code>11.4</code>.</p>
<p>If you installed PyTorch with, say,</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install pytorch torchvision torchaudio cudatoolkit=<span class="number">11.1</span> -c pytorch -c nvidia</span><br></pre></td></tr></table></figure>

<p>then you should also have the necessary libraries (<code>cudatoolkit</code>) in your Anaconda directory, which may be different from your system-level libraries.</p>
<p>However, note that these depend on the NVIDIA display drivers:</p>
<p><a href="https://i.stack.imgur.com/lKSLg.png" target="_blank" rel="noopener"><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2qxb8m3snj20dw0auwf5.jpg" alt="enter image description here"></a></p>
<p>Installing <code>cudatoolkit</code> does not install the drivers (<code>nvidia.ko</code>), which you need to install separately on your system.</p>
<p><a href="https://stackoverflow.com/questions/69497328/why-are-torch-version-cuda-and-devicequery-reporting-different-versions" target="_blank" rel="noopener">https://stackoverflow.com/questions/69497328/why-are-torch-version-cuda-and-devicequery-reporting-different-versions</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2022/05/25/Deeplearning/2022-05-25-M1%20GPU%20usage/">Deeplearning/2022-05-25-M1 GPU usage</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-05-25</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/DevOps/">DevOps</a></span><div class="content"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">10103  chmod +x Miniforge3-MacOSX-arm64.sh</span><br><span class="line">10104  ./Miniforge3-MacOSX-arm64.sh</span><br><span class="line">10119  conda --version &lt;--- must be osx-arm64 for "platform"</span><br><span class="line">10120  python</span><br><span class="line">10121  conda create --name env_arm_py38torch python=3.8</span><br><span class="line">10122  conda activate env_arm_py38torch</span><br></pre></td></tr></table></figure>

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38arfxr23j21x20scn05.jpg" alt="image-20220525155414871" style="zoom:50%;" />







<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38arizezpj21em0u00x5.jpg" alt="image-20220525160030684" style="zoom:50%;" />





<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h2kplalpvpj21ba0fwq56.jpg" alt="image-20220525160201912"></p>
<p><code>mps: Apple&#39;s Metal Performance Shaders</code></p>
<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38arm7ywnj218w0qc0vi.jpg" alt="image-20220528103507819" style="zoom:67%;" />

<p><a href="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/" target="_blank" rel="noopener">https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> python</span><br><span class="line">Python <span class="number">3.8</span><span class="number">.13</span> | packaged by conda-forge | (default, Mar <span class="number">25</span> <span class="number">2022</span>, <span class="number">06</span>:<span class="number">05</span>:<span class="number">16</span>)</span><br><span class="line">[Clang <span class="number">12.0</span><span class="number">.1</span> ] on darwin</span><br><span class="line">Type <span class="string">"help"</span>, <span class="string">"copyright"</span>, <span class="string">"credits"</span> <span class="keyword">or</span> <span class="string">"license"</span> <span class="keyword">for</span> more information.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line">torch.device()^[[D&gt;&gt;&gt; torch.device(<span class="string">'mps'</span>)</span><br><span class="line">KeyboardInterrupt</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.__version__</span><br><span class="line"><span class="string">'1.13.0.dev20220524'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.device(<span class="string">'mps'</span>)</span><br><span class="line">device(type=<span class="string">'mps'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">10</span>).to(<span class="string">"mps"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">/Users/joe/miniforge3/envs/env_arm_py38torch/lib/python3<span class="number">.8</span>/site-packages/torch/_tensor_str.py:<span class="number">103</span>: UserWarning: The operator <span class="string">'aten::bitwise_and.Tensor_out'</span> <span class="keyword">is</span> <span class="keyword">not</span> currently supported on the MPS backend <span class="keyword">and</span> will fall back to run on the CPU. This may have performance implications. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:<span class="number">11.</span>)</span><br><span class="line">  nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) &amp; tensor_view.ne(<span class="number">0</span>))</span><br><span class="line">tensor([ <span class="number">0.5814</span>,  <span class="number">1.1789</span>,  <span class="number">2.8108</span>, <span class="number">-0.5239</span>, <span class="number">-0.5657</span>, <span class="number">-0.1814</span>, <span class="number">-0.1226</span>,  <span class="number">0.1378</span>,</span><br><span class="line">         <span class="number">0.0298</span>,  <span class="number">0.4484</span>], device=<span class="string">'mps:0'</span>)</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; pip install jupyter</span><br></pre></td></tr></table></figure>



<h2 id="Perm-Test"><a href="#Perm-Test" class="headerlink" title="Perm Test"></a>Perm Test</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install asitop</span></span><br></pre></td></tr></table></figure>









<h2 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h2><p><a href="https://www.gushiciku.cn/pl/gXrk/zh-tw" target="_blank" rel="noopener">https://www.gushiciku.cn/pl/gXrk/zh-tw</a></p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><span class="space">&hellip;</span><a class="page-number" href="/page/81/">81</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>