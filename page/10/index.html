<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.1.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">249</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">24</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">36</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Awaken Desparado</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/12/CVs/2019-12-12-Problems%20Collection%20from%20EGN/">CVs/2019-12-12-Problems Collection from EGN</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/DevOps/">DevOps</a></span><div class="content"><h3 id="LC-46-Permutation"><a href="#LC-46-Permutation" class="headerlink" title="LC 46 - Permutation"></a>LC 46 - Permutation</h3></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/12/NLP/2019-12-12-LSTM%20Brief.%20&amp;%20Hamming%20Loss/">NLP/2019-12-12-LSTM Brief. &amp; Hamming Loss</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/NLP-AI/">NLP, AI</a></span><div class="content"><h3 id="LSTM-Brief"><a href="#LSTM-Brief" class="headerlink" title="LSTM Brief."></a>LSTM Brief.</h3><p>LSTM是SimpleRNN的变体，它解决了梯度消失的问题。怎么解决的那？</p>
<p>LSTM增加了一个可以相隔多个timesteps来传递信息的方法。想想有一个传送带在你处理sequences时一起运转。每个时间节点的信息都可以放到传送带上，或者从传送带上拿下来，当然你也可以更新传送带上的信息。这样就保存了很久之前的信息，防止了信息的丢失。我们把SimpleRNN中的矩阵记为<code>Wo Uo bo</code>，LSTM的结构图如下：</p>
<p><img src="https://pic4.zhimg.com/80/v2-31da92629c2ddbb0a3971d18f1592b03_hd.jpg" alt="img"></p>
<p>我们在SimpleRNN基础上，增加一条传送带（adding a carry track）用来传递信息。传送带上每个时刻的状态我们记为：<code>c t</code> c是carry的意思。</p>
<p>显然，当前时刻的输出就应该收到三个信息的影响</p>
<hr>
<h3 id="Hamming-Distance"><a href="#Hamming-Distance" class="headerlink" title="Hamming Distance"></a>Hamming Distance</h3><p>在<a href="https://zh.wikipedia.org/wiki/信息论" target="_blank" rel="noopener">資訊理論</a>中，兩個等長<a href="https://zh.wikipedia.org/wiki/字符串" target="_blank" rel="noopener">字符串</a>之間的<strong>漢明距離</strong>（英語：Hamming distance）是兩個字符串對應位置的不同字符的個數。換句話說，它就是將一個字符串變換成另外一個字符串所需要<em>替換</em>的字符個數。</p>
<p><strong><a href="https://zh.wikipedia.org/wiki/汉明重量" target="_blank" rel="noopener">漢明重量</a></strong>是字符串相對於同樣長度的零字符串的漢明距離，也就是說，它是字符串中非零的元素個數：對於<a href="https://zh.wikipedia.org/wiki/二进制" target="_blank" rel="noopener">二進位</a><a href="https://zh.wikipedia.org/wiki/字符串" target="_blank" rel="noopener">字符串</a>來說，就是1的個數，所以11101的漢明重量是4。</p>
<p>例如：</p>
<ul>
<li><strong>1011101</strong>與<strong>1001001</strong>之間的漢明距離是2。</li>
<li><strong>2143896</strong>與<strong>2233796</strong>之間的漢明距離是3。</li>
<li>“<strong>toned</strong>“與”<strong>roses</strong>“之間的漢明距離是3。</li>
</ul>
<hr>
<h3 id="Hamming-Loss"><a href="#Hamming-Loss" class="headerlink" title="Hamming Loss"></a>Hamming Loss</h3><p>Hamming Loss 是用来计算多标签分类(Multi-label classification)模型精度的。</p>
<p>HammingLoss=1N∑i=1NXOR(Yi,j,Pi,j)LHammingLoss=1N∑i=1NXOR(Yi,j,Pi,j)L</p>
<p>NN是样本的数量，LL是标签的个数，Yi,jYi,j是第ii个预测结果中第jj个分量的真实值，Pi,jPi,j是第ii个预测结果中第jj个分量的预测值，XORXOR是抑或，XOR(0,1)=XOR(1,0)=1XOR(0,1)=XOR(1,0)=1，XOR(0,0)=XOR(1,1)=0XOR(0,0)=XOR(1,1)=0。</p>
<p>例子：三个样本</p>
<p>Y1=(0,1,1,1,0),P1=(1,1,1,0,0)Y1=(0,1,1,1,0),P1=(1,1,1,0,0)</p>
<p>Y2=(1,0,0,1,1),P2=(1,0,0,0,1)Y2=(1,0,0,1,1),P2=(1,0,0,0,1)</p>
<p>Y3=(1,1,0,0,0),P3=(1,0,1,0,1)Y3=(1,1,0,0,0),P3=(1,0,1,0,1)<br>$$<br>HammingLoss=\frac{1}{3}×\frac{2+1+3}{5}=0.4<br>$$</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/12/NLP/2019-12-12-NLP%20metric%20%3E%20Perplexity/">NLP/2019-12-12-NLP metric &gt; Perplexity</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/NLP-AI/">NLP, AI</a></span><div class="content"><p>from : <a href="https://blog.csdn.net/index20001/article/details/78884646" target="_blank" rel="noopener">https://blog.csdn.net/index20001/article/details/78884646</a></p>
<h1 id="语言模型评价指标Perplexity"><a href="#语言模型评价指标Perplexity" class="headerlink" title="语言模型评价指标Perplexity"></a>语言模型评价指标Perplexity</h1><p>原创<a href="https://me.csdn.net/index20001" target="_blank" rel="noopener">Joy_Shen</a> 发布于2017-12-24 13:33:02 阅读数 26576 收藏</p>
<p>展开</p>
<p>语言模型（Language Model，LM），给出一句话的前k个词，希望它可以预测第k+1个词是什么，即给出一个第k+1个词可能出现的概率的分布p(xk+1|x1,x2,…,xk)。</p>
<p>在报告里听到用PPL衡量语言模型收敛情况，于是从公式角度来理解一下该指标的意义。</p>
<h2 id="Perplexity定义"><a href="#Perplexity定义" class="headerlink" title="Perplexity定义"></a>Perplexity定义</h2><p>PPL是用在自然语言处理领域（NLP）中，衡量语言模型好坏的指标。它主要是根据每个词来估计一句话出现的概率，并用句子长度作normalize，公式为</p>
<p><img src="https://img-blog.csdn.net/20171224134258243" alt="img"></p>
<p>S代表sentence，N是句子长度，p(wi)是第i个词的概率。第一个词就是 p(w1|w0)，而w0是START，表示句子的起始，是个占位符。</p>
<p>这个式子可以这样理解，PPL越小，p(wi)则越大，一句我们期望的sentence出现的概率就越高。</p>
<p>还有人说，Perplexity可以认为是average branch factor（平均分支系数），即预测下一个词时可以有多少种选择。别人在作报告时说模型的PPL下降到90，可以直观地理解为，在模型生成一句话时下一个词有90个合理选择，可选词数越少，我们大致认为模型越准确。这样也能解释，为什么PPL越小，模型越好。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/12/Python/2019-12-12-Design%20Prototype/">Python/2019-12-12-Design Prototype</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Design/">Design</a></span><div class="content"><h3 id="Axure"><a href="#Axure" class="headerlink" title="Axure"></a>Axure</h3></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/12/Python/2019-12-12-MapReduce/">Python/2019-12-12-MapReduce</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/BigData-Python/">BigData, Python</a></span><div class="content"><p>Ref: <a href="https://zhuanlan.zhihu.com/p/62135686" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/62135686</a></p>
<h1 id="Ref1"><a href="#Ref1" class="headerlink" title="Ref1"></a>Ref1</h1><h2 id="一、MapReduce是什么"><a href="#一、MapReduce是什么" class="headerlink" title="一、MapReduce是什么"></a>一、MapReduce是什么</h2><ol>
<li>MapReduce是一种分布式计算框架 ，以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。主要用于搜索领域，解决海量数据的计算问题。</li>
<li>MR有两个阶段组成：Map和Reduce，用户只需实现map()和reduce()两个函数，即可实现分布式计算。</li>
</ol>
<h2 id="二、MapReduce做什么"><a href="#二、MapReduce做什么" class="headerlink" title="二、MapReduce做什么"></a>二、MapReduce做什么</h2><ol>
<li>MapReduce框架由Map和Reduce组成。</li>
<li>Map()负责把一个大的block块进行切片并计算。</li>
<li>Reduce() 负责把Map()切片的数据进行汇总、计算。</li>
</ol>
<h2 id="三、MapReduce怎么做"><a href="#三、MapReduce怎么做" class="headerlink" title="三、MapReduce怎么做"></a>三、MapReduce怎么做</h2><p><img src="https://pic1.zhimg.com/80/v2-956054759aea4352a795452e31754ef0_hd.jpg" alt="img"></p>
<ol>
<li>第一步对输入的数据进行切片，每个切片分配一个map()任务，map()对其中的数据进行计算，对每个数据用键值对的形式记录，然后输出到环形缓冲区（图中sort的位置）。</li>
<li>map（）中输出的数据在环形缓冲区内进行快排，每个环形缓冲区默认大小100M，当数据达到80M时（默认），把数据输出到磁盘上。形成很多个内部有序整体无序的小文件。</li>
<li>框架把磁盘中的小文件传到Reduce()中来，然后进行归并排序，最终输出。</li>
</ol>
<h2 id="四、要点是什么"><a href="#四、要点是什么" class="headerlink" title="四、要点是什么"></a>四、要点是什么</h2><ol>
<li>MapReduce将输入的数据进行逻辑切片，一片对应一个Map任务</li>
<li>Map以并行的方式处理切片</li>
<li>框架对Map输出进行排序，然后发给Reduce</li>
<li>MapReduce的输入输出数据处于同一个文件系统（HDFS）</li>
<li>框架负责任务调度、任务监控、失败任务的重新执行</li>
<li>框架会对键和值进行序列化，因此键和值需要实现writable接口，框架会对键排序，因此必须实现writableComparable接口。</li>
</ol>
<h2 id="五、MapReduce原语"><a href="#五、MapReduce原语" class="headerlink" title="五、MapReduce原语"></a>五、MapReduce原语</h2><p>MapReduce原语：“相同”key的键值对为一组调用一次Reduce方法，方法内迭代这组数据进行计算。</p>
<h1 id="Ref2"><a href="#Ref2" class="headerlink" title="Ref2"></a>Ref2</h1><p><a href="https://www.jianshu.com/p/6b6a42a0740c" target="_blank" rel="noopener">https://www.jianshu.com/p/6b6a42a0740c</a></p>
<h5 id="1-mapreduce-简介"><a href="#1-mapreduce-简介" class="headerlink" title="1. mapreduce 简介"></a>1. mapreduce 简介</h5><p>mapreduce源自google的一篇文章，将海量数据处理的过程拆分为map和reduce。mapreduce 成为了最早的分布式计算框架，这样即使不懂的分布式计算框架的内部运行机制的用户，也可以利用分布式的计算框架实现分布式的计算，并在hadoop上面运行。</p>
<h5 id="1-设计思想"><a href="#1-设计思想" class="headerlink" title="1. 设计思想"></a>1. 设计思想</h5><p>hadoop 文件系统 ，提供了一个分布式的文件系统，但是hadoop文件系统读写的操作都涉及到大量的网络的操作，并不能很好的完成实时性比较强的任务。</p>
<p>但是hadoop可以给上面的应用提供一个很好的支持。比如hadoop文件系统上面可以运行mapreduce。mapreduce是一个计算的框架，mapreduce是一个分布式的计算框架，这样mapreduce利用分布式的文件系统，将不同的机器上完成不同的计算，然后就计算结果返回。这样很好的利用了分布式的文件系统。</p>
<p>数据分布式的存储，然后计算的时候，分布式的计算，然后将结果返回。这样的好处就是不会涉及到大量的网络传输数据。</p>
<p>不知道在哪里看见一句话，觉得很好，记了下来。大数据设计的一个基本的思想是<strong>将计算的任务推送到数据所在的地方，而不是反过来。</strong></p>
<h5 id="2-Mapreduce-的架构"><a href="#2-Mapreduce-的架构" class="headerlink" title="2. Mapreduce 的架构"></a>2. Mapreduce 的架构</h5><p>mrappmaster（管理节点）<br> Maptask（多个）<br> reducetask（多个）</p>
<p>mapreduce 的计算过程，举一个例子 wordcount （单词计数的例子）比如说有一个文件 ，文件内容：</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">good better best never it rest </span><br><span class="line">till good <span class="keyword">is</span> better and better <span class="keyword">is</span> best</span><br></pre></td></tr></table></figure>

<p>那么第一步 先map，map的流程是，将单词以空格来切分，然后建立一个key-value的map。</p>
<p>得到的结果是：</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">good    <span class="number">1</span></span><br><span class="line">better  <span class="number">1</span></span><br><span class="line">best    <span class="number">1</span></span><br><span class="line">never   <span class="number">1</span></span><br><span class="line">it      <span class="number">1</span></span><br><span class="line">rest    <span class="number">1</span></span><br><span class="line">till    <span class="number">1</span></span><br><span class="line">good    <span class="number">1</span></span><br><span class="line"><span class="keyword">is</span>      <span class="number">1</span></span><br><span class="line">better  <span class="number">1</span></span><br><span class="line">and     <span class="number">1</span></span><br><span class="line">better  <span class="number">1</span></span><br><span class="line"><span class="keyword">is</span>      <span class="number">1</span></span><br><span class="line">best    <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>上面这个map的结果，相当于给每一个每一个单词都建立一个字典，key就是单词本身，value是个数。</p>
<p>第二步是reduce：<br> reduce是将一致的单词，发送个同一个reduce节点。在同一个reduce节点上面，这个reduce节点，负责将相同的key合并再一起。</p>
<p>这样就完成的单词的计数。</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/4717565-0afa417b7248b948.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/767/format/webp" alt="img"></p>
<p>image.png</p>
<h6 id="这里存在几个问题："><a href="#这里存在几个问题：" class="headerlink" title="这里存在几个问题："></a>这里存在几个问题：</h6><p><strong>Q1:</strong> reduce的方式是将一个类型的key，送给同一个节点。比如说，把good都送给第一个节点。till送给第二个节点。那么如果做到这一点呢？</p>
<p>答：使用hash表的方式，一个key，放在hash表里面，就会产生一个为一个code（java 里面的数据结构是 hashcode），然后再给它取余数。比如机器有四个节点，做reduce，那么就取余4，这样计算的任务就分给四台机器。这个就是shuffl机制。（shuffl就是洗牌的意思）（这个算法其实就是<strong>哈希取模</strong>的算法）</p>
<p><strong>Q2:</strong> map 执行完成之后，中间结果保存在哪里？<br> map函数输出的中间结果key/value数据在内存中进行缓存，然后周期性的写入磁盘。每个map函数在写入磁盘之前，通过哈希函数，将自己的key/value对分割成R份。（R是reduce的个数 哈希函数一般是 用key对r进行哈希取模，这样将map函数的中间数据分割成r份，每一份分给一个reduce）。<strong>当某个reduce任务的worker接收到master的通知，其通过rpc远程调用 将map任务产生的m份属于自己的文件远程拉取到本地。</strong></p>
<p><strong>mapreduce的计算特点以及不足：</strong><br> mapreduce的计算框架的优点是，极强的扩展能力，可以在数千台机器上并发的执行。其次，有很好的容错性，另外，就是向上的接口简洁。用户只需要写map和reduce函数，即可完成大规模数据的并行处理。</p>
<p><strong>mapreduce的缺点：</strong><br> mapreduce并不适合对实时性要求比较高的场景，比如交互式查询或者是流式计算。另外，也不适合迭代类的计算（比如机器学习类的应用）。</p>
<p>原因：<br> mapreduce的启动时间比较长，对于批处理的任务，这个问题并不算大。但是对于实时性比较高的任务，其启动时间长的缺点就很不合适了。</p>
<p>mapreduce一次执行的过程里面，往往涉及到多出磁盘读写，以及网络的传输。对于迭代的任务，这样很好的开销需要很多次，明显降低了效率。</p>
<p>而Storm和Spark，一个是流式计算的框架，一个是机器学习的框架。他们更适合解决这类型的任务。</p>
<p>Demo：<br> 一个利用mapreduce思想单词计数的实例：<a href="https://www.jianshu.com/p/59ebf5a36ee5" target="_blank" rel="noopener">http://www.jianshu.com/p/59ebf5a36ee5</a></p>
<p>参考：</p>
<ol>
<li>google的mapreduce 论文</li>
<li>《hadoop权威指南》</li>
<li>《hadoop 海量数据处理》</li>
</ol>
<p>作者：zhaozhengcoder<br>链接：<a href="https://www.jianshu.com/p/6b6a42a0740c" target="_blank" rel="noopener">https://www.jianshu.com/p/6b6a42a0740c</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/50/">50</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>