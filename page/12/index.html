<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">384</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">66</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Awaken Desparado</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/10/22/RecSys/5%20RecSys%20Wired-in/">RecSys/5 RecSys Wired-in</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-22</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/RecSys/">RecSys</a></span><div class="content"><p>根據用戶的歷史info &amp; 行為，作推薦他感興趣的內容</p>
<h3 id="Behaviour-based"><a href="#Behaviour-based" class="headerlink" title="Behaviour-based"></a>Behaviour-based</h3><p>CF</p>
<h3 id="Content-based"><a href="#Content-based" class="headerlink" title="Content-based"></a>Content-based</h3><p>w/ tag</p>
<h3 id="The-Solution-to"><a href="#The-Solution-to" class="headerlink" title="The Solution to"></a>The Solution to</h3><ol>
<li>info overload</li>
<li>The long tail module</li>
<li>user’s experience</li>
</ol>
<h3 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h3></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/08/26/DevOps/2020-08-26-jenkins/">DevOps/2020-08-26-jenkins</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-08-26</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/DevOps/">DevOps</a></span><div class="content"><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5k04kfj93j218o0ekdgo.jpg" alt="image-20220826112156024" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5k053p89yj20u0070aa5.jpg" alt="image-20220826112229639" style="zoom: 50%;" />
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/06/03/Algo.%20Ult./special_DFS/">Algo. Ult./special_DFS</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-06-03</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/AlgoUlt/">AlgoUlt.</a></span><div class="content"><h1 id="Special-DFS"><a href="#Special-DFS" class="headerlink" title="Special DFS"></a>Special DFS</h1><p>p.s. DFS with specific boundary check during recursion</p>
<p>e.g. like subset, comb, or perm and so on</p>
<h2 id="320-Generalized-Abbreviation"><a href="#320-Generalized-Abbreviation" class="headerlink" title="320 Generalized Abbreviation"></a>320 Generalized Abbreviation</h2><p>A word’s <strong>generalized abbreviation</strong> can be constructed by taking any number of <strong>non-overlapping</strong> and <strong>non-adjacent</strong> substrings and replacing them with their respective lengths.</p>
<ul>
<li>For example,</li>
</ul>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;abcde&quot;</span><br></pre></td></tr></table></figure>



<p>  can be abbreviated into:</p>
<ul>
<li><code>&quot;a3e&quot;</code> (<code>&quot;bcd&quot;</code> turned into <code>&quot;3&quot;</code>)</li>
<li><code>&quot;1bcd1&quot;</code> (<code>&quot;a&quot;</code> and <code>&quot;e&quot;</code> both turned into <code>&quot;1&quot;</code>)</li>
<li><code>&quot;5&quot;</code> (<code>&quot;abcde&quot;</code> turned into <code>&quot;5&quot;</code>)</li>
<li><code>&quot;abcde&quot;</code> (no substrings replaced)</li>
</ul>
<ul>
<li>However, these abbreviations are</li>
</ul>
<p>  invalid</p>
<p>  :</p>
<ul>
<li><code>&quot;23&quot;</code> (<code>&quot;ab&quot;</code> turned into <code>&quot;2&quot;</code> and <code>&quot;cde&quot;</code> turned into <code>&quot;3&quot;</code>) is invalid as the substrings chosen are adjacent.</li>
<li><code>&quot;22de&quot;</code> (<code>&quot;ab&quot;</code> turned into <code>&quot;2&quot;</code> and <code>&quot;bc&quot;</code> turned into <code>&quot;2&quot;</code>) is invalid as the substring chosen overlap.</li>
</ul>
<p>Given a string <code>word</code>, return <em>a list of all the possible <strong>generalized abbreviations</strong> of</em> <code>word</code>. Return the answer in <strong>any order</strong>.</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: word &#x3D; &quot;word&quot;</span><br><span class="line">Output: [&quot;4&quot;,&quot;3d&quot;,&quot;2r1&quot;,&quot;2rd&quot;,&quot;1o2&quot;,&quot;1o1d&quot;,&quot;1or1&quot;,&quot;1ord&quot;,&quot;w3&quot;,&quot;w2d&quot;,&quot;w1r1&quot;,&quot;w1rd&quot;,&quot;wo2&quot;,&quot;wo1d&quot;,&quot;wor1&quot;,&quot;word&quot;]</span><br></pre></td></tr></table></figure>

<p><strong>Example 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: word &#x3D; &quot;a&quot;</span><br><span class="line">Output: [&quot;1&quot;,&quot;a&quot;]</span><br></pre></td></tr></table></figure>



<p><strong>Constraints:</strong></p>
<ul>
<li><code>1 &lt;= word.length &lt;= 15</code></li>
<li><code>word</code> consists of only lowercase English letters.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateAbbreviations</span><span class="params">(self, word: str)</span> -&gt; List[str]:</span></span><br><span class="line">        res = []</span><br><span class="line">        self.my_20200604(word, <span class="number">0</span>, <span class="number">0</span>, [], res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">        <span class="comment"># return self.my_1(word)</span></span><br><span class="line">        <span class="comment"># return self.sol(word)</span></span><br><span class="line">        <span class="comment"># return self.sol2(word)</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># [1, 0]  --&gt; 1 o</span></span><br><span class="line">    <span class="comment">#         --&gt; 1 + 1 = 2</span></span><br><span class="line">    <span class="comment"># [w, 0]  --&gt; w o</span></span><br><span class="line">    <span class="comment">#         --&gt; w 1</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">my_20200604</span><span class="params">(self, word, idx, cnt, item, res)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> idx == len(word):</span><br><span class="line">            <span class="keyword">if</span> cnt &gt; <span class="number">0</span>:</span><br><span class="line">                item.append(str(cnt))</span><br><span class="line">            res.append(<span class="string">''</span>.join(item))</span><br><span class="line">            <span class="keyword">if</span> cnt &gt; <span class="number">0</span>:</span><br><span class="line">                item.pop()</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        self.my_20220604(word, idx + <span class="number">1</span>, cnt + <span class="number">1</span>, item, res)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># item.append(word[idx])</span></span><br><span class="line">        <span class="comment"># self.my_20220604(word, idx + 1, 0, item + word[idx], res)</span></span><br><span class="line">        <span class="comment"># str_cnt = str(cnt)</span></span><br><span class="line">        <span class="keyword">if</span> cnt &gt; <span class="number">0</span>:</span><br><span class="line">            self.my_20220604(word, idx + <span class="number">1</span>, <span class="number">0</span>, item + [str(cnt)] + [word[idx]], res)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.my_20220604(word, idx + <span class="number">1</span>, <span class="number">0</span>, item + [word[idx]], res)</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateAbbreviations</span><span class="params">(self, word: str)</span> -&gt; List[str]:</span></span><br><span class="line">        subsets = [<span class="string">""</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(word)):</span><br><span class="line">            <span class="comment"># at every level, we take the previous strings then either </span></span><br><span class="line">            <span class="comment"># (1). append the character</span></span><br><span class="line">            <span class="comment"># (2). abbreviate the character</span></span><br><span class="line">            lvl_subsets = []</span><br><span class="line">            <span class="keyword">for</span> subset <span class="keyword">in</span> subsets:</span><br><span class="line">                <span class="comment"># (1). append character</span></span><br><span class="line">                lvl_subsets.append(subset + word[i])</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># (2). abbreviation</span></span><br><span class="line">                <span class="comment"># (2)(a)</span></span><br><span class="line">                <span class="comment"># if last char is an integer, += 1</span></span><br><span class="line">                <span class="keyword">if</span> subset <span class="keyword">and</span> subset[<span class="number">-1</span>].isdigit():</span><br><span class="line">                    lvl_subsets.append(subset[:len(subset) - <span class="number">1</span>] + str(int(subset[<span class="number">-1</span>]) + <span class="number">1</span>))</span><br><span class="line">                <span class="comment"># (2)(b) </span></span><br><span class="line">                <span class="comment"># otherwise, add the number 1 if the previous character is NOT a number</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    lvl_subsets.append(subset + <span class="string">"1"</span>)</span><br><span class="line">            subsets = lvl_subsets</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> subsets</span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateAbbreviations</span><span class="params">(self, word: str)</span> -&gt; List[str]:</span></span><br><span class="line">        queue = deque([([], <span class="number">0</span>, <span class="number">0</span>)]) <span class="comment"># tuple of currentWord, index, count</span></span><br><span class="line">        </span><br><span class="line">        res = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> queue:</span><br><span class="line">            currWord, index, count = queue.popleft()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> index == len(word): <span class="comment"># index has reached the end of word - we are finished processing this tuple</span></span><br><span class="line">                <span class="keyword">if</span> count != <span class="number">0</span>:</span><br><span class="line">                    currWord.append(str(count))</span><br><span class="line">                res.append(<span class="string">""</span>.join(currWord))</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># branch 1</span></span><br><span class="line">                <span class="comment"># don't add current letter from input and increase count by 1 (so we can turn it into a number later)</span></span><br><span class="line">                queue.append((currWord, index + <span class="number">1</span>, count + <span class="number">1</span>))</span><br><span class="line">            </span><br><span class="line">                <span class="comment"># branch 2</span></span><br><span class="line">                newWord = list(currWord)</span><br><span class="line">                <span class="keyword">if</span> (count != <span class="number">0</span>): <span class="comment"># if there is a count, consume it and add it to our newWord</span></span><br><span class="line">                    newWord.append(str(count))</span><br><span class="line">                </span><br><span class="line">                newWord.append(word[index]) <span class="comment"># add current letter</span></span><br><span class="line">                queue.append((newWord, index + <span class="number">1</span>, <span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>





<h2 id="22-Generate-Parentheses"><a href="#22-Generate-Parentheses" class="headerlink" title="22 Generate Parentheses"></a>22 Generate Parentheses</h2><p>Given <code>n</code> pairs of parentheses, write a function to <em>generate all combinations of well-formed parentheses</em>.</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: n &#x3D; 3</span><br><span class="line">Output: [&quot;((()))&quot;,&quot;(()())&quot;,&quot;(())()&quot;,&quot;()(())&quot;,&quot;()()()&quot;]</span><br></pre></td></tr></table></figure>

<p><strong>Example 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Input: n &#x3D; 1</span><br><span class="line">Output: [&quot;()&quot;]</span><br></pre></td></tr></table></figure>



<p><strong>Constraints:</strong></p>
<ul>
<li><code>1 &lt;= n &lt;= 8</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2 ==&gt; 4 symbols</span></span><br><span class="line"><span class="comment"># (()), ()()</span></span><br><span class="line"><span class="comment"># ((((, ((()</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateParenthesis</span><span class="params">(self, n: int)</span> -&gt; List[str]:</span></span><br><span class="line">        <span class="comment"># self.res = []</span></span><br><span class="line">        <span class="comment"># self.helper(n, n, n, "")</span></span><br><span class="line">        <span class="comment"># return self.res</span></span><br><span class="line">        res = []</span><br><span class="line">        self.dfs_20220604(n, <span class="number">0</span>, <span class="number">0</span>, [], res)</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">dfs_20220604</span><span class="params">(self, n, l, r, item, res)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> l == n <span class="keyword">and</span> r == n:</span><br><span class="line">            res.append(<span class="string">''</span>.join(item[:]))</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> l &lt; r:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> l &lt; n:</span><br><span class="line">            item.append(<span class="string">'('</span>)</span><br><span class="line">            self.dfs_20220604(n, l + <span class="number">1</span>, r, item, res)</span><br><span class="line">            item.pop()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> r &lt; n:</span><br><span class="line">            item.append(<span class="string">')'</span>)</span><br><span class="line">            self.dfs_20220604(n, l, r + <span class="number">1</span>, item, res)</span><br><span class="line">            item.pop()</span><br></pre></td></tr></table></figure>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/04/09/jupyter-demo/2020-04-09-SNPS%20stock%20prediction/">jupyter-demo/2020-04-09-SNPS stock prediction</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-09</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Jupy-Demo/">Jupy-Demo</a></span><div class="content"><iframe
src="https://nbviewer.jupyter.org/github/Joecth/Joecth.github.io/blob/hexo-melody/source/_posts/jupyter-demo/stock_pred_w_RNN/rnn_stock.ipynb" width="100%" height="1000">
</iframe>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/03/28/NLP/2020-03-28-NLP_nltk_0/">NLP/2020-03-28-NLP_nltk_0</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-28</time><div class="content"><h3 id="Text-Preprocessing"><a href="#Text-Preprocessing" class="headerlink" title="Text Preprocessing"></a>Text Preprocessing</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># regex for removing punctuation!</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># nltk preprocessing magic</span></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="comment"># grabbing a part of speech function:</span></span><br><span class="line"><span class="keyword">from</span> part_of_speech <span class="keyword">import</span> get_part_of_speech</span><br><span class="line"></span><br><span class="line">text = <span class="string">"So many squids are jumping out of suitcases these days that you can barely go anywhere without seeing one burst forth from a tightly packed valise. I went to the dentist the other day, and sure enough I saw an angry one jump out of my dentist's bag within minutes of arriving. She hardly even noticed."</span></span><br><span class="line"></span><br><span class="line">cleaned = re.sub(<span class="string">'\W+'</span>, <span class="string">' '</span>, text)</span><br><span class="line">tokenized = word_tokenize(cleaned)</span><br><span class="line"></span><br><span class="line">stemmer = PorterStemmer()</span><br><span class="line">stemmed = [stemmer.stem(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokenized]</span><br><span class="line"></span><br><span class="line"><span class="comment">## -- CHANGE these -- ##</span></span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line">lemmatized = [lemmatizer.lemmatize(token, get_part_of_speech(token)) <span class="keyword">for</span> token <span class="keyword">in</span> tokenized]</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Stemmed text:"</span>)</span><br><span class="line">print(stemmed)</span><br><span class="line">print(<span class="string">"\nLemmatized text:"</span>)</span><br><span class="line">print(lemmatized)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Stemmed text:</span><br><span class="line">[<span class="string">'So'</span>, <span class="string">'mani'</span>, <span class="string">'squid'</span>, <span class="string">'are'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'suitcas'</span>, <span class="string">'these'</span>, <span class="string">'day'</span>, <span class="string">'that'</span>, <span class="string">'you'</span>, <span class="string">'can'</span>, <span class="string">'bare'</span>, <span class="string">'go'</span>, <span class="string">'anywher'</span>, <span class="string">'without'</span>, <span class="string">'see'</span>, <span class="string">'one'</span>, <span class="string">'burst'</span>, <span class="string">'forth'</span>, <span class="string">'from'</span>, <span class="string">'a'</span>, <span class="string">'tightli'</span>, <span class="string">'pack'</span>, <span class="string">'valis'</span>, <span class="string">'I'</span>, <span class="string">'went'</span>, <span class="string">'to'</span>, <span class="string">'the'</span>, <span class="string">'dentist'</span>, <span class="string">'the'</span>, <span class="string">'other'</span>, <span class="string">'day'</span>, <span class="string">'and'</span>, <span class="string">'sure'</span>, <span class="string">'enough'</span>, <span class="string">'I'</span>, <span class="string">'saw'</span>, <span class="string">'an'</span>, <span class="string">'angri'</span>, <span class="string">'one'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'my'</span>, <span class="string">'dentist'</span>, <span class="string">'s'</span>, <span class="string">'bag'</span>, <span class="string">'within'</span>, <span class="string">'minut'</span>, <span class="string">'of'</span>, <span class="string">'arriv'</span>, <span class="string">'she'</span>, <span class="string">'hardli'</span>, <span class="string">'even'</span>, <span class="string">'notic'</span>]</span><br><span class="line"></span><br><span class="line">Lemmatized text:</span><br><span class="line">[<span class="string">'So'</span>, <span class="string">'many'</span>, <span class="string">'squid'</span>, <span class="string">'be'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'suitcase'</span>, <span class="string">'these'</span>, <span class="string">'day'</span>, <span class="string">'that'</span>, <span class="string">'you'</span>, <span class="string">'can'</span>, <span class="string">'barely'</span>, <span class="string">'go'</span>, <span class="string">'anywhere'</span>, <span class="string">'without'</span>, <span class="string">'see'</span>, <span class="string">'one'</span>, <span class="string">'burst'</span>, <span class="string">'forth'</span>, <span class="string">'from'</span>, <span class="string">'a'</span>, <span class="string">'tightly'</span>, <span class="string">'pack'</span>, <span class="string">'valise'</span>, <span class="string">'I'</span>, <span class="string">'go'</span>, <span class="string">'to'</span>, <span class="string">'the'</span>, <span class="string">'dentist'</span>, <span class="string">'the'</span>, <span class="string">'other'</span>, <span class="string">'day'</span>, <span class="string">'and'</span>, <span class="string">'sure'</span>, <span class="string">'enough'</span>, <span class="string">'I'</span>, <span class="string">'saw'</span>, <span class="string">'an'</span>, <span class="string">'angry'</span>, <span class="string">'one'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'my'</span>, <span class="string">'dentist'</span>, <span class="string">'s'</span>, <span class="string">'bag'</span>, <span class="string">'within'</span>, <span class="string">'minute'</span>, <span class="string">'of'</span>, <span class="string">'arrive'</span>, <span class="string">'She'</span>, <span class="string">'hardly'</span>, <span class="string">'even'</span>, <span class="string">'notice'</span>]</span><br></pre></td></tr></table></figure>



<h3 id="Parsing-Text"><a href="#Parsing-Text" class="headerlink" title="Parsing Text"></a>Parsing Text</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> Tree</span><br><span class="line"><span class="keyword">from</span> squids <span class="keyword">import</span> squids_text</span><br><span class="line"></span><br><span class="line">dependency_parser = spacy.load(<span class="string">'en'</span>)</span><br><span class="line"></span><br><span class="line">parsed_squids = dependency_parser(squids_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assign my_sentence a new value:</span></span><br><span class="line">my_sentence = <span class="string">"Your sentence goes here!"</span></span><br><span class="line">my_parsed_sentence = dependency_parser(my_sentence)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_nltk_tree</span><span class="params">(node)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> node.n_lefts + node.n_rights &gt; <span class="number">0</span>:</span><br><span class="line">    parsed_child_nodes = [to_nltk_tree(child) <span class="keyword">for</span> child <span class="keyword">in</span> node.children]</span><br><span class="line">    <span class="keyword">return</span> Tree(node.orth_, parsed_child_nodes)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> node.orth_</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> parsed_squids.sents:</span><br><span class="line">  to_nltk_tree(sent.root).pretty_print()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> my_parsed_sentence.sents:</span><br><span class="line"> to_nltk_tree(sent.root).pretty_print()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">        jumping                       </span><br><span class="line">  _________|_______________________    </span><br><span class="line"> |   |     |      |       out      |  </span><br><span class="line"> |   |     |      |        |       |   </span><br><span class="line"> |   |     |    squids     of     days</span><br><span class="line"> |   |     |      |        |       |   </span><br><span class="line"> So are    .     many  suitcases these</span><br><span class="line"></span><br><span class="line">          go                       </span><br><span class="line">  ________|____________________     </span><br><span class="line"> |   |    |       |      |  without</span><br><span class="line"> |   |    |       |      |     |    </span><br><span class="line"> |   |    |       |      |   seeing</span><br><span class="line"> |   |    |       |      |     |    </span><br><span class="line">You can barely anywhere  .    one  </span><br><span class="line"></span><br><span class="line">          went               </span><br><span class="line">  _________|_________         </span><br><span class="line"> |   |     to        |       </span><br><span class="line"> |   |     |         |        </span><br><span class="line"> |   |  dentist     day      </span><br><span class="line"> |   |     |      ___|____    </span><br><span class="line"> I   .    the   the     other</span><br><span class="line"></span><br><span class="line">             saw                                     </span><br><span class="line">  ____________|___________________                    </span><br><span class="line"> |   |   |    |                  jump                </span><br><span class="line"> |   |   |    |          _________|__________         </span><br><span class="line"> |   |   |    |         |                   out      </span><br><span class="line"> |   |   |    |         |                    |        </span><br><span class="line"> |   |   |    |         |                    of      </span><br><span class="line"> |   |   |    |         |                    |        </span><br><span class="line"> |   |   |    |         |                   bag      </span><br><span class="line"> |   |   |    |         |                    |        </span><br><span class="line"> |   |   |  enough     one                dentist    </span><br><span class="line"> |   |   |    |      ___|____           _____|_____   </span><br><span class="line"> ,   I   .   Sure   an     angry       my          <span class="string">'s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    noticed         </span></span><br><span class="line"><span class="string">  _____|__________   </span></span><br><span class="line"><span class="string">She  hardly even  . </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     goes         </span></span><br><span class="line"><span class="string">  ____|______      </span></span><br><span class="line"><span class="string"> |    |   sentence</span></span><br><span class="line"><span class="string"> |    |      |     </span></span><br><span class="line"><span class="string">here  !     Your</span></span><br></pre></td></tr></table></figure>



<h3 id="Language-Models-Bag-of-Words-Approach"><a href="#Language-Models-Bag-of-Words-Approach" class="headerlink" title="Language Models - Bag-of-Words Approach"></a>Language Models - Bag-of-Words Approach</h3><p>When grammar and word order are irrelevant, this is probably a good model to use.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># importing regex and nltk</span></span><br><span class="line"><span class="keyword">import</span> re, nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="comment"># importing Counter to get word counts for bag of words</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="comment"># importing a passage from Through the Looking Glass</span></span><br><span class="line"><span class="keyword">from</span> looking_glass <span class="keyword">import</span> looking_glass_text</span><br><span class="line"><span class="comment"># importing part-of-speech function for lemmatization</span></span><br><span class="line"><span class="keyword">from</span> part_of_speech <span class="keyword">import</span> get_part_of_speech</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change text to another string:</span></span><br><span class="line"><span class="comment"># text = looking_glass_text</span></span><br><span class="line">text = <span class="string">"hello world i miss you"</span></span><br><span class="line"></span><br><span class="line">cleaned = re.sub(<span class="string">'\W+'</span>, <span class="string">' '</span>, text).lower()</span><br><span class="line">tokenized = word_tokenize(cleaned)</span><br><span class="line"></span><br><span class="line">stop_words = stopwords.words(<span class="string">'english'</span>)</span><br><span class="line">filtered = [word <span class="keyword">for</span> word <span class="keyword">in</span> tokenized <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stop_words]</span><br><span class="line"></span><br><span class="line">normalizer = WordNetLemmatizer()</span><br><span class="line">normalized = [normalizer.lemmatize(token, get_part_of_speech(token)) <span class="keyword">for</span> token <span class="keyword">in</span> filtered]</span><br><span class="line"><span class="comment"># Comment out the print statement below</span></span><br><span class="line">print(normalized)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define bag_of_looking_glass_words &amp; print:</span></span><br><span class="line">bag_of_looking_glass_words = Counter(normalized)</span><br><span class="line">print(bag_of_looking_glass_words)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'hello'</span>, <span class="string">'world'</span>, <span class="string">'miss'</span>]</span><br><span class="line">Counter(&#123;<span class="string">'hello'</span>: 1, <span class="string">'world'</span>: 1, <span class="string">'miss'</span>: 1&#125;)</span><br></pre></td></tr></table></figure>



<h3 id="Language-Models-N-Grams-and-NLM"><a href="#Language-Models-N-Grams-and-NLM" class="headerlink" title="Language Models - N-Grams and NLM"></a>Language Models - N-Grams and NLM</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk, re</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="comment"># importing ngrams module from nltk</span></span><br><span class="line"><span class="keyword">from</span> nltk.util <span class="keyword">import</span> ngrams</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> looking_glass <span class="keyword">import</span> looking_glass_full_text</span><br><span class="line"></span><br><span class="line">cleaned = re.sub(<span class="string">'\W+'</span>, <span class="string">' '</span>, looking_glass_full_text).lower()</span><br><span class="line">tokenized = word_tokenize(cleaned)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the n value to 2:</span></span><br><span class="line">looking_glass_bigrams = ngrams(tokenized, <span class="number">2</span>)</span><br><span class="line">looking_glass_bigrams_frequency = Counter(looking_glass_bigrams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the n value to 3:</span></span><br><span class="line">looking_glass_trigrams = ngrams(tokenized, <span class="number">3</span>)</span><br><span class="line">looking_glass_trigrams_frequency = Counter(looking_glass_trigrams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the n value to a number greater than 3:</span></span><br><span class="line">looking_glass_ngrams = ngrams(tokenized, <span class="number">4</span>)</span><br><span class="line">looking_glass_ngrams_frequency = Counter(looking_glass_ngrams)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Looking Glass Bigrams:"</span>)</span><br><span class="line">print(looking_glass_bigrams_frequency.most_common(<span class="number">10</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\nLooking Glass Trigrams:"</span>)</span><br><span class="line">print(looking_glass_trigrams_frequency.most_common(<span class="number">10</span>), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">3</span></span><br><span class="line">print(<span class="string">"\nLooking Glass n-grams:"</span>)</span><br><span class="line">print(looking_glass_ngrams_frequency.most_common(<span class="number">10</span>), <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Looking Glass Bigrams:</span><br><span class="line">[((<span class="string">'of'</span>, <span class="string">'the'</span>), 101), ((<span class="string">'said'</span>, <span class="string">'the'</span>), 98), ((<span class="string">'in'</span>, <span class="string">'a'</span>), 97), ((<span class="string">'in'</span>, <span class="string">'the'</span>), 90), ((<span class="string">'as'</span>, <span class="string">'she'</span>), 82), ((<span class="string">'you'</span>, <span class="string">'know'</span>), 72), ((<span class="string">'a'</span>, <span class="string">'little'</span>), 68), ((<span class="string">'the'</span>, <span class="string">'queen'</span>), 67), ((<span class="string">'said'</span>, <span class="string">'alice'</span>), 67), ((<span class="string">'to'</span>, <span class="string">'the'</span>), 66)] 2</span><br><span class="line"></span><br><span class="line">Looking Glass Trigrams:</span><br><span class="line">[((<span class="string">'the'</span>, <span class="string">'red'</span>, <span class="string">'queen'</span>), 54), ((<span class="string">'the'</span>, <span class="string">'white'</span>, <span class="string">'queen'</span>), 31), ((<span class="string">'said'</span>, <span class="string">'in'</span>, <span class="string">'a'</span>), 21), ((<span class="string">'she'</span>, <span class="string">'went'</span>, <span class="string">'on'</span>), 18), ((<span class="string">'said'</span>, <span class="string">'the'</span>, <span class="string">'red'</span>), 17), ((<span class="string">'thought'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 16), ((<span class="string">'the'</span>, <span class="string">'queen'</span>, <span class="string">'said'</span>), 16), ((<span class="string">'said'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 14), ((<span class="string">'said'</span>, <span class="string">'humpty'</span>, <span class="string">'dumpty'</span>), 14), ((<span class="string">'the'</span>, <span class="string">'knight'</span>, <span class="string">'said'</span>), 14)] 3</span><br><span class="line"></span><br><span class="line">Looking Glass n-grams:</span><br><span class="line">[((<span class="string">'said'</span>, <span class="string">'the'</span>, <span class="string">'red'</span>, <span class="string">'queen'</span>), 15), ((<span class="string">'she'</span>, <span class="string">'said'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 11), ((<span class="string">'alice'</span>, <span class="string">'thought'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 9), ((<span class="string">'to'</span>, <span class="string">'herself'</span>, <span class="string">'as'</span>, <span class="string">'she'</span>), 9), ((<span class="string">'one'</span>, <span class="string">'and'</span>, <span class="string">'one'</span>, <span class="string">'and'</span>), 8), ((<span class="string">'and'</span>, <span class="string">'one'</span>, <span class="string">'and'</span>, <span class="string">'one'</span>), 8), ((<span class="string">'alice'</span>, <span class="string">'said'</span>, <span class="string">'in'</span>, <span class="string">'a'</span>), 6), ((<span class="string">'for'</span>, <span class="string">'a'</span>, <span class="string">'minute'</span>, <span class="string">'or'</span>), 6), ((<span class="string">'a'</span>, <span class="string">'minute'</span>, <span class="string">'or'</span>, <span class="string">'two'</span>), 6), ((<span class="string">'in'</span>, <span class="string">'a'</span>, <span class="string">'tone'</span>, <span class="string">'of'</span>), 6)] 5</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk, re</span><br><span class="line"><span class="keyword">from</span> sherlock_holmes <span class="keyword">import</span> bohemia_ch1, bohemia_ch2, bohemia_ch3, boscombe_ch1, boscombe_ch2, boscombe_ch3</span><br><span class="line"><span class="keyword">from</span> preprocessing <span class="keyword">import</span> preprocess_text</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer, TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> LatentDirichletAllocation</span><br><span class="line"></span><br><span class="line"><span class="comment"># preparing the text</span></span><br><span class="line">corpus = [bohemia_ch1, bohemia_ch2, bohemia_ch3, boscombe_ch1, boscombe_ch2, boscombe_ch3]</span><br><span class="line">preprocessed_corpus = [preprocess_text(chapter) <span class="keyword">for</span> chapter <span class="keyword">in</span> corpus]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update stop_list:</span></span><br><span class="line">stop_list = []</span><br><span class="line"><span class="comment"># filtering topics for stop words</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_out_stop_words</span><span class="params">(corpus)</span>:</span></span><br><span class="line">  no_stops_corpus = []</span><br><span class="line">  <span class="keyword">for</span> chapter <span class="keyword">in</span> corpus:</span><br><span class="line">    no_stops_chapter = <span class="string">" "</span>.join([word <span class="keyword">for</span> word <span class="keyword">in</span> chapter.split(<span class="string">" "</span>) <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stop_list])</span><br><span class="line">    no_stops_corpus.append(no_stops_chapter)</span><br><span class="line">  <span class="keyword">return</span> no_stops_corpus</span><br><span class="line">filtered_for_stops = filter_out_stop_words(preprocessed_corpus)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the bag of words model</span></span><br><span class="line">bag_of_words_creator = CountVectorizer()</span><br><span class="line">bag_of_words = bag_of_words_creator.fit_transform(filtered_for_stops)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the tf-idf model</span></span><br><span class="line">tfidf_creator = TfidfVectorizer(min_df = <span class="number">0.2</span>)</span><br><span class="line">tfidf = tfidf_creator.fit_transform(preprocessed_corpus)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the bag of words LDA model</span></span><br><span class="line">lda_bag_of_words_creator = LatentDirichletAllocation(learning_method=<span class="string">'online'</span>, n_components=<span class="number">10</span>)</span><br><span class="line">lda_bag_of_words = lda_bag_of_words_creator.fit_transform(bag_of_words)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the tf-idf LDA model</span></span><br><span class="line">lda_tfidf_creator = LatentDirichletAllocation(learning_method=<span class="string">'online'</span>, n_components=<span class="number">10</span>)</span><br><span class="line">lda_tfidf = lda_tfidf_creator.fit_transform(tfidf)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"~~~ Topics found by bag of words LDA ~~~"</span>)</span><br><span class="line"><span class="keyword">for</span> topic_id, topic <span class="keyword">in</span> enumerate(lda_bag_of_words_creator.components_):</span><br><span class="line">  message = <span class="string">"Topic #&#123;&#125;: "</span>.format(topic_id + <span class="number">1</span>)</span><br><span class="line">  message += <span class="string">" "</span>.join([bag_of_words_creator.get_feature_names()[i] <span class="keyword">for</span> i <span class="keyword">in</span> topic.argsort()[:<span class="number">-5</span> :<span class="number">-1</span>]])</span><br><span class="line">  print(message)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\n\n~~~ Topics found by tf-idf LDA ~~~"</span>)</span><br><span class="line"><span class="keyword">for</span> topic_id, topic <span class="keyword">in</span> enumerate(lda_tfidf_creator.components_):</span><br><span class="line">  message = <span class="string">"Topic #&#123;&#125;: "</span>.format(topic_id + <span class="number">1</span>)</span><br><span class="line">  message += <span class="string">" "</span>.join([tfidf_creator.get_feature_names()[i] <span class="keyword">for</span> i <span class="keyword">in</span> topic.argsort()[:<span class="number">-5</span> :<span class="number">-1</span>]])</span><br><span class="line">  print(message)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">~~~ Topics found by bag of words LDA ~~~</span><br><span class="line">Topic <span class="comment">#1: holmes say little upon</span></span><br><span class="line">Topic <span class="comment">#2: house come could man</span></span><br><span class="line">Topic <span class="comment">#3: holmes say know come</span></span><br><span class="line">Topic <span class="comment">#4: holmes would say know</span></span><br><span class="line">Topic <span class="comment">#5: say holmes know see</span></span><br><span class="line">Topic <span class="comment">#6: say holmes man could</span></span><br><span class="line">Topic <span class="comment">#7: say upon mccarthy man</span></span><br><span class="line">Topic <span class="comment">#8: make holmes cry majesty</span></span><br><span class="line">Topic <span class="comment">#9: holmes say man upon</span></span><br><span class="line">Topic <span class="comment">#10: upon holmes see say</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">~~~ Topics found by tf-idf LDA ~~~</span><br><span class="line">Topic <span class="comment">#1: merely upon boot catch</span></span><br><span class="line">Topic <span class="comment">#2: boot save holmes mccarthy</span></span><br><span class="line">Topic <span class="comment">#3: norton resolve help refer</span></span><br><span class="line">Topic <span class="comment">#4: leave remove three lodge</span></span><br><span class="line">Topic <span class="comment">#5: say neck resolute stone</span></span><br><span class="line">Topic <span class="comment">#6: holmes king majesty photograph</span></span><br><span class="line">Topic <span class="comment">#7: fear together heavy upon</span></span><br><span class="line">Topic <span class="comment">#8: holmes say know man</span></span><br><span class="line">Topic <span class="comment">#9: figure surround definite heel</span></span><br><span class="line">Topic <span class="comment">#10: know many swiftly scotland</span></span><br></pre></td></tr></table></figure>



<h3 id="Text-Similarity"><a href="#Text-Similarity" class="headerlink" title="Text Similarity"></a>Text Similarity</h3><p>Most of us have a good autocorrect story. Our phone’s messenger quietly swaps one letter for another as we type and suddenly the meaning of our message has changed (to our horror or pleasure). However, addressing <strong><em>text similarity\</em></strong> — including spelling correction — is a major challenge within natural language processing.</p>
<p>Addressing word similarity and misspelling for spellcheck or autocorrect often involves considering the <strong><em>Levenshtein distance\</em></strong> or minimal edit distance between two words. The distance is calculated through the minimum number of insertions, deletions, and substitutions that would need to occur for one word to become another. For example, turning “bees” into “beans” would require one substitution (“a” for “e”) and one insertion (“n”), so the Levenshtein distance would be two.</p>
<p>Phonetic similarity is also a major challenge within speech recognition. English-speaking humans can easily tell from context whether someone said “euthanasia” or “youth in Asia,” but it’s a far more challenging task for a machine! More advanced autocorrect and spelling correction technology additionally considers key distance on a keyboard and <strong><em>phonetic similarity\</em></strong> (how much two words or phrases sound the same).</p>
<p>It’s also helpful to find out if texts are the same to guard against plagiarism, which we can identify through <strong><em>lexical similarity\</em></strong> (the degree to which texts use the same vocabulary and phrases). Meanwhile, <strong><em>semantic similarity\</em></strong> (the degree to which documents contain similar meaning or topics) is useful when you want to find (or recommend) an article or book similar to one you recently finished.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="comment"># NLTK has a built-in function</span></span><br><span class="line"><span class="comment"># to check Levenshtein distance:</span></span><br><span class="line"><span class="keyword">from</span> nltk.metrics <span class="keyword">import</span> edit_distance</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_levenshtein</span><span class="params">(string1, string2)</span>:</span></span><br><span class="line">  print(<span class="string">"The Levenshtein distance from '&#123;0&#125;' to '&#123;1&#125;' is &#123;2&#125;!"</span>.format(string1, string2, edit_distance(string1, string2)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the distance between</span></span><br><span class="line"><span class="comment"># any two words here!</span></span><br><span class="line">print_levenshtein(<span class="string">"fart"</span>, <span class="string">"target"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assign passing strings here:</span></span><br><span class="line">three_away_from_code = <span class="string">"cat"</span></span><br><span class="line"></span><br><span class="line">two_away_from_chunk = <span class="string">"cheek"</span></span><br><span class="line"></span><br><span class="line">print_levenshtein(<span class="string">"code"</span>, three_away_from_code)</span><br><span class="line">print_levenshtein(<span class="string">"chunk"</span>, two_away_from_chunk)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The Levenshtein distance from <span class="string">'fart'</span> to <span class="string">'target'</span> is 3!</span><br><span class="line">The Levenshtein distance from <span class="string">'code'</span> to <span class="string">'cat'</span> is 3!</span><br><span class="line">The Levenshtein distance from <span class="string">'chunk'</span> to <span class="string">'cheek'</span> is 2!</span><br></pre></td></tr></table></figure>



<h3 id="Language-Prediction-amp-Text-Generation"><a href="#Language-Prediction-amp-Text-Generation" class="headerlink" title="Language Prediction &amp; Text Generation"></a>Language Prediction &amp; Text Generation</h3><p>How does your favorite search engine complete your search queries? How does your phone’s keyboard know what you want to type next? <strong><em>Language prediction\</em></strong> is an application of NLP concerned with predicting text given preceding text. Autosuggest, autocomplete, and suggested replies are common forms of language prediction.</p>
<p>Your first step to language prediction is picking a language model. Bag of words alone is generally not a great model for language prediction; no matter what the preceding word was, you will just get one of the most commonly used words from your training corpus.</p>
<p>If you go the <em>n</em>-gram route, you will most likely rely on <strong><em>Markov chains\</em></strong> to predict the statistical likelihood of each following word (or character) based on the training corpus. Markov chains are memory-less and make statistical predictions based entirely on the current <em>n</em>-gram on hand.</p>
<p>For example, let’s take a sentence beginning, “I ate so many grilled cheese”. Using a trigram model (where <em>n</em> is 3), a Markov chain would predict the following word as “sandwiches” based on the number of times the sequence “grilled cheese sandwiches” has appeared in the training data out of all the times “grilled cheese” has appeared in the training data.</p>
<p>A more advanced approach, using a neural language model, is the <strong><em>Long Short Term Memory (LSTM)\</em></strong> model. LSTM uses deep learning with a network of artificial “cells” that manage memory, making them better suited for text prediction than traditional neural networks.</p>
<p><strong>1.</strong></p>
<p>Add three short stories by your favorite author or the lyrics to three songs by your favorite artist to <strong>document1.py</strong>, <strong>document2.py</strong>, and <strong>document3.py</strong>. Then run <strong>script.py</strong> to see a short example of text prediction.</p>
<p>Does it look like something by your favorite author or artist?</p>
<p>If you accidentally close one of the files, just click the file folder in the top left corner of the code editor to find the file and re-open it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk, re, random</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict, deque</span><br><span class="line"><span class="keyword">from</span> document1 <span class="keyword">import</span> training_doc1</span><br><span class="line"><span class="keyword">from</span> document2 <span class="keyword">import</span> training_doc2</span><br><span class="line"><span class="keyword">from</span> document3 <span class="keyword">import</span> training_doc3</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MarkovChain</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.lookup_dict = defaultdict(list)</span><br><span class="line">    self._seeded = <span class="literal">False</span></span><br><span class="line">    self.__seed_me()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__seed_me</span><span class="params">(self, rand_seed=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self._seeded <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">True</span>:</span><br><span class="line">      <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> rand_seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          random.seed(rand_seed)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          random.seed()</span><br><span class="line">        self._seeded = <span class="literal">True</span></span><br><span class="line">      <span class="keyword">except</span> NotImplementedError:</span><br><span class="line">        self._seeded = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add_document</span><span class="params">(self, str)</span>:</span></span><br><span class="line">    preprocessed_list = self._preprocess(str)</span><br><span class="line">    pairs = self.__generate_tuple_keys(preprocessed_list)</span><br><span class="line">    <span class="keyword">for</span> pair <span class="keyword">in</span> pairs:</span><br><span class="line">      self.lookup_dict[pair[<span class="number">0</span>]].append(pair[<span class="number">1</span>])</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_preprocess</span><span class="params">(self, str)</span>:</span></span><br><span class="line">    cleaned = re.sub(<span class="string">r'\W+'</span>, <span class="string">' '</span>, str).lower()</span><br><span class="line">    tokenized = word_tokenize(cleaned)</span><br><span class="line">    <span class="keyword">return</span> tokenized</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__generate_tuple_keys</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(data) &lt; <span class="number">1</span>:</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data) - <span class="number">1</span>):</span><br><span class="line">      <span class="keyword">yield</span> [ data[i], data[i + <span class="number">1</span>] ]</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">generate_text</span><span class="params">(self, max_length=<span class="number">50</span>)</span>:</span></span><br><span class="line">    context = deque()</span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">if</span> len(self.lookup_dict) &gt; <span class="number">0</span>:</span><br><span class="line">      self.__seed_me(rand_seed=len(self.lookup_dict))</span><br><span class="line">      chain_head = [list(self.lookup_dict)[<span class="number">0</span>]]</span><br><span class="line">      context.extend(chain_head)</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">while</span> len(output) &lt; (max_length - <span class="number">1</span>):</span><br><span class="line">        next_choices = self.lookup_dict[context[<span class="number">-1</span>]]</span><br><span class="line">        <span class="keyword">if</span> len(next_choices) &gt; <span class="number">0</span>:</span><br><span class="line">          next_word = random.choice(next_choices)</span><br><span class="line">          context.append(next_word)</span><br><span class="line">          output.append(context.popleft())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">break</span></span><br><span class="line">      output.extend(list(context))</span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(output)</span><br><span class="line"></span><br><span class="line">my_markov = MarkovChain()</span><br><span class="line">my_markov.add_document(training_doc1)</span><br><span class="line">my_markov.add_document(training_doc2)</span><br><span class="line">my_markov.add_document(training_doc3)</span><br><span class="line">generated_text = my_markov.generate_text()</span><br><span class="line">print(generated_text)</span><br></pre></td></tr></table></figure>

</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/11/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/77/">77</a><a class="extend next" rel="next" href="/page/13/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>