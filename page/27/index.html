<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">399</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">70</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Awaken Desparado</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/12/Python/2019-12-12-MapReduce/">Python/2019-12-12-MapReduce</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-12</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/BigData-Python/">BigData, Python</a></span><div class="content"><p>Ref: <a href="https://zhuanlan.zhihu.com/p/62135686" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/62135686</a></p>
<h1 id="Ref1"><a href="#Ref1" class="headerlink" title="Ref1"></a>Ref1</h1><h2 id="一、MapReduce是什么"><a href="#一、MapReduce是什么" class="headerlink" title="一、MapReduce是什么"></a>一、MapReduce是什么</h2><ol>
<li>MapReduce是一种分布式计算框架 ，以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。主要用于搜索领域，解决海量数据的计算问题。</li>
<li>MR有两个阶段组成：Map和Reduce，用户只需实现map()和reduce()两个函数，即可实现分布式计算。</li>
</ol>
<h2 id="二、MapReduce做什么"><a href="#二、MapReduce做什么" class="headerlink" title="二、MapReduce做什么"></a>二、MapReduce做什么</h2><ol>
<li>MapReduce框架由Map和Reduce组成。</li>
<li>Map()负责把一个大的block块进行切片并计算。</li>
<li>Reduce() 负责把Map()切片的数据进行汇总、计算。</li>
</ol>
<h2 id="三、MapReduce怎么做"><a href="#三、MapReduce怎么做" class="headerlink" title="三、MapReduce怎么做"></a>三、MapReduce怎么做</h2><p><img src="https://pic1.zhimg.com/80/v2-956054759aea4352a795452e31754ef0_hd.jpg" alt="img"></p>
<ol>
<li>第一步对输入的数据进行切片，每个切片分配一个map()任务，map()对其中的数据进行计算，对每个数据用键值对的形式记录，然后输出到环形缓冲区（图中sort的位置）。</li>
<li>map（）中输出的数据在环形缓冲区内进行快排，每个环形缓冲区默认大小100M，当数据达到80M时（默认），把数据输出到磁盘上。形成很多个内部有序整体无序的小文件。</li>
<li>框架把磁盘中的小文件传到Reduce()中来，然后进行归并排序，最终输出。</li>
</ol>
<h2 id="四、要点是什么"><a href="#四、要点是什么" class="headerlink" title="四、要点是什么"></a>四、要点是什么</h2><ol>
<li>MapReduce将输入的数据进行逻辑切片，一片对应一个Map任务</li>
<li>Map以并行的方式处理切片</li>
<li>框架对Map输出进行排序，然后发给Reduce</li>
<li>MapReduce的输入输出数据处于同一个文件系统（HDFS）</li>
<li>框架负责任务调度、任务监控、失败任务的重新执行</li>
<li>框架会对键和值进行序列化，因此键和值需要实现writable接口，框架会对键排序，因此必须实现writableComparable接口。</li>
</ol>
<h2 id="五、MapReduce原语"><a href="#五、MapReduce原语" class="headerlink" title="五、MapReduce原语"></a>五、MapReduce原语</h2><p>MapReduce原语：“相同”key的键值对为一组调用一次Reduce方法，方法内迭代这组数据进行计算。</p>
<h1 id="Ref2"><a href="#Ref2" class="headerlink" title="Ref2"></a>Ref2</h1><p><a href="https://www.jianshu.com/p/6b6a42a0740c" target="_blank" rel="noopener">https://www.jianshu.com/p/6b6a42a0740c</a></p>
<h5 id="1-mapreduce-简介"><a href="#1-mapreduce-简介" class="headerlink" title="1. mapreduce 简介"></a>1. mapreduce 简介</h5><p>mapreduce源自google的一篇文章，将海量数据处理的过程拆分为map和reduce。mapreduce 成为了最早的分布式计算框架，这样即使不懂的分布式计算框架的内部运行机制的用户，也可以利用分布式的计算框架实现分布式的计算，并在hadoop上面运行。</p>
<h5 id="1-设计思想"><a href="#1-设计思想" class="headerlink" title="1. 设计思想"></a>1. 设计思想</h5><p>hadoop 文件系统 ，提供了一个分布式的文件系统，但是hadoop文件系统读写的操作都涉及到大量的网络的操作，并不能很好的完成实时性比较强的任务。</p>
<p>但是hadoop可以给上面的应用提供一个很好的支持。比如hadoop文件系统上面可以运行mapreduce。mapreduce是一个计算的框架，mapreduce是一个分布式的计算框架，这样mapreduce利用分布式的文件系统，将不同的机器上完成不同的计算，然后就计算结果返回。这样很好的利用了分布式的文件系统。</p>
<p>数据分布式的存储，然后计算的时候，分布式的计算，然后将结果返回。这样的好处就是不会涉及到大量的网络传输数据。</p>
<p>不知道在哪里看见一句话，觉得很好，记了下来。大数据设计的一个基本的思想是<strong>将计算的任务推送到数据所在的地方，而不是反过来。</strong></p>
<h5 id="2-Mapreduce-的架构"><a href="#2-Mapreduce-的架构" class="headerlink" title="2. Mapreduce 的架构"></a>2. Mapreduce 的架构</h5><p>mrappmaster（管理节点）<br> Maptask（多个）<br> reducetask（多个）</p>
<p>mapreduce 的计算过程，举一个例子 wordcount （单词计数的例子）比如说有一个文件 ，文件内容：</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">good better best never it rest </span><br><span class="line">till good <span class="keyword">is</span> better and better <span class="keyword">is</span> best</span><br></pre></td></tr></table></figure>

<p>那么第一步 先map，map的流程是，将单词以空格来切分，然后建立一个key-value的map。</p>
<p>得到的结果是：</p>
<figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">good    <span class="number">1</span></span><br><span class="line">better  <span class="number">1</span></span><br><span class="line">best    <span class="number">1</span></span><br><span class="line">never   <span class="number">1</span></span><br><span class="line">it      <span class="number">1</span></span><br><span class="line">rest    <span class="number">1</span></span><br><span class="line">till    <span class="number">1</span></span><br><span class="line">good    <span class="number">1</span></span><br><span class="line"><span class="keyword">is</span>      <span class="number">1</span></span><br><span class="line">better  <span class="number">1</span></span><br><span class="line">and     <span class="number">1</span></span><br><span class="line">better  <span class="number">1</span></span><br><span class="line"><span class="keyword">is</span>      <span class="number">1</span></span><br><span class="line">best    <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>上面这个map的结果，相当于给每一个每一个单词都建立一个字典，key就是单词本身，value是个数。</p>
<p>第二步是reduce：<br> reduce是将一致的单词，发送个同一个reduce节点。在同一个reduce节点上面，这个reduce节点，负责将相同的key合并再一起。</p>
<p>这样就完成的单词的计数。</p>
<p><img src="https:////upload-images.jianshu.io/upload_images/4717565-0afa417b7248b948.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/767/format/webp" alt="img"></p>
<p>image.png</p>
<h6 id="这里存在几个问题："><a href="#这里存在几个问题：" class="headerlink" title="这里存在几个问题："></a>这里存在几个问题：</h6><p><strong>Q1:</strong> reduce的方式是将一个类型的key，送给同一个节点。比如说，把good都送给第一个节点。till送给第二个节点。那么如果做到这一点呢？</p>
<p>答：使用hash表的方式，一个key，放在hash表里面，就会产生一个为一个code（java 里面的数据结构是 hashcode），然后再给它取余数。比如机器有四个节点，做reduce，那么就取余4，这样计算的任务就分给四台机器。这个就是shuffl机制。（shuffl就是洗牌的意思）（这个算法其实就是<strong>哈希取模</strong>的算法）</p>
<p><strong>Q2:</strong> map 执行完成之后，中间结果保存在哪里？<br> map函数输出的中间结果key/value数据在内存中进行缓存，然后周期性的写入磁盘。每个map函数在写入磁盘之前，通过哈希函数，将自己的key/value对分割成R份。（R是reduce的个数 哈希函数一般是 用key对r进行哈希取模，这样将map函数的中间数据分割成r份，每一份分给一个reduce）。<strong>当某个reduce任务的worker接收到master的通知，其通过rpc远程调用 将map任务产生的m份属于自己的文件远程拉取到本地。</strong></p>
<p><strong>mapreduce的计算特点以及不足：</strong><br> mapreduce的计算框架的优点是，极强的扩展能力，可以在数千台机器上并发的执行。其次，有很好的容错性，另外，就是向上的接口简洁。用户只需要写map和reduce函数，即可完成大规模数据的并行处理。</p>
<p><strong>mapreduce的缺点：</strong><br> mapreduce并不适合对实时性要求比较高的场景，比如交互式查询或者是流式计算。另外，也不适合迭代类的计算（比如机器学习类的应用）。</p>
<p>原因：<br> mapreduce的启动时间比较长，对于批处理的任务，这个问题并不算大。但是对于实时性比较高的任务，其启动时间长的缺点就很不合适了。</p>
<p>mapreduce一次执行的过程里面，往往涉及到多出磁盘读写，以及网络的传输。对于迭代的任务，这样很好的开销需要很多次，明显降低了效率。</p>
<p>而Storm和Spark，一个是流式计算的框架，一个是机器学习的框架。他们更适合解决这类型的任务。</p>
<p>Demo：<br> 一个利用mapreduce思想单词计数的实例：<a href="https://www.jianshu.com/p/59ebf5a36ee5" target="_blank" rel="noopener">http://www.jianshu.com/p/59ebf5a36ee5</a></p>
<p>参考：</p>
<ol>
<li>google的mapreduce 论文</li>
<li>《hadoop权威指南》</li>
<li>《hadoop 海量数据处理》</li>
</ol>
<p>作者：zhaozhengcoder<br>链接：<a href="https://www.jianshu.com/p/6b6a42a0740c" target="_blank" rel="noopener">https://www.jianshu.com/p/6b6a42a0740c</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/11/CVs/2019-12-11-CNN%20&amp;%20RNN%20Review%20&amp;%20Prep/">CVs/2019-12-11-CNN &amp; RNN Review &amp; Prep</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/CV/">CV</a></span><div class="content"><blockquote>
<p>Two stages: RPN for localization, then classification &amp; bbox regression on proposals</p>
<p>Single shot: classification + bbox regression at one time</p>
</blockquote>
<h3 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h3><ul>
<li><p>~2000 forward passes for each image</p>
</li>
<li><p>Train 3 models seperately</p>
<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdd7ffqcltj30pi0ku17e.jpg" alt="image-20200331164611434" style="zoom:50%;" />
</li>
<li><p>Selective search(texture, adjecent color, and intensity) to clustering pixeles as RPN function, and then feed into AlexNet to extract embeddings. </p>
</li>
<li><p>SVM to classify each bbox into categoies.</p>
</li>
<li><p>linear regression on bbox for tighter bbox.</p>
</li>
</ul>
<h3 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP Net"></a>SPP Net</h3><p>1.結合空間金字塔方法實現CNNs的多尺度輸入。<br>SPP Net的第一個貢獻就是在最後一個卷積層後，接入了金字塔池化層，保證傳到下一層全連線層的輸入固定。<br>換句話說，在普通的CNN機構中，輸入影象的尺寸往往是固定的（比如224*224畫素），輸出則是一個固定維數的向量。SPP Net在普通的CNN結構中加入了ROI池化層（ROI Pooling），使得網路的輸入影象可以是任意尺寸的，輸出則不變，同樣是一個固定維數的向量。</p>
<p>簡言之，CNN原本只能固定輸入、固定輸出，CNN加上SSP之後，便能任意輸入、固定輸出。神奇吧？</p>
<p>ROI池化層一般跟在卷積層後面，此時網路的輸入可以是任意尺度的，在SPP layer中每一個pooling的filter會根據輸入調整大小，而SPP的輸出則是固定維數的向量，然後給到全連線FC層。<br><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdd8d9rgnxj30al0750sy.jpg" alt="img"><br>2.只對原圖提取一次卷積特徵<br>在R-CNN中，每個候選框先resize到統一大小，然後分別作為CNN的輸入，這樣是很低效的。<br>而SPP Net根據這個缺點做了優化：只對原圖進行一次卷積計算，便得到整張圖的卷積特徵feature map，然後找到每個候選框在feature map上的對映patch，將此patch作為每個候選框的卷積特徵輸入到SPP layer和之後的層，完成特徵提取工作。</p>
<p>如此這般，R-CNN要對每個區域計算卷積，而SPPNet只需要計算一次卷積，從而節省了大量的計算時間，比R-CNN有一百倍左右的提速。</p>
<h3 id="Fast"><a href="#Fast" class="headerlink" title="Fast"></a>Fast</h3><ul>
<li><p>ROI pool to share process</p>
</li>
<li><p>Search selective algorithm is computed base on the output feature map of the previous step. Then, ROI pooling layer is used to ensure the standard and pre-defined output size.</p>
</li>
<li><p>These valid outputs are passed to a fully connected layer as inputs. Finally, two output vectors are used to predict the observed object with a softmax classifier and adapt bounding box localisations with a linear regressor.</p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gddbgk1y3dj30in097my5.jpg" alt="img"></p>
</li>
</ul>
<h3 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h3><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdd7vl10thj30om0l8q4a.jpg" alt="image-20200331165148305"></p>
<h4 id="VGG-backbone"><a href="#VGG-backbone" class="headerlink" title="VGG backbone"></a><code>VGG</code> backbone</h4><ul>
<li><p>VGG: Input 224x224, therefore, 224/2^4 = 14, 14x14 for conv-5 (ch-512, same as conv-4),  13 conv, 13 ReLU, 4 Pooling</p>
</li>
<li><p>Faster RCNN’s image size :  ==&gt; 800x600 (image’s input by python ‘s cv2)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># reshape network inputs</span><br><span class="line"> net.blobs[&#39;data&#39;].reshape(*(blobs[&#39;data&#39;].shape))</span><br></pre></td></tr></table></figure>

<p>As we can see, the input blob <code>&#39;data&#39;</code> is reshaped according to the input image size. Once you <code>forward</code> caffe will reshape all consequent blobs according to the input shape；　<code>*</code> means convert passed argument from tuple to positional parameters</p>
</li>
<li><p>RPN: 3x3x512, as each point fuses 3x3 info arounding it. and then calc + &amp; - anchors as well as bbox regression shift, and then calc proposals;</p>
<p><code>ROI Pooling</code> extract <code>proposal feature</code> from <code>feature map</code>for FC and softmax</p>
</li>
<li><p>9 anchors for each point –&gt; + &amp; -</p>
</li>
<li><p>TRAINING: 128 + anchors and 128 - anchors</p>
<ul>
<li>Suitable Anchors:</li>
</ul>
</li>
</ul>
<p><img src="https://www.zhihu.com/equation?tex=%5Ctext%7Bceil%7D(800%2F16)+%5Ctimes+%5Ctext%7Bceil%7D(600%2F16)+%5Ctimes+9%3D50%5Ctimes38+%5Ctimes9%3D17100" alt="[公式]"></p>
<blockquote>
<p><a href="https://github.com/rbgirshick/py-faster-rcnn/tree/master/models/pascal_voc/VGG16/faster_rcnn_end2end" target="_blank" rel="noopener">https://github.com/rbgirshick/py-faster-rcnn/tree/master/models/pascal_voc/VGG16/faster_rcnn_end2end</a></p>
</blockquote>
<p>那么为何要在softmax前后都接一个reshape layer？其实只是为了便于softmax分类，至于具体原因这就要从caffe的实现形式说起了。在caffe基本数据结构blob中以如下形式保存数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blob&#x3D;[batch_size, channel，height，width]</span><br></pre></td></tr></table></figure>

<p>对应至上面的保存positive/negative anchors的矩阵，其在caffe blob中的存储形式为[1, 2x9, H, W]。而在softmax分类时需要进行positive/negative二分类，所以reshape layer会将其变为[1, 2, 9xH, W]大小，即单独“腾空”出来一个维度以便softmax分类，之后再reshape回复原状。贴一段caffe softmax_loss_layer.cpp的reshape函数的解释，非常精辟：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"Number of labels must match number of predictions; "</span></span><br><span class="line"><span class="string">"e.g., if softmax axis == 1 and prediction shape is (N, C, H, W), "</span></span><br><span class="line"><span class="string">"label count (number of labels) must be N*H*W, "</span></span><br><span class="line"><span class="string">"with integer values in &#123;0, 1, ..., C-1&#125;."</span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>soomth-L1</li>
<li>ROI pooliing 7x7</li>
</ul>
<h4 id="for-ZF-backbone"><a href="#for-ZF-backbone" class="headerlink" title="*for ZF backbone *"></a>*for <code>ZF</code> backbone *</h4><p>==&gt; ch-256 before RPN</p>
<h3 id="★-比較-R-CNN-v-s-Fast-v-s-Faster"><a href="#★-比較-R-CNN-v-s-Fast-v-s-Faster" class="headerlink" title="★ 比較 R-CNN v.s. Fast v.s. Faster"></a>★ 比較 R-CNN v.s. Fast v.s. Faster</h3><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdddgum6x0j31jk0esacq.jpg" alt="img" style="zoom:67%;" />



<hr>
<h3 id="YOLO-v1"><a href="#YOLO-v1" class="headerlink" title="YOLO v1"></a>YOLO v1</h3><ul>
<li><p>45FPS</p>
</li>
<li><p>Can we just out bbox (x,y,w,h) and (c) ? But we found as objected to be detected increase, output dimension of model also increase, not able to be determined.</p>
<p>==&gt; YOLO does this by gridding image into grids, within each of which being able to output class and bbox.</p>
</li>
<li><p>7x7 grids on image, 30 channels, as No RPN, just use a big net to catch all fishes</p>
</li>
<li><p>2 predictor for each cell.</p>
</li>
<li><p><strong>Q: If class prediction is not sharing, can one cell predict two obj?</strong></p>
<ul>
<li>No. In this way,  how do the two predictor divide their works?</li>
<li>Faster RCNN OK because of anhchors and IOU w/ GT, which got introduced in YOLO v2</li>
</ul>
</li>
<li><p><strong>Why 2 bounding boxes?</strong></p>
<ul>
<li>Predictor with bigger IOU with GT while training, is responsible for detecting the corresponding object.</li>
</ul>
</li>
<li><p>x, y means shift relative to cell’s upper-left corner; w, h relative to the whole image</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gamijfkmaej30oy0iy77z.jpg" alt="image-20200106075944588"></p>
</li>
<li><p>confidence = <em>Pr(Object) x IOU</em>,  IOU is calculated during training, Pr(Object) is bool</p>
<p>So, Pr(Classi|Object) x <em>Pr(Object) x IOU</em> , Pr(Classi|Object) is meaningful only when Pr(Object) is not 0.</p>
</li>
</ul>
<p>Ref: <a href="https://zhuanlan.zhihu.com/p/37850811" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37850811</a></p>
<hr>
<h3 id="YOLO-v2"><a href="#YOLO-v2" class="headerlink" title="YOLO v2"></a>YOLO v2</h3><ul>
<li><p>input: 416x416 ==&gt; 13 x 13</p>
</li>
<li><p>No FC (YOLO v1 has FC to turn 1024x7x7 into 30x7x7)</p>
</li>
<li><p>5 Anchor, so that <strong>able to predict not only one obj for each cell</strong>, but 5</p>
</li>
<li><p>BN – quickly converge, and for regularization</p>
</li>
<li><p>Fully convolutional network architecture, so any size of image.</p>
</li>
<li><p>Skipping <code>reorg</code> layer –  after conv5-5, making gradient able forward. </p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gamo1nin68j30u60700ul.jpg" alt="image-20200106111017191"></p>
</li>
<li><p>Prediction:<br>(4 + 1 + num_class) for <code>each anchor</code>。Use sigmoid to make value btw 0~1. Use exponential for scaling.</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gamoddpf2zj30um0ta140.jpg" alt="image-20200106112133343"></p>
</li>
<li><p>anchor with largest IOU (by moving both of anchor and GT_box to upper-left corner) to predict correcponding obj</p>
</li>
<li><p>Loss: </p>
<ul>
<li>anchor predicting obj xywh: L2</li>
<li>anchor not predicing obj xywh: for correct anchor’s xywh</li>
<li>anchor predicting obj confidence: IOU btw predicted bbox and GT bbox</li>
<li>anchor not predicing obj confidence: for correct anchor’s xywh</li>
</ul>
</li>
<li><p>Multi-scale:</p>
<p>[320,320]，[416,416]和[512,512]，==&gt; grids: [10,10], [13,13], [16,16]. </p>
<p>During training, every 10 batches, one size btw 320x320 ~ 608x608 is chosen</p>
</li>
</ul>
<p>Ref: <a href="https://zhuanlan.zhihu.com/p/40659490" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40659490</a></p>
<hr>
<h3 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h3><p>prototxt: <a href="https://github.com/intel/caffe/blob/master/models/intel_optimized_models/ssd/VGGNet/VOC0712/SSD_300x300/deploy.prototxt" target="_blank" rel="noopener">https://github.com/intel/caffe/blob/master/models/intel_optimized_models/ssd/VGGNet/VOC0712/SSD_300x300/deploy.prototxt</a></p>
<ul>
<li><p>as YOLO, turn <code>detection</code> problem into <code>regression</code> problem</p>
</li>
<li><p>as FasterRCNN’s anchor, proposed <code>prior box</code>,  for each feature map</p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gamqauu7ioj30l402smxd.jpg" alt="image-20200106122821151"></p>
<p>By this formula, Prior Box size could be determined for each feature map together with <code>aspect ratio</code></p>
<p>m: total feature maps adopted</p>
<ul>
<li><p><code>default box</code> : abstract concept of <code>prior box</code></p>
</li>
<li><p><code>prior box</code>: adopted during training, the actually chosen default box for training</p>
</li>
<li><p>for <code>k default box</code> on their own feature maps: k x  (c+4) x  m x n</p>
<ul>
<li><p>for confidence’s output: c x k x m x n,<br>c x m x n for each of the k default box </p>
<p>if 20 classes, then we have </p>
</li>
<li><p>for localization’s output: 4 x k x m x n<br>4 x m x n for each of the k default box </p>
</li>
<li><p>All prior box amount:<br>$$<br>38x38x4 + 19x19x6 +10x10x6 + 5x5x6 + 3x3x4 +1x1x4 = 8732<br>$$<br>k x (20+1), if k is 6 for each prior box; thus, 6x21 = 126 kernels<br>k x 4, if k is 6 for each prior box; thus, 6x4 = 24 kernels</p>
</li>
<li><p>TRAINING to make prior box regress to GT box </p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>as FPN, use Pyramidal Feature Hierarchy</p>
</li>
<li><p>DIDN’T generate RPN, thus speed-up</p>
</li>
<li><p>VGG-16 as backbone, the final 2 FC were turned into conv layers</p>
</li>
<li><p>Permute: 32x19x19x24 ==&gt; 32x24x19x19</p>
<p>Flatten: 32x19x19x24 ==&gt; 32x8664, where 32 is batch_size</p>
<p>mbox_priorbox – for training only</p>
<p>mbox_loc</p>
<p>mbox_conf</p>
</li>
<li><p><strong>Sample augmentation</strong></p>
</li>
<li><p><strong>+/- sampling</strong></p>
<p>Match <code>prior box</code> and <code>GT</code> according to IOU (Jaccard Overlap). </p>
<p>+ prior box  : matching to GT</p>
<p>- prior box : not mathcing to GT</p>
<p>and soft all - prior boxes according to classificatin loss, to control + : -  is around 1 : 3</p>
</li>
<li><p>GT : each GT has it mapping anchor. anchors are mapped into original image to match GT box</p>
<img src="https://tva1.sinaimg.cn/large/006tNbRwly1gams525z5sj30ha0f67ap.jpg" alt="image-20200106133152958" style="zoom:50%;" />
</li>
<li><p>input 300x300, pooling stride 2, thus conv4_3 length is 38, keep all left equals to 19, and final feature-map’s length is 10</p>
</li>
<li><p><strong>Loss</strong></p>
<ul>
<li>loc-loss: smooth-L1 loss as Faster-RCNN</li>
<li>conf-loss: softmax loss for each class</li>
</ul>
</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gampfyf6l8j31200ju46v.jpg" alt="image-20200106115837659"></p>
<p>ref: <a href="https://www.cnblogs.com/xuanyuyt/p/7222867.html" target="_blank" rel="noopener">https://www.cnblogs.com/xuanyuyt/p/7222867.html</a></p>
<hr>
<h3 id="FPN-–-didn’t-dig-into-this-too-much"><a href="#FPN-–-didn’t-dig-into-this-too-much" class="headerlink" title="FPN – didn’t dig into this too much."></a>FPN – didn’t dig into this too much.</h3><h3 id="梯度消失主角"><a href="#梯度消失主角" class="headerlink" title="梯度消失主角"></a>梯度消失主角</h3><ul>
<li>Sigmoid邊緣區</li>
</ul>
<h3 id="Why-ReLU-Better-than-Sigmoid"><a href="#Why-ReLU-Better-than-Sigmoid" class="headerlink" title="Why ReLU Better than Sigmoid?"></a>Why ReLU Better than Sigmoid?</h3><ul>
<li><p>一方面，ReLU比sigmoid效果好的分析都是基于深度神经网络的前提，比如网络足够深时<strong>sigmoid会有明显的梯度消失问题，如果是浅层神经网络的话这些问题并不存在</strong>。另一方面，它们的用处不同，sigmoid输出范围是01之间，可以当作概率。深度神经网络中sigmoid可以用作门控单元（比如LSTM的三种门都是sigmoid）或attention（比如SENet中excitation部分），这些ReLU并不能取代。</p>
</li>
<li><p>说白了还是具体问题具体分析。如果神经网络是进行二分类，你用relu做输出层激励函数，你的输出是不是很难控制？如果你的神经网络层数很深，你用sigmoid，反向传播过程是不是会有梯度消失？现在sigmoid更多的情况下，在小型神经网络和二分类型的输出层中出现的比较多，relu效果好不代表在任何应用条件下都好</p>
</li>
<li><p>隐含层就放心用Relu吧,</p>
<ul>
<li>relu的好处是可以解决梯度消失问题</li>
<li>sigmoid的好处是可以把输入缩放到0–1之前，并且连续没有绝对的好与坏，具体情况具体分析</li>
</ul>
</li>
<li><p>sigmoid和tanh的gradient在饱和区域非常平缓，接近于0，很容易造成vanishing gradient的问题，减缓收敛速度。vanishing gradient在网络层数多的时候尤其明显，是加深网络结构的主要障碍之一。</p>
</li>
<li><p>Relu的另一个优势是在生物上的合理性, with 0s so sparse network，它是单边的，相比sigmoid和tanh，更符合生物神经元的特征。</p>
</li>
<li><p>Relu的另一个优势是在生物上的合理性，它是单边的，相比sigmoid和tanh，更符合生物神经元的特征。</p>
</li>
</ul>
<h3 id="Why-Non-linear"><a href="#Why-Non-linear" class="headerlink" title="Why Non-linear"></a>Why Non-linear</h3><ul>
<li>or you can just use LR… same meaning.</li>
</ul>
<h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><h3 id="Optimization-Functions"><a href="#Optimization-Functions" class="headerlink" title="Optimization Functions"></a>Optimization Functions</h3><ul>
<li>SGD =&gt; momentum, to make local minimum to global min</li>
<li>AdaGrad: 衰減 α,  </li>
</ul>
<p>Identify class <strong>imbalance</strong> as the primary obstacle preventing one-stage object detectors from surpassing top-performing, two-stage methods, such as Faster R-CNN variants. To address this, we propose the focal loss which applies a modulating term to the cross entropy loss in order to focus learning on hard examples and down-weight the numerous easy negatives.</p>
<p>ref:</p>
<p><a href="https://medium.com/@chih.sheng.huang821/機器學習-基礎數學-三-梯度最佳解相關算法-gradient-descent-optimization-algorithms-b61ed1478bd7" target="_blank" rel="noopener">https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%B8%89-%E6%A2%AF%E5%BA%A6%E6%9C%80%E4%BD%B3%E8%A7%A3%E7%9B%B8%E9%97%9C%E7%AE%97%E6%B3%95-gradient-descent-optimization-algorithms-b61ed1478bd7</a></p>
<ul>
<li><h5 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a><strong>Adam</strong></h5><p>Adam全名Adaptive Moment Estimation。剛剛介紹的Momentum是「計算參數更新方向前會考慮前一次參數更新的方向」， RMSprop則是「在學習率上依據梯度的大小對學習率進行加強或是衰減」。</p>
<p><strong><em>Adam則是兩者合併加強版本(Momentum+RMSprop+各自做偏差的修正)。</em></strong></p>
</li>
</ul>
<h3 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a>MobileNet</h3><ul>
<li>Explanation:</li>
</ul>
<h3 id="MobileNet-v2"><a href="#MobileNet-v2" class="headerlink" title="MobileNet v2"></a>MobileNet v2</h3><h3 id="ShuffleNet"><a href="#ShuffleNet" class="headerlink" title="ShuffleNet"></a>ShuffleNet</h3><h3 id="1x1"><a href="#1x1" class="headerlink" title="1x1"></a>1x1</h3><h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><ul>
<li>To solve what problem?</li>
<li>Explanation:</li>
<li>Keywords:<ul>
<li>Downsampling</li>
</ul>
</li>
</ul>
<h3 id="Mask-RCNN"><a href="#Mask-RCNN" class="headerlink" title="Mask RCNN"></a>Mask RCNN</h3><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdnuk0bzxaj31aw0kqtrn.jpg" alt="image-20200409214203203"></p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdnv8pvmiwj315q09qai1.jpg" alt="image-20200409220551821"></p>
<p><strong>双线性插值</strong></p>
<p>双线性插值本质上就是在两个方向上做线性插值。</p>
<img src="/Users/joe/Library/Application Support/typora-user-images/image-20200409221718377.png" alt="image-20200409221718377" style="zoom: 33%;" />

<blockquote>
<p>如图，假设我们想得到P点的插值，我们可以先在x方向上，对Q11和Q21 之间做线性插值得到R1 ，R2 同理可得。然后在y方向上对R1和R2 进行线性插值就可以得到最终的P。其实知道这个就已经理解了双线性插值的意思了，如果用公式表达则如下（注意 f 前面的系数看成权重就很好理解了）。</p>
<p>下面通过一个例子来讲解ROI Align操作。如下图所示，虚线部分表示feature map，实线表示ROI，这里将ROI切分成2x2的单元格。如果采样点数是4，那我们首先将每个单元格子均分成四个小方格（如红色线所示），每个小方格中心就是采样点。这些采样点的坐标通常是浮点数，所以需要对采样点像素进行双线性插值（如四个箭头所示），就可以得到该像素点的值了。然后对每个单元格内的四个采样点进行maxpooling，就可以得到最终的ROIAlign的结果。</p>
</blockquote>
<img src="/Users/joe/Library/Application Support/typora-user-images/image-20200409221825219.png" alt="image-20200409221825219" style="zoom: 33%;" />

<blockquote>
<p>需要说明的是，在相关实验中，作者发现将采样点设为4会获得最佳性能，甚至直接设为1在性能上也相差无几。事实上，ROI Align 在遍历取样点的数量上没有ROIPooling那么多，但却可以获得更好的性能，这主要归功于解决了misalignment的问题。</p>
<p>作者：数据智能谷<br>链接：<a href="https://www.jianshu.com/p/a5c46271dc9e" target="_blank" rel="noopener">https://www.jianshu.com/p/a5c46271dc9e</a><br>来源：简书<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
</blockquote>
<h3 id="RF-Receptive-Field"><a href="#RF-Receptive-Field" class="headerlink" title="RF (Receptive Field)"></a>RF (Receptive Field)</h3><ul>
<li><p>Top-Down (Easy!)</p>
<p>VGG as e.g.</p>
<table>
<thead>
<tr>
<th>Layer</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>1-1</td>
<td>1 + 1x2^1</td>
<td>3</td>
</tr>
<tr>
<td>1-2</td>
<td>1 + 2x2^1</td>
<td>5</td>
</tr>
<tr>
<td>Pooling 1</td>
<td>1 + 2x2^1 + <strong>2^0</strong></td>
<td>6</td>
</tr>
<tr>
<td>2-1</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 1x2^2</td>
<td>10</td>
</tr>
<tr>
<td>2-2</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2</td>
<td>14</td>
</tr>
<tr>
<td>Pooling 2</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong></td>
<td>16</td>
</tr>
<tr>
<td>3-1</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 1x2^3</td>
<td>24</td>
</tr>
<tr>
<td>3-2</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 2x2^3</td>
<td>32</td>
</tr>
<tr>
<td>3-3</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3</td>
<td>40</td>
</tr>
<tr>
<td>Pooling 3</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong></td>
<td>44</td>
</tr>
<tr>
<td>4-1</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 1x2^4</td>
<td>60</td>
</tr>
<tr>
<td>4-2</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 2x2^4</td>
<td>76</td>
</tr>
<tr>
<td>4-3</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + *<em>2^2 *</em>+ 3x2^4</td>
<td>92</td>
</tr>
<tr>
<td>Pooling 4</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 3x2^4 + <strong>2^3</strong></td>
<td>100</td>
</tr>
<tr>
<td>5-1</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 3x2^4 + <strong>2^3</strong> + 1x2^5</td>
<td>132</td>
</tr>
<tr>
<td>5-2</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 3x2^4 + <strong>2^3</strong> + 2x2^5</td>
<td>164</td>
</tr>
<tr>
<td>5-3</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 3x2^4 + <strong>2^3</strong> + 3x2^5</td>
<td>196</td>
</tr>
<tr>
<td>Pooling 5</td>
<td>1 + 2x2^1 + <strong>2^0</strong> + 2x2^2 + <strong>2^1</strong> + 3x2^3 + <strong>2^2</strong> + 3x2^4 + <strong>2^3</strong> + 3x2^5 + <strong>2^4</strong></td>
<td>212</td>
</tr>
</tbody></table>
<p>​    </p>
</li>
<li><p>Bottom Up (Hard..)</p>
</li>
</ul>
<h3 id="Gradient-Vanishing"><a href="#Gradient-Vanishing" class="headerlink" title="Gradient Vanishing"></a>Gradient Vanishing</h3><h3 id="Gradient-Explosion"><a href="#Gradient-Explosion" class="headerlink" title="Gradient Explosion"></a>Gradient Explosion</h3><p>ROI Pooling vs ROI Align</p>
<h3 id="BN-梯度消失解決原理"><a href="#BN-梯度消失解決原理" class="headerlink" title="BN 梯度消失解決原理"></a>BN 梯度消失解決原理</h3><ul>
<li>藉由改為正態分布，把data拉回sigmoid中間區那區梯度才不會太平 (兩側都沒梯度了)<ul>
<li>導數最大時是0.25, 在x==0時</li>
</ul>
</li>
</ul>
<p>ref: <a href="https://blog.csdn.net/m0_37477175/article/details/80259773" target="_blank" rel="noopener">https://blog.csdn.net/m0_37477175/article/details/80259773</a></p>
<h3 id="NMS-for-overlapping-boxes"><a href="#NMS-for-overlapping-boxes" class="headerlink" title="NMS - for overlapping boxes"></a>NMS - for overlapping boxes</h3><p>Non-Maximal Suppression</p>
<hr>
<h2 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h2><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><ul>
<li><p>Explanation</p>
<p>The delta btw y_hat and y will be fed into another weak classifier </p>
</li>
</ul>
<h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><p><strong>SVM本身是一个二值分类器</strong></p>
<p>　　SVM算法最初是为二值分类问题设计的，当处理多类问题时，就需要构造合适的多类分类器。</p>
<p>　　目前，构造SVM多类分类器的方法主要有两类</p>
<p>　　（1）直接法，直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。这种方法看似简单，但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中；</p>
<p>　　（2）间接法，主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one和one-against-all两种。</p>
<h3 id="DT"><a href="#DT" class="headerlink" title="DT"></a>DT</h3><p>smaller entropy means less wrongly classified</p>
<ul>
<li><p>ID3 (granually too small), </p>
<p>info gain  = Entropy </p>
</li>
<li><p>C4.5, </p>
</li>
<li><p>CART (binary tree, generally better than previous twos, needs some pruning sometimes)</p>
<p>with gini coefficient</p>
</li>
</ul>
<h2 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h2><h3 id="RF-Random-Forest"><a href="#RF-Random-Forest" class="headerlink" title="RF (Random Forest)"></a>RF (Random Forest)</h3><h3 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h3><ul>
<li><p>Bagging</p>
<p>​    to decrease variance</p>
</li>
<li><p>Boosting </p>
<p>​    to decrease bias</p>
<p>mainly to enhance weak classifier into a strong one. According to the training result from previous classifie, and then train next classifier according to new sample’s distribution.</p>
</li>
<li><p>Adaboost increase wrongly-classifed samples’ weights</p>
</li>
</ul>
<p>Ref: <a href="https://zhuanlan.zhihu.com/p/37358517" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/37358517</a></p>
<hr>
<p>used to eliminate the redundant features</p>
<h3 id="SVM-1"><a href="#SVM-1" class="headerlink" title="SVM"></a>SVM</h3><ul>
<li><p>hinge loss</p>
</li>
<li><p>分类间隔为1/||w||，||w||代表向量的模</p>
</li>
<li><p>当参数C越小时，分类间隔越大，分类错误越多，趋于欠学习</p>
<p>考虑软间隔的时候，C对优化问题的影响就在于把a的范围从[0，+inf]限制到了[0,C]。C越小，那么a就会越小，目标函数拉格朗日函数导数为0可以求出w=求和ai∗yi∗xi，a变小使得w变小，因此间隔2/||w||变大</p>
</li>
</ul>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><p>copied from : <a href="https://chtseng.wordpress.com/2017/02/10/決策樹-decision-trees/" target="_blank" rel="noopener">https://chtseng.wordpress.com/2017/02/10/%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-trees/</a></p>
<ul>
<li>Entropy definition</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gb23fhkw46j30l710otgs.jpg" alt="image-20200119192602821"></p>
<h2 id="Gini-Index-吉尼係數"><a href="#Gini-Index-吉尼係數" class="headerlink" title="Gini Index (吉尼係數)"></a><strong>Gini Index (吉尼係數)</strong></h2><p>採用GINI Index的代表是CART tree。CART是Classification And Regression Tree的縮寫，從字面上可看出它兼具分類與迴歸兩種功能，同時支援分類(Classification)與數字預測(Regression)，由於不限制應變數與自變數的類型，因此在使用上較具彈性，是目前最為常用的決策樹方法。</p>
<p>GINI係數與INFORMATION GAIN兩者有一個最大的差別：INFORMATION GAIN一次可產生多個不同節點，而GINI係數一次僅能產生兩個，即True或False的Binary分類。</p>
<p>下方一樣以板球為例來說明：（Gini係數公式為p2+q2）</p>
<p><strong>用性別來分類：</strong> </p>
<p><img src="https://chtseng.files.wordpress.com/2017/02/3148_gxdl-o-obg.png?w=1140" alt="img"></p>
<p>Femail節點：十位女性，其中有2位打板球10位不打，Gini係數為<br>(0.2)2+(0.8)2=0.68</p>
<p>Male節點：20位男性，其中有13位打板球7位不打，Gini係數為<br>(0.65)2+(0.35)2=0.55</p>
<p>因此以性別分類的Gini係數加權後為：(10/30)<em>0.68+(20/30)</em>0.55 = 0.59。</p>
<p><strong>用班級來分類：</strong></p>
<p><img src="https://chtseng.files.wordpress.com/2017/02/3148_jsuhhmuveq1.png?w=1140" alt="img"></p>
<p>  Class IX節點：此班14位同學，其中6位打板球8位不打，因此Gini係數為<br>(0.43)2+(0.57)2=0.51</p>
<p>  Class X節點：此班16位同學，其中9位打板球7位不打，因此Gini係數為<br>(0.56)2+(0.44)2=0.51</p>
<p>因此以班級分類的決策樹，其Gini係數加權結果：(14/30)<em>0.51+(16/30)</em>0.51 = 0.51。兩樹相互比較，以性別分類的吉尼係數大於以班級分類，因此系統會採用性別來進行節點的分類。</p>
<h3 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h3><ul>
<li>特征变量X的各个维度是类别条件独立随机变量</li>
</ul>
<h3 id="One-hot"><a href="#One-hot" class="headerlink" title="One-hot"></a>One-hot</h3><p>拆成更多個不同的字段，分別表示０、１</p>
<h3 id="Categorical-特徵處理方式"><a href="#Categorical-特徵處理方式" class="headerlink" title="Categorical 特徵處理方式"></a>Categorical 特徵處理方式</h3><h3 id="感知機"><a href="#感知機" class="headerlink" title="感知機"></a>感知機</h3><p>用的是Step function</p>
<h2 id="決策樹演算法的步驟"><a href="#決策樹演算法的步驟" class="headerlink" title="決策樹演算法的步驟"></a><strong>決策樹演算法的步驟</strong></h2><ol>
<li><strong>資料設定：</strong>將原始資料分成兩組，一部分為訓練資料，一部分為測試資料</li>
<li><strong>決策樹生成：</strong>使用訓練資料來建立決策樹，而在每一個內部節點，則依據屬性選擇指標 (如：資訊理論(Information Theory)…) 來評估選擇哪個屬性做分支的依據。此又稱節點分割 (Splitting Node)</li>
<li><strong>剪枝：</strong>使用測試資料來進行決策樹修剪，將以上1~3步驟不斷重複進行，直到所有的新產生節點都是樹葉節點為止。</li>
</ol>
<p>不過決策樹很容易有「Overfitting（過度擬合）」的問題，因為我們如果沒有對樹的成長作限制，演算法最後就會為每個不同特徵值創建新的分類節點，最後將所有資料作到100%正確的分類，因此為了預防Overfitting，我們會採取下列兩種方式：設限及剪枝。</p>
<h2 id="設限"><a href="#設限" class="headerlink" title="設限"></a><strong>設限</strong></h2><ol>
<li>Minimum samples for a node split：資料數目不得小於多少才能再產生新節點。</li>
<li>Minimum samples for a terminal node (leaf)：要成為葉節點，最少需要多少資料。</li>
<li>Maximum depth of tree (vertical depth)：限制樹的高度最多幾層。</li>
<li>Maximum number of terminal nodes：限制最終葉節點的數目</li>
<li>Maximum features to consider for split：在分離節點時，最多考慮幾種特徵值。</li>
</ol>
<p><img src="https://chtseng.files.wordpress.com/2017/02/3148_vgszibb2dq.png?w=1140" alt="img"></p>
<p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gb23urtakpj30g410pdkb.jpg" alt="image-20200119194043890"></p>
<h3 id="Training-Imbalance"><a href="#Training-Imbalance" class="headerlink" title="Training Imbalance"></a>Training Imbalance</h3><ul>
<li>Undersampling</li>
<li>Oversampling</li>
<li>SMOTE</li>
<li>圖像而言，有 Focal loss!</li>
</ul>
<h3 id="Why-Regularization-example"><a href="#Why-Regularization-example" class="headerlink" title="Why Regularization ? example?"></a>Why Regularization ? example?</h3><h3 id="Backward"><a href="#Backward" class="headerlink" title="Backward"></a>Backward</h3><hr>
<h3 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison:"></a>Comparison:</h3><p><img src="https://tva1.sinaimg.cn/large/006tNbRwly1gb20p3423tj30kf0b7dhi.jpg" alt="image-20200119175125694"></p>
<h4 id="Contrastive-loss"><a href="#Contrastive-loss" class="headerlink" title="Contrastive loss"></a>Contrastive loss</h4><p>​        2006, Yann LeCun’s paper, mainly adopted for dimension reduction, 即本来相似的样本，在经过降维（特征提取）后，两个样本仍旧相似；而原本不相似的样本，在经过降维后，两个样本仍旧不相似。同样，该损失函数也可以很好的表达成对样本的匹配程度<br>​        F = kX, as SPRING model</p>
<h4 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h4><p>​        2015, Google</p>
<p>​        三元组损失：最小化锚点和具有相同的身份的正例之间的距离，并最大化锚点和不同身份的负例之间的距离。 目标： 相同标签的两个示例使其嵌入在嵌入空间中靠近在一起，不同标签的两个示例的嵌入距离要很远 但不希望推动每个标签的训练嵌入到非常小的簇中。 唯一的要求是给出同一类的两个正例和一个负例，负例应该比正例的距离至少远margin。 这与SVM中使用的margin非常相似，这里希望每个类的簇由margin分隔。        </p>
<p>​    <strong>Triplet的选取</strong></p>
<ul>
<li><p>如何选择triplet，如何用正负例构建triplet，对模型训练的效率有很大影响。easy negative example比较容易识别，没必要训练，否则会严重降低训练效率。若都采用hard negative example，又可能会影响训练效果。</p>
</li>
<li><p>Facenet论文中采用了随机的semi-hard negative构建triplet进行训练。</p>
</li>
<li><p>基于negative example与anchor和positive距离，分为三类三元组：</p>
</li>
<li><ul>
<li>容易三元组(easy triplets)：损失为0的三元组，因为d(a,n)&gt;d(a,p)+margin</li>
<li>困难三元组(hard triplets) ：其中负例比正例更靠近锚点，即d(a,n)&lt;d(a,p)</li>
<li>半困难三元组(semi-hard triplets)：其中负例不比正例更接近锚点，但仍有大于0的损失，d(a,p)&lt;d(a,n)&lt;d(a,p)+margin</li>
</ul>
</li>
</ul>
<h4 id="Center-loss"><a href="#Center-loss" class="headerlink" title="Center loss"></a>Center loss</h4><p>Center Loss源于深圳先研院乔宇、Yandong Wen等在ECCV 2016上发表的 <a href="https://link.zhihu.com/?target=http%3A//ydwen.github.io/papers/WenECCV16.pdf">A Discriminative Feature Learning Approach for Deep Face Recognition</a>。<br><strong>判别性</strong></p>
<ul>
<li>深度学习的特征需要具有discriminative(判别性)和泛化能力，以便在没有标签预测的情况下识别新的未见类别，如一个人脸即便没有训练过也能判断类别。判别性同时表征了紧凑的类内差异和可分离的类间差异。</li>
<li>判别性特征可以通过最近邻（NN）或k近邻（k-NN）算法进行良好分类，其不一定取决于标签预测。</li>
<li>而softmax损失仅鼓励特征的可分离性，所得到的特征对于人脸识别不是足够有效的。</li>
<li>对比损失和三元组损失分别构成图像对和三元组的损失函数，然而与原样本相比，训练对或三元组的数量急剧增加，导致了网络收敛缓慢。</li>
</ul>
<p><strong>中心损失的定义</strong></p>
<ul>
<li>中心损失：为每一个类别提供一个类别中心，最小化min-batch中每个样本与该类别中心的距离，即缩小类内距离。</li>
<li>有效地表征了深度特征的类内距离，提升深度特征的判别能力，在保持不同类别的特征可分离的同时最小化类内距离是关键。公式如下，c_yi就是第yi个类别的特征中心，xi表示全连接层之前的特征，m表示mini-batch的大小</li>
</ul>
<h4 id="ArcFace-loss"><a href="#ArcFace-loss" class="headerlink" title="ArcFace loss"></a>ArcFace loss</h4><ul>
<li><p>性能高，易于编程实现，复杂性低，训练效率高</p>
</li>
<li><p>ArcFace直接优化geodesic distance margin(弧度)，因为归一化超球体中的角和弧度的对应。</p>
</li>
<li><p>为了性能的稳定，ArcFace不需要与其他loss函数实现联合监督，可以很容易地收敛于任何训练数据集。</p>
</li>
<li><p>缺点：W模型很大</p>
</li>
</ul>
<h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h3><ul>
<li>metric</li>
</ul>
<h3 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h3><p><em>Ilya Sutskever, Oriol Vinyals, Quoc V. Le, 2014, “Sequence to Sequence Learning with Neural Networks,” pp. 3104–311 in NIPS 2014</em></p>
<p>Take AlexNet for example, by eliminating softmax, we’ll be able to extract a 4096 dimension embedding.</p>
<p>Now, feed the vector into RNN, as what language translation does, it’ll generate a output sequence, the CAPTION for the image.</p>
<ul>
<li><h5 id="ImageTOseq"><a href="#ImageTOseq" class="headerlink" title="ImageTOseq"></a>ImageTOseq</h5><p>Image Caption, mean</p>
<p><em>Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN) – ICLR2015, San Diego</em><br><em>by Junua Mao</em></p>
<p>Meanwhile, Oriol Vinyals, (Andrej, Fei-Fei Li) also acquired the similar conclusion.</p>
</li>
</ul>
<p>After obtaining this vector, decoder part of the network starts its processing with this fixed vector representation and at <strong>each time step of the decoder network it produces outputs</strong>. <strong>Operation stops when a special token</strong> showing the end of the sentence is produced. Distributed representations of the words are used as inputs to the encoder network. At the output side at each time step, a Word is chosen from a specific vocabulary list. At the decoder side, after decoder part a classifier network is used to produce a Word from the output at each time step. <strong>LSTM networks are used in this paper due to their capability of capturing long term relationships</strong>. Paper also shows experiments on machine translation task, which is from English to French. Simulation results reveal that presented approach outperforms existing studies.</p>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>The Encoder + Decoder mechanism based on RNN (LSTM or GRU). </p>
<p>For Image caption, it explains different region afftectin the output text series BY</p>
<p>weighing differently in X and therefore extracts important info for model making more precies judgement.</p>
<p><a href="https://zhuanlan.zhihu.com/p/31547842" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31547842</a></p>
<h3 id="Saliency-Detection"><a href="#Saliency-Detection" class="headerlink" title="Saliency Detection"></a>Saliency Detection</h3><p>The region within the image where user most care about.</p>
<p>![image-20200119174713586](/Users/joe/Library/Application Support/typora-user-images/image-20200119174713586.png)</p>
<h3 id="Reason-of-LR-as-Linear"><a href="#Reason-of-LR-as-Linear" class="headerlink" title="Reason of LR as Linear"></a>Reason of LR as Linear</h3><p>有人說，因為邏輯迴歸不是線性的，這個說法是不對的！因為我們可以把邏輯回歸的模型轉成線性的形式如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcx9msq25oj311a0b6411.jpg" alt="螢幕快照 2017-12-22 上午12.41.33"></p>
<p>主要原因很簡單，因為迴歸分析中 <img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcx9mt6yxrj300o00n08d.jpg" alt="Y"> 是已經觀察到的資料，可是邏輯迴歸中 <img src="https://s0.wp.com/latex.php?zoom=2&latex=P%28Y%3D1%7CX%29&bg=ffffff&fg=000&s=0" alt="P(https://tva1.sinaimg.cn/large/00831rSTgy1gcx9mo7366j301q00y0fi.jpg)"> 是資料裡面無法觀察到的，所以我們就沒辦法用傳統的最小平方法估計，而要採用最大概似法 (Maximum Likelihood Estimation)。至於最大概似法的原理是什麼，可以用下面這張圖很清楚的解釋。</p>
<h3 id="关于logit-回归和SVM-不正确的是（A）-机器学习-ML模型-中"><a href="#关于logit-回归和SVM-不正确的是（A）-机器学习-ML模型-中" class="headerlink" title="关于logit 回归和SVM 不正确的是（A） 机器学习 ML模型 中"></a>关于logit 回归和SVM 不正确的是（A） 机器学习 ML模型 中</h3><p>A. Logit回归本质上是一种根据样本对权值进行极大似然估计的方法，而后验概率正比于先验概率和似然函数的乘积。logit仅仅是最大化似然函数，并没有最大化后验概率，更谈不上最小化后验概率。<strong>A错误</strong><br>B. Logit回归的输出就是样本属于正类别的几率，可以计算出概率，正确<br>C. SVM的目标是找到使得训练数据尽可能分开且分类间隔最大的超平面，应该属于结构风险最小化。<br>D. SVM可以通过正则化系数控制模型的复杂度，避免过拟合。<br>@BlackEyes_SGC：<strong>Logit回归目标函数是最小化后验概率，Logit回归可以用于预测事件发生概率的大小，</strong>SVM目标是结构风险最小化，SVM可以有效避免模型过拟合。</p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcx9mu07mkj314s0u0tjz.jpg" alt="螢幕快照 2017-12-22 上午12.44.31"></p>
<h3 id="为什么xgboost要用泰勒展开，优势在哪里？机器学习-ML模型-难"><a href="#为什么xgboost要用泰勒展开，优势在哪里？机器学习-ML模型-难" class="headerlink" title="为什么xgboost要用泰勒展开，优势在哪里？机器学习 ML模型 难"></a>为什么xgboost要用泰勒展开，优势在哪里？机器学习 ML模型 难</h3><p>@AntZ：xgboost使用了一阶和二阶偏导, 二阶导数有利于梯度下降的更快更准. 使用泰勒展开取得函数做自变量的二阶导数形式, 可以在不选定损失函数具体形式的情况下, 仅仅依靠输入数据的值就可以进行叶子分裂优化计算, 本质上也就把损失函数的选取和模型算法优化/参数选择分开了. 这种去耦合增加了xgboost的适用性, 使得它按需选取损失函数, 可以用于分类, 也可以用于回归。<br>————————————————<br>版权声明：本文为CSDN博主「v_JULY_v」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/v_JULY_v/article/details/78121924" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/78121924</a> </p>
<h3 id="L1和L2正则先验分别服从什么分布。机器学习-ML基础-易"><a href="#L1和L2正则先验分别服从什么分布。机器学习-ML基础-易" class="headerlink" title="L1和L2正则先验分别服从什么分布。机器学习 ML基础 易"></a>L1和L2正则先验分别服从什么分布。机器学习 ML基础 易</h3><ul>
<li>L1和L2正则先验分别服从什么分布，L1是拉普拉斯分布，L2是高斯分布。</li>
<li>先验就是优化的起跑线, 有先验的好处就是可以在较小的数据集中有良好的泛化性能，当然这是在先验分布是接近真实分布的情况下得到的了，从信息论的角度看，向系统加入了正确先验这个信息，肯定会提高系统的性能。<br>对参数引入高斯正态先验分布相当于L2正则化, 这个大家都熟悉：</li>
</ul>
<h3 id="How-to-choose-K-for-K-Means-Clustering"><a href="#How-to-choose-K-for-K-Means-Clustering" class="headerlink" title="How to choose K for K-Means Clustering"></a>How to choose K for K-Means Clustering</h3><ul>
<li>sqrt(n/2) – bad</li>
<li>elbow method - Y-axis means sum(square errors)</li>
</ul>
<p><a href="https://rpubs.com/skydome20/R-Note9-Clustering" target="_blank" rel="noopener">https://rpubs.com/skydome20/R-Note9-Clustering</a></p>
<p><a href="https://www.biaodianfu.com/k-means-choose-k.html" target="_blank" rel="noopener">https://www.biaodianfu.com/k-means-choose-k.html</a></p>
<h3 id="How-to-choose-K-for-kNN"><a href="#How-to-choose-K-for-kNN" class="headerlink" title="How to choose K for kNN"></a>How to choose K for kNN</h3><ul>
<li>CV error might rise after a specific lowest value of K</li>
</ul>
<p>如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；<br>如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。<br>K=N，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。<br>    在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是一部分样本做训练集，一部分做测试集）来选择最优的K值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">K = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line">error_histories = []</span><br><span class="line">num_val_samples = len(train_data) // K</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(K):</span><br><span class="line">    print(<span class="string">'Processing fold #'</span>, i)</span><br><span class="line">    val_data = train_data[i*num_val_samples : (i+<span class="number">1</span>)*num_val_samples]</span><br><span class="line">    val_targets = train_targets[i*num_val_samples : (i+<span class="number">1</span>)*num_val_samples]</span><br><span class="line">    </span><br><span class="line">    partial_train_data = np.concatenate( </span><br><span class="line">                         [train_data[: i*num_val_samples],</span><br><span class="line">                         train_data[(i+<span class="number">1</span>)*num_val_samples :]],</span><br><span class="line">                         axis = <span class="number">0</span>)</span><br><span class="line">    partial_train_targets = np.concatenate(</span><br><span class="line">                         [train_targets[: i*num_val_samples],</span><br><span class="line">                         train_targets[(i+<span class="number">1</span>)*num_val_samples :]],</span><br><span class="line">                         axis = <span class="number">0</span>)</span><br><span class="line">    model = build_model()</span><br><span class="line">    history = model.fit(partial_train_data,</span><br><span class="line">                        partial_train_targets,</span><br><span class="line">                        validation_data = (val_data, val_targets),</span><br><span class="line">                        epochs = epochs,</span><br><span class="line">                        batch_size = batch_size,</span><br><span class="line">                        verbose = <span class="number">1</span>)</span><br><span class="line">    mae_history = history.history[<span class="string">'val_mean_absolute_error'</span>]</span><br><span class="line">    error_histories.append(mae_history)</span><br><span class="line">    average_error = [ np.mean([x[i] <span class="keyword">for</span> x <span class="keyword">in</span> error_histories]) <span class="keyword">for</span> i <span class="keyword">in</span> range(epochs)]</span><br><span class="line"></span><br><span class="line">fr: </span><br><span class="line">  https://jason-chen<span class="number">-1992.</span>weebly.com/home/-cross-validation</span><br></pre></td></tr></table></figure>



<h3 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h3><p>Density-based spatial clustering of applications with noise</p>
<h3 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合,"></a>防止过拟合,</h3><p>　　过拟合的原因是算法的学习能力过强；一些假设条件（如样本独立同分布）可能是不成立的；训练样本过少不能对整个空间进行分布估计。<br>　　处理方法：</p>
<p>早停止：如在训练中多次迭代后发现模型性能没有显著提高就停止训练<br>数据集扩增：原有数据增加、原有数据加随机噪声、重采样<br>正则化<br>交叉验证<br>特征选择/特征降维<br>创建一个验证集是最基本的防止过拟合的方法。我们最终训练得到的模型目标是要在验证集上面有好的表现，而不训练集。<br>正则化可以限制模型的复杂度。</p>
<p>在训练中，我们希望在中间箭头的位置停止训练。而Early stopping就可以实现该功能，这时获得的模型泛化能力较强，还可以得到一个中等大小的w的弗罗贝尼乌斯范数。其与L2正则化相似，选择参数w范数较小的神经网络。</p>
<p>可以用L2正则化代替early stopping。因为只要训练的时间足够长，多试几个lambda。总可以得到比较好的结果。</p>
<h3 id="Early-stopping"><a href="#Early-stopping" class="headerlink" title="Early stopping:"></a>Early stopping:</h3><p>优点：只运行一次梯度下降，我们就可以找出w的较小值，中间值和较大值。而无需尝试L2正则化超级参数lambda的很多值。</p>
<p>缺点：不能独立地处理以上两个问题，使得要考虑的东西变得复杂。举例如下：</p>
<p>一般机器学习的步骤分为以上两步，第一步我们确定一个成本函数J，然后可以用梯度下降等方法去优化它；第二步我们不希望模型发生过拟合，就有正则化等方式去操作，这是一个动态的过程。但是如果采用early stopping，这就相当于用一种方式来控制两个问题的结束，这会使得问题变得复杂。如图一所示，在中间位置时，模型已经停止训练了，而成本函数还没有下降到合适的区域。</p>
<h3 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h3><p>二階混淆矩陣</p>
<p>有了混淆矩陣，就可以定義<strong>ROC</strong>曲線了。<strong>ROC</strong>曲線將假陽性率（FPR）定義為 X 軸，真陽性率（TPR）定義為 Y 軸。其中：</p>
<ul>
<li>TPR：在所有實際為陽性的樣本中，被正確地判斷為陽性的樣本比率。</li>
<li>FPR：在所有實際為陰性的樣本中，被錯誤地判斷為陽性的樣本比率。</li>
<li>TPR = TP / (TP + FN)</li>
<li>FPR = FP / (FP + TN)</li>
<li><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcydclzpf2j30hs0csdgb.jpg" alt="img" style="zoom:50%;" />

</li>
</ul>
<h3 id="ML-Flow"><a href="#ML-Flow" class="headerlink" title="ML Flow"></a>ML Flow</h3><p>Abstract as math problem -&gt; acquire data, pca … -&gt; feature selection -&gt; train &amp; optimize model -&gt; analyze model -&gt; deploy (time complexity, resource consumption, stability)</p>
<h3 id="Linear-vs-Non-linear-classifiers"><a href="#Linear-vs-Non-linear-classifiers" class="headerlink" title="Linear vs Non-linear classifiers"></a>Linear vs Non-linear classifiers</h3><p>非线性分类器效果拟合能力较强，不足之处是数据量不足容易过拟合、计算复杂度高、可解释性不好。<br>常见的线性分类器有：LR,贝叶斯分类，单层感知机、线性回归<br>常见的非线性分类器：决策树、RF、GBDT、多层感知机<br>SVM两种都有（看线性核还是高斯核）</p>
<h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><p>下面几种方式,随便选一个,结果基本都差不多。但是一定要做。否则可能会减慢收敛速度，影响收敛结果，甚至造成Nan等一系列问题。</p>
<p>下面的n_in为网络的输入大小，n_out为网络的输出大小，n为n_in或(n_in+n_out)*0.5</p>
<p>Xavier初始法论文：<a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener">http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf</a></p>
<p>He初始化论文：<a href="https://arxiv.org/abs/1502.01852" target="_blank" rel="noopener">https://arxiv.org/abs/1502.01852</a><br>————————————————<br>版权声明：本文为CSDN博主「v_JULY_v」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/v_JULY_v/article/details/78121924" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/78121924</a></p>
<h3 id="k-d-tree"><a href="#k-d-tree" class="headerlink" title="k-d tree"></a>k-d tree</h3><h3 id="Ave-Pooling"><a href="#Ave-Pooling" class="headerlink" title="Ave Pooling"></a>Ave Pooling</h3><p>但是average-pooling在全局平均池化操作中应用也比较广，在ResNet和Inception结构中最后一层都使用了平均池化。有的时候在模型接近分类器的末端使用全局平均池化还可以代替Flatten操作，使输入数据变成一位向量。</p>
<h3 id="Newton’s-method-for-Optimization"><a href="#Newton’s-method-for-Optimization" class="headerlink" title="Newton’s method for Optimization"></a>Newton’s method for Optimization</h3><p>牛顿法的优缺点总结：</p>
<p>优点：二阶收敛，收敛速度快；</p>
<p>缺点：牛顿法是一种迭代算法，每一步都需要求解目标函数的Hessian矩阵的逆矩阵，计算比较复杂。</p>
<p>什么是拟牛顿法（Quasi-Newton Methods）？机器学习 ML基础 中</p>
<p>@wtq1993，<a href="http://blog.csdn.net/wtq1993/article/details/51607040" target="_blank" rel="noopener">http://blog.csdn.net/wtq1993/article/details/51607040</a><br>拟牛顿法是求解非线性优化问题最有效的方法之一，于20世纪50年代由美国Argonne国家实验室的物理学家W.C.Davidon所提出来。Davidon设计的这种算法在当时看来是非线性优化领域最具创造性的发明之一。不久R. Fletcher和M. J. D. Powell证实了这种新的算法远比其他方法快速和可靠，使得非线性优化这门学科在一夜之间突飞猛进。</p>
<p>拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。拟牛顿法和最速下降法一样只要求每一步迭代时知道目标函数的梯度。通过测量梯度的变化，构造一个目标函数的模型使之足以产生超线性收敛性。这类方法大大优于最速下降法，尤其对于困难的问题。另外，因为拟牛顿法不需要二阶导数的信息，所以有时比牛顿法更为有效。如今，优化软件中包含了大量的拟牛顿算法用来解决无约束，约束，和大规模的优化问题。</p>
<h3 id="共轭梯度法？"><a href="#共轭梯度法？" class="headerlink" title="共轭梯度法？"></a>共轭梯度法？</h3><p>​    共轭梯度法是介于梯度下降法（最速下降法）与牛顿法之间的一个方法，它仅需利用一阶导数信息，但克服了梯度下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hessian矩阵并求逆的缺点，共轭梯度法不仅是解决大型线性方程组最有用的方法之一，也是解大型非线性最优化最有效的算法之一。在各种优化算法中，共轭梯度法是非常重要的一种。其优点是所需存储量小，具有逐步收敛性，稳定性高，而且不需要任何外来参数。</p>
<h3 id="直觀理解正定、半正定矩陣-positive-definite和positive-semi-definite"><a href="#直觀理解正定、半正定矩陣-positive-definite和positive-semi-definite" class="headerlink" title="直觀理解正定、半正定矩陣　positive definite和positive semi-definite:"></a>直觀理解正定、半正定矩陣　positive definite和positive semi-definite:</h3><p>半正定与正定矩阵同意用半正定矩阵来事例：<br>首先半正定矩阵定义为: <img src="https://www.zhihu.com/equation?tex=X%5ETMX+%5Cgeq+0" alt="[公式]"><br>其中X 是向量，M 是变换矩阵</p>
<p>我们换一个思路看这个问题，矩阵变换中，<img src="https://www.zhihu.com/equation?tex=MX" alt="[公式]">代表对向量 X进行变换，我们假设变换后的向量为Y，记做<img src="https://www.zhihu.com/equation?tex=Y%3DMX" alt="[公式]">。于是半正定矩阵可以写成：<br><img src="https://www.zhihu.com/equation?tex=X%5ETY+%5Cgeq+0" alt="[公式]"></p>
<p>这个是不是很熟悉呢？ 他是两个向量的内积。 同时我们也有公式：</p>
<p><img src="https://www.zhihu.com/equation?tex=cos(%5Ctheta)+%3D+%5Cfrac%7BX%5ETY%7D%7B%7C%7CX%7C%7C*+%7C%7CY%7C%7C%7D" alt="[公式]"></p>
<p>||X||, ||Y||代表向量 X,Y的长度，<img src="https://www.zhihu.com/equation?tex=%5Ctheta" alt="[公式]">是他们之间的夹角。 于是半正定矩阵意味着<img src="https://www.zhihu.com/equation?tex=cos(%5Ctheta)%5Cgeq+0" alt="[公式]">, 这下明白了么？</p>
<p>正定、半正定矩阵的直觉代表一个向量经过它的变化后的向量与其本身的夹角小于等于90度。</p>
<h3 id="GAN-1"><a href="#GAN-1" class="headerlink" title="GAN"></a>GAN</h3><h3 id="Convolutinon-實現"><a href="#Convolutinon-實現" class="headerlink" title="Convolutinon 實現"></a>Convolutinon 實現</h3><p>img2col</p>
<p>note: <a href="https://zhuanlan.zhihu.com/p/63974249" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/63974249</a></p>
<h3 id="随机森林如何处理缺失值？"><a href="#随机森林如何处理缺失值？" class="headerlink" title="随机森林如何处理缺失值？"></a>随机森林如何处理缺失值？</h3><p>方法一（na.roughfix）简单粗暴，对于训练集,同一个class下的数据，如果是分类变量缺失，用众数补上，如果是连续型变量缺失，用中位数补。<br>方法二（rfImpute）这个方法计算量大，至于比方法一好坏？不好判断。先用na.roughfix补上缺失值，然后构建森林并计算proximity matrix，再回头看缺失值，如果是分类变量，则用没有缺失的观测实例的proximity中的权重进行投票。如果是连续型变量，则用proximity矩阵进行加权平均的方法补缺失值。然后迭代4-6次，这个补缺失值的思想和KNN有些类似12。</p>
<h3 id="Why-Smooth-L1-in-Faster-amp-SSD"><a href="#Why-Smooth-L1-in-Faster-amp-SSD" class="headerlink" title="Why Smooth-L1 in Faster &amp; SSD?"></a>Why Smooth-L1 in Faster &amp; SSD?</h3><p>对于边框预测回归问题，通常也可以选择平方损失函数（L2损失），但L2范数的缺点是当存在离群点（outliers)的时候，这些点会占loss的主要组成部分。比如说真实值为1，预测10次，有一次预测值为1000，其余次的预测值为1左右，显然loss值主要由1000主宰。所以FastRCNN采用稍微缓和一点绝对损失函数（smooth L1损失），它是随着误差线性增长，而不是平方增长。</p>
<p>注意：smooth L1和L1-loss函数的区别在于，L1-loss在0点处导数不唯一，可能影响收敛。smooth L1的解决办法是在0点附近使用平方函数使得它更加平滑。</p>
<p>ref: <a href="https://zhuanlan.zhihu.com/p/48426076" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/48426076</a></p>
<p>根据fast rcnn的说法，”…… L1 loss that is less sensitive to outliers than the L2 loss used in R-CNN and SPPnet.” 也就是smooth L1 loss让loss对于离群点更加鲁棒，即：相比于L2损失函数，其对离群点、异常值（outlier）不敏感，梯度变化相对更小，训练时不容易跑飞。</p>
<h2 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h2><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdc5yneca2j31400g6di2.jpg" alt="img" style="zoom:67%;" />

<h3 id="★-LSTM-amp-GRU"><a href="#★-LSTM-amp-GRU" class="headerlink" title="★ LSTM &amp; GRU"></a>★ LSTM &amp; GRU</h3><p>Ref: <a href="https://kknews.cc/zh-tw/code/vegon84.html" target="_blank" rel="noopener">https://kknews.cc/zh-tw/code/vegon84.html</a></p>
<p><a href="https://mp.weixin.qq.com/s/aV9Rj-CnJZRXRm0rDOK6gg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/aV9Rj-CnJZRXRm0rDOK6gg</a></p>
<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdc37qy1wmj30oo0bbwf7.jpg" alt="img" style="zoom:67%;" />

<p>Ref: <a href="https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/" target="_blank" rel="noopener">https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/</a></p>
<p>神經元數跟參數個數</p>
<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdc734yxpjj307u00kmwy.jpg" alt="img" style="zoom:67%;" />

<p>隱向量長度應該是要比字典短不少，不過例子裡的字在字典裡長度是５，隱向量長度是10，所以　(5+10)x10 + 10 共四個 for３個gates    </p>
<p>Ref: <a href="https://www.cnblogs.com/wushaogui/p/9176617.html" target="_blank" rel="noopener">https://www.cnblogs.com/wushaogui/p/9176617.html</a>, <a href="https://blog.csdn.net/Hello_word5/article/details/88918075" target="_blank" rel="noopener">https://blog.csdn.net/Hello_word5/article/details/88918075</a></p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdc7csb4tuj30u01dn0x9.jpg" alt="img"></p>
<h3 id="Word-Representation-to-Word-Embedding"><a href="#Word-Representation-to-Word-Embedding" class="headerlink" title="Word Representation to Word Embedding"></a>Word Representation to Word Embedding</h3><h2 id="Race-Condition"><a href="#Race-Condition" class="headerlink" title="Race Condition"></a>Race Condition</h2><h1 id="為什麼-a-會發生-race-condition"><a href="#為什麼-a-會發生-race-condition" class="headerlink" title="為什麼 a++ 會發生 race condition"></a>為什麼 a++ 會發生 race condition</h1><p>當你寫了 <code>a++</code> 時電腦實際上做了三件事：</p>
<ol>
<li>CPU 把 a 的值取出來</li>
<li>把剛剛取得的值加 1</li>
<li>把運算的結果存回變數 a</li>
</ol>
<p>但萬一你有<strong>多核 CPU</strong> 就有可能會這樣：</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ge0guxph51j301o00r3y9.jpg" alt="img"></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ge0gux2c7vj30kp09c0ss.jpg" alt="img" style="zoom:33%;" />

<p>兩個 CPU 同時去拿變數 a 的值，各自加 1 後存回，導致 a 只被加了一次，因此結果（9903）會小於正確的 10000</p>
<h2 id="解法：互斥鎖"><a href="#解法：互斥鎖" class="headerlink" title="解法：互斥鎖"></a>解法：互斥鎖</h2><p>這裡會發生 race condition 最根本的原因是「兩個 goroutine 可能會同時存取變數 a」，如果能限制<strong>同時只能有一個</strong> goroutine 做 <code>a++</code>，那就能解決這個問題，為了達到這個目的我們要使用 <code>sync.Mutex</code></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/11/Web/2019-12-11-WSGI/">Web/2019-12-11-WSGI</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Web/">Web</a></span><div class="content"><h3 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h3><p>WSGI describes the protocol between Server and Framework.</p>
<p>WSGI描述了Server与Framework之间通信的规范，简单来说，WSGI规范了以下几项内容：</p>
<ul>
<li>WSGI协议主要包括server和application两部分，server负责接受客户端请求并进行解析，然后将其传入application，客户端处理请求并将响应头和正文返回服务器（严格说来，还有一个模块叫做中间件middleware，但中间件也同样使用上述两种接口进行通讯）</li>
<li>从application的角度来说，它应当是一个可调用的对象（实现了<strong>call</strong> 函数的方法或者类），它接受两个参数：environ和start_response，其主要作用就是根据server传入的environ字典来生成一个“可迭代的”http报文并返回给server</li>
<li>从server的角度来说，其主要工作是解析http请求，生成一个environ字典并将其传递给可调用的application对象；另外，server还要实现一个start_response函数，其作用是生成响应头，start_response作为参数传入application中并被其调用</li>
</ul>
<p><img src="https://pic3.zhimg.com/80/v2-8e57dcd56fe8ae513f23a7855d5f62e6_hd.jpg" alt="v2-8e57dcd56fe8ae513f23a7855d5f62e6_hd"></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/11/Web/2019-12-11-sync_db_w_REPLACE/">Web/2019-12-11-sync_db_w_REPLACE</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-11</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Web/">Web</a></span><div class="content"><h3 id="Sync-DB-w-REPLACE"><a href="#Sync-DB-w-REPLACE" class="headerlink" title="Sync DB w/ REPLACE"></a>Sync DB w/ REPLACE</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> requests.auth <span class="keyword">import</span> HTTPBasicAuth</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConfJsonHandler</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, conf_json_root)</span>:</span></span><br><span class="line">        self.conf_json_root = conf_json_root</span><br><span class="line">        self.serv_b = ServB()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">upload_one_style_w_replace</span><span class="params">(self, style=<span class="string">'ZZZ'</span>)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Example Below:</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        <span class="comment"># obj.serv_b.post_filtering(filter_pat)       # 根据 filter_pat 拿data跟id</span></span><br><span class="line">        <span class="comment"># obj.serv_b.delete_by_filtering(filter_pat)  # 根据 filter_pat 找到的data的id作软删除</span></span><br><span class="line">        <span class="comment"># obj.serv_b.get_all_materials(&#123;'material_type': 'template', 'content.template':'测试测试'&#125;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># style = 'ZZZ'</span></span><br><span class="line">        local_style = self.style_mapper(style)  <span class="comment"># 'ZZZ' --&gt; '测试测试'</span></span><br><span class="line"></span><br><span class="line">        upload = <span class="literal">True</span>  <span class="comment"># <span class="doctag">TODO:</span> Set to True to upload to mongodb</span></span><br><span class="line">        filter_del = &#123;</span><br><span class="line">            <span class="string">"filter"</span>: &#123;<span class="string">'material_type'</span>: <span class="string">'template'</span>, <span class="string">'content.template'</span>: local_style&#125;&#125;  <span class="comment"># E.g. content.template: '光'</span></span><br><span class="line">        <span class="comment"># filter_del = &#123;"filter":&#123;'content.template':'aaa'&#125;&#125;</span></span><br><span class="line">        self.run_one_style(style, upload, filter_del)</span><br><span class="line"></span><br><span class="line">        filter_pat = filter_del</span><br><span class="line">        res = self.serv_b.post_filtering(filter_pat)</span><br><span class="line">        <span class="keyword">if</span> <span class="number">200</span> != res.status_code:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">"FAILED in upload_one_style_w_replace."</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">style_mapper</span><span class="params">(self, style)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> style == <span class="string">'A'</span>:</span><br><span class="line">            local_style = <span class="string">'AAA'</span></span><br><span class="line">        <span class="keyword">elif</span> style == <span class="string">'B'</span>:</span><br><span class="line">            local_style = <span class="string">'BBB'</span></span><br><span class="line">        <span class="keyword">elif</span> style == <span class="string">'C'</span>:</span><br><span class="line">            local_style = <span class="string">'CCC'</span></span><br><span class="line">        <span class="keyword">elif</span> style == <span class="string">'D'</span>:</span><br><span class="line">            local_style = <span class="string">'DDD'</span></span><br><span class="line">        <span class="keyword">elif</span> style == <span class="string">'G'</span>:</span><br><span class="line">            local_style = <span class="string">'EEE'</span></span><br><span class="line">        <span class="keyword">elif</span> style == <span class="string">'M'</span>:</span><br><span class="line">            local_style = <span class="string">'FFF'</span></span><br><span class="line">        <span class="comment"># elif style == 'E':</span></span><br><span class="line">        <span class="comment">#     local_style = 'GGG'</span></span><br><span class="line">        <span class="keyword">elif</span> style == <span class="string">'ZZZ'</span>:</span><br><span class="line">            local_style = <span class="string">'ZZZZZZZ'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">"&#123;&#125; has no corresponding chinese style"</span>.format(style))</span><br><span class="line">        <span class="keyword">return</span> local_style</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_post</span><span class="params">(self)</span>:</span></span><br><span class="line">        styles_paths = glob.glob(os.path.join(self.conf_json_root, <span class="string">'*'</span>))</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> styles_paths:      <span class="comment"># [A, B, C]</span></span><br><span class="line">            style = s.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">            self.run_one_style(style)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_one_style</span><span class="params">(self, style, upload, filter_del)</span>:</span></span><br><span class="line">        <span class="comment"># self.serv_b.set_filter_del(filter_del)</span></span><br><span class="line"></span><br><span class="line">        scs_paths = glob.glob(os.path.join(self.conf_json_root, style, <span class="string">'*'</span>))</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> scs_paths:         <span class="comment"># ['out_jsons/A/3_4_detail_res2_sc4',</span></span><br><span class="line">                                    <span class="comment"># 'out_jsons/A/3_4_detail_res2_sc3',</span></span><br><span class="line">                                    <span class="comment"># 'out_jsons/A/3_4_detail_res2_sc2', ,...]</span></span><br><span class="line">            print()</span><br><span class="line">            print(<span class="string">'-'</span>*<span class="number">20</span>, <span class="string">'Processing &#123;&#125;'</span>.format(s), <span class="string">'-'</span>*<span class="number">20</span>)</span><br><span class="line">            sc = s.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">            self.run_one_sc(style, sc, upload, filter_del)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_one_sc</span><span class="params">(self, style, sc, upload, filter_del)</span>:</span></span><br><span class="line">        conf_path = glob.glob(os.path.join(self.conf_json_root, style, sc, <span class="string">'*'</span>))[<span class="number">0</span>]</span><br><span class="line">                                    <span class="comment"># out_jsons/A/3_4_detail_res2_sc3/3_4_detail_res2_sc3.json</span></span><br><span class="line">        basename = os.path.basename(conf_path)</span><br><span class="line">                                    <span class="comment"># 3_4_detail_res2_sc3.json</span></span><br><span class="line">        basename_split = basename.split(<span class="string">'.'</span>)[<span class="number">0</span>].split(<span class="string">'_'</span>)</span><br><span class="line">        scale = basename_split[<span class="number">0</span>] + <span class="string">':'</span> + basename_split[<span class="number">1</span>]     <span class="comment"># 3_4 --&gt; 3:4</span></span><br><span class="line">        intent = basename_split[<span class="number">2</span>]  <span class="comment"># detail</span></span><br><span class="line">        img = basename_split[<span class="number">-3</span>]    <span class="comment"># img2 <span class="doctag">TODO:</span> use re to support number &gt; 10</span></span><br><span class="line">        vid = basename_split[<span class="number">-2</span>]   <span class="comment"># vid0</span></span><br><span class="line">        sc = basename_split[<span class="number">-1</span>]    <span class="comment"># sc3</span></span><br><span class="line">        <span class="keyword">with</span> open(conf_path, <span class="string">'r+'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            conf = json.load(f)</span><br><span class="line"></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        Info for payload </span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        id = conf_path</span><br><span class="line">        template = self.style_mapper(style)</span><br><span class="line">        pic_num = int(<span class="string">""</span>.join(re.findall(<span class="string">r"\d+"</span>, img)))</span><br><span class="line">        vid_num = int(<span class="string">""</span>.join(re.findall(<span class="string">r"\d+"</span>, vid)))</span><br><span class="line">        config = conf</span><br><span class="line">        stage = self.intent_mapper(intent)</span><br><span class="line">        style = sc</span><br><span class="line">        scale = scale</span><br><span class="line"></span><br><span class="line">        payload = self.pkg_payload(id=id, template=template, pic_num=pic_num, vid_num = vid_num, config=config, stage=stage, style=style, scale=scale)</span><br><span class="line">        <span class="comment"># payload = &#123;"bbb":55, "ccc":999&#125;</span></span><br><span class="line">        <span class="comment"># payload = config</span></span><br><span class="line">        <span class="comment"># exit()</span></span><br><span class="line">        print(<span class="string">'payload to upload: &#123;&#125;'</span>.format(payload))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_del:</span><br><span class="line">            self.serv_b.delete_by_filtering(filter_del)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> set upload to True if going to upload</span></span><br><span class="line">        <span class="keyword">if</span> upload:</span><br><span class="line">            self.serv_b.post(payload)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intent_mapper</span><span class="params">(self, intent)</span>:</span></span><br><span class="line">        <span class="comment">###</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> d.get(intent, <span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pkg_payload</span><span class="params">(self, id:int, template:str, pic_num:int, vid_num:int, config:json, stage:list, style:str, scale:str)</span> -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        print(<span class="string">'in pkg_payload'</span>)</span><br><span class="line">        payload = &#123;</span><br><span class="line">            <span class="string">"id"</span>:id,</span><br><span class="line">            <span class="string">"template"</span>:template,</span><br><span class="line">            <span class="string">"pic_num"</span>:pic_num,</span><br><span class="line">            <span class="string">"vid_num"</span>:vid_num,</span><br><span class="line">            <span class="string">"config"</span>:config,</span><br><span class="line">            <span class="string">"stage"</span>:stage,</span><br><span class="line">            <span class="string">"style"</span>:style,</span><br><span class="line">            <span class="string">"scale"</span>:scale</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> payload</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ServB</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, account=<span class="string">''</span>, pw=<span class="string">''</span>)</span>:</span></span><br><span class="line"></span><br><span class="line">        self.account = <span class="string">'serv_b-admin'</span></span><br><span class="line">        self.pw = <span class="string">'passwd'</span></span><br><span class="line">        self.filter_del = <span class="literal">None</span></span><br><span class="line">        <span class="comment"># self.account = 'user@xxxxxxxxxxxxx.com'</span></span><br><span class="line">        <span class="comment"># if not pw:</span></span><br><span class="line">        <span class="comment">#     fname = 'password.txt'</span></span><br><span class="line">        <span class="comment">#     with open(fname, 'r+') as f:</span></span><br><span class="line">        <span class="comment">#         pw = f.readline().strip()</span></span><br><span class="line">        <span class="comment">#         self.pw = pw</span></span><br><span class="line">        <span class="comment"># else:</span></span><br><span class="line">        <span class="comment">#     self.pw = pw</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_filter_del</span><span class="params">(self, filter_del=None)</span>:</span></span><br><span class="line">        self.filter_del = filter_del</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(self, payload)</span>:</span></span><br><span class="line">        print(<span class="string">"=== In POST ALL ==="</span>)</span><br><span class="line">        <span class="comment"># POST</span></span><br><span class="line">        <span class="comment"># payload = &#123;"bbb":55, "ccc":88&#125;</span></span><br><span class="line">        res = <span class="string">"/api/v3/add/materials"</span></span><br><span class="line">        res = requests.post(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw),</span><br><span class="line">                        json=&#123;<span class="string">"material_content"</span>:payload, <span class="string">"material_type"</span>:<span class="string">"template"</span>&#125;)</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        print(json.dumps(res.json(), ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post_one_testing_data</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># POST</span></span><br><span class="line">        payload = &#123;<span class="string">"bbb"</span>:<span class="number">55</span>, <span class="string">"ccc"</span>:<span class="number">88</span>&#125;</span><br><span class="line">        res = <span class="string">"/api/v3/add/materials"</span></span><br><span class="line">        res = requests.post(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw),</span><br><span class="line">                            json=&#123;<span class="string">"material_content"</span>:payload, <span class="string">"material_type"</span>:<span class="string">"helloworld"</span>&#125;)</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        print(json.dumps(res.json(), ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">put</span><span class="params">(self, payload, id)</span>:</span></span><br><span class="line">        <span class="comment"># PUT</span></span><br><span class="line">        res = <span class="string">"/api/v3/dp_materials"</span></span><br><span class="line">        res = requests.post(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw),</span><br><span class="line">                            json=&#123;<span class="string">"content"</span>:payload&#125;)</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        print(json.dumps(res.json(), ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">put_one_by_id</span><span class="params">(self, payload, id=<span class="string">'c42f7c9aaf01463f88b01d46e7d0b850'</span>)</span>:</span></span><br><span class="line">        <span class="comment"># PUT</span></span><br><span class="line">        payload = &#123;<span class="string">"bbb"</span>:<span class="number">55</span>, <span class="string">"ccc"</span>:<span class="number">7777</span>&#125;</span><br><span class="line">        res = <span class="string">"/api/v3/dp_materials/"</span> + str(id)</span><br><span class="line">        res = requests.put(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw),</span><br><span class="line">                            json=&#123;<span class="string">"content"</span>:payload&#125;)</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        print(json.dumps(res.json()))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post_filtering</span><span class="params">(self, filter)</span>:</span></span><br><span class="line">        print(<span class="string">"In POST_FILTERING()"</span>)</span><br><span class="line">        res = <span class="string">"/api/v3/search/dp_materials"</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            res = requests.post(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw),</span><br><span class="line">                           json=filter)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">"Invalid filter for post: &#123;&#125;"</span>.format(filter))</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        <span class="comment"># print(res.text)</span></span><br><span class="line">        print(<span class="string">'post filtering: &#123;&#125;'</span>.format(json.dumps(res.json(), ensure_ascii=<span class="literal">False</span>)))</span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delete_by_id</span><span class="params">(self, id=<span class="string">'f18c4278016643e7b84815279dbef12f'</span>)</span>:</span></span><br><span class="line">        res = <span class="string">"/api/v3/dp_materials/"</span> + str(id)</span><br><span class="line">        res = requests.delete(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw))</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        print(json.dumps(res.json(), ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_materials</span><span class="params">(self, filter)</span>:</span></span><br><span class="line">        res = <span class="string">"/api/v3/dp_materials"</span></span><br><span class="line">        res = requests.get(<span class="string">"https://serv_b2.xxxxxxxxxxxxx.com"</span>+res, auth=HTTPBasicAuth(self.account, self.pw),</span><br><span class="line">                            <span class="comment"># json=filter)</span></span><br><span class="line">                           params=filter)</span><br><span class="line">        print(res.status_code)</span><br><span class="line">        <span class="comment"># print(res.text)</span></span><br><span class="line">        print(json.dumps(res.json(), ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">delete_by_filtering</span><span class="params">(self, filter)</span>:</span></span><br><span class="line">        print(<span class="string">"In DELETE_BY_FILTERING()"</span>)</span><br><span class="line">        res = self.post_filtering(filter)</span><br><span class="line">        <span class="keyword">if</span> res.status_code != <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">"Faid filtering existing data to Delete.."</span>)</span><br><span class="line"></span><br><span class="line">        count = res.json().get(<span class="string">'count'</span>, <span class="number">0</span>)</span><br><span class="line">        data = res.json().get(<span class="string">'data'</span>, &#123;&#125;)</span><br><span class="line">        <span class="keyword">assert</span>(count == len(data))</span><br><span class="line">        <span class="keyword">if</span> <span class="number">0</span> == count:</span><br><span class="line">            print(<span class="string">'No data to be deleted..'</span>)</span><br><span class="line"></span><br><span class="line">        ids = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">            ids.append(item.get(<span class="string">'material_id'</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> id <span class="keyword">in</span> ids:</span><br><span class="line">            self.delete_by_id(id)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    run_all = <span class="literal">False</span></span><br><span class="line">    print(<span class="string">'='</span>*<span class="number">40</span>)</span><br><span class="line">    conf_json_root = <span class="string">'out_jsons'</span>    <span class="comment"># <span class="doctag">TODO:</span> use argumentParse</span></span><br><span class="line">    <span class="comment"># conf_json_root = 'trans_jsons'    # <span class="doctag">TODO:</span> use argumentParse</span></span><br><span class="line"></span><br><span class="line">    obj = ConfJsonHandler(conf_json_root)</span><br><span class="line">    <span class="keyword">if</span> run_all:</span><br><span class="line">        obj.run_post()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># obj.serv_b.post_one_testing_data()</span></span><br><span class="line">    <span class="comment"># obj.serv_b.put_one_testing_data(&#123;"bbb":53335, "ccc":666&#125;)   # replace existing data w/ a new one</span></span><br><span class="line"></span><br><span class="line">    obj.upload_one_style_w_replace(<span class="string">'ZZZ'</span>)</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Example Below:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># obj.serv_b.post_filtering(filter_pat)       # 根据 filter_pat 拿data跟id</span></span><br><span class="line">    <span class="comment"># obj.serv_b.delete_by_filtering(filter_pat)  # 根据 filter_pat 找到的data的id作软删除</span></span><br><span class="line">    <span class="comment"># obj.serv_b.get_all_materials(&#123;'material_type': 'template', 'content.template':'测试测试'&#125;)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># style = 'ZZZ'</span></span><br><span class="line">    <span class="comment"># local_style = obj.style_mapper(style)  # 'ZZZ' --&gt; '测试测试'</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># upload = True  # <span class="doctag">TODO:</span> Set to True to upload to mongodb</span></span><br><span class="line">    <span class="comment"># filter_del = &#123;</span></span><br><span class="line">    <span class="comment">#     "filter": &#123;'material_type': 'template', 'content.template': local_style&#125;&#125;  # E.g. content.template: '光'</span></span><br><span class="line">    <span class="comment"># obj.run_one_style(style, upload, filter_del)</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># filter_pat = filter_del</span></span><br><span class="line">    <span class="comment"># res = obj.serv_b.post_filtering(filter_pat)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> query by content.config.path</span></span><br><span class="line">    <span class="comment"># obj.serv_b.delete_by_id()</span></span><br></pre></td></tr></table></figure>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/12/10/NLP/2019-12-10-Bagging%20vs%20Boosting/">NLP/2019-12-10-Bagging vs Boosting</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-12-10</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/ML/">ML</a></span><div class="content"><p>ref: <a href="https://www.cnblogs.com/liuwu265/p/4690486.html" target="_blank" rel="noopener">https://www.cnblogs.com/liuwu265/p/4690486.html</a></p>
<h3 id="Bagging-vs-Boosting"><a href="#Bagging-vs-Boosting" class="headerlink" title="Bagging vs Boosting"></a>Bagging vs Boosting</h3><p>“　</p>
<p>　Bagging和Boosting都是将已有的分类或回归算法通过一定方式组合起来，形成一个性能更加强大的分类器，更准确的说这是一种分类算法的组装方法。即将弱分类器组装成强分类器的方法。</p>
<p>首先介绍Bootstraping，即自助法：它是一种有放回的抽样方法（可能抽到重复的样本）。</p>
<p>1、Bagging (bootstrap aggregating)</p>
<p>Bagging即套袋法，其算法过程如下：</p>
<p>A）从原始样本集中抽取训练集。每轮从原始样本集中使用Bootstraping的方法抽取n个训练样本（在训练集中，有些样本可能被多次抽取到，而有些样本可能一次都没有被抽中）。共进行k轮抽取，得到k个训练集。（k个训练集之间是相互独立的）</p>
<p>B）每次使用一个训练集得到一个模型，k个训练集共得到k个模型。（注：这里并没有具体的分类算法或回归方法，我们可以根据具体问题采用不同的分类或回归方法，如决策树、感知器等）</p>
<p>C）对分类问题：将上步得到的k个模型采用投票的方式得到分类结果；对回归问题，计算上述模型的均值作为最后的结果。（所有模型的重要性相同）</p>
<p>2、Boosting</p>
<p>其主要思想是将弱分类器组装成一个强分类器。在PAC（概率近似正确）学习框架下，则一定可以将弱分类器组装成一个强分类器。</p>
<p>关于Boosting的两个核心问题：</p>
<p>1）在每一轮如何改变训练数据的权值或概率分布？</p>
<p>通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据有较好的效果。</p>
<p>2）通过什么方式来组合弱分类器？</p>
<p>通过加法模型将弱分类器进行线性组合，比如AdaBoost通过加权多数表决的方式，即增大错误率小的分类器的权值，同时减小错误率较大的分类器的权值。</p>
<p>而提升树通过拟合残差的方式逐步减小残差，将每一步生成的模型叠加得到最终模型。</p>
<p>3、Bagging，Boosting二者之间的区别</p>
<p>Bagging和Boosting的区别：</p>
<p>1）样本选择上：</p>
<p>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。</p>
<p>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</p>
<p>2）样例权重：</p>
<p>Bagging：使用均匀取样，每个样例的权重相等</p>
<p>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。</p>
<p>3）预测函数：</p>
<p>Bagging：所有预测函数的权重相等。</p>
<p>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</p>
<p>4）并行计算：</p>
<p>Bagging：各个预测函数可以并行生成</p>
<p>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p>
<p>4、总结</p>
<p>这两种方法都是把若干个分类器整合为一个分类器的方法，只是整合的方式不一样，最终得到不一样的效果，将不同的分类算法套入到此类算法框架中一定程度上会提高了原单一分类器的分类效果，但是也增大了计算量。</p>
<p>下面是将决策树与这些算法框架进行结合所得到的新的算法：</p>
<p>1）Bagging + 决策树 = 随机森林</p>
<p>2）AdaBoost + 决策树 = 提升树</p>
<p>3）Gradient Boosting + 决策树 = GBDT</p>
<p> “</p>
<p>参考文献</p>
<p>[1] 林轩田，机器学习技法。</p>
<p>[2] IRLAB, <a href="http://www.cnblogs.com/guolei/archive/2013/05/21/3091301.html" target="_blank" rel="noopener">http://www.cnblogs.com/guolei/archive/2013/05/21/3091301.html</a></p>
<p>[3] 百度技术，<a href="http://baidutech.blog.51cto.com/4114344/743809/" target="_blank" rel="noopener">http://baidutech.blog.51cto.com/4114344/743809/</a></p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/26/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/26/">26</a><span class="page-number current">27</span><a class="page-number" href="/page/28/">28</a><span class="space">&hellip;</span><a class="page-number" href="/page/80/">80</a><a class="extend next" rel="next" href="/page/28/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>