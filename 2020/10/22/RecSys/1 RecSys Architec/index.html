<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="RecSys/1 RecSys Architec"><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>RecSys/1 RecSys Architec | Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Recommendation-System"><span class="toc-number">1.</span> <span class="toc-text">Recommendation System</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Behaviour-based"><span class="toc-number">1.1.</span> <span class="toc-text">Behaviour-based</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Content-based"><span class="toc-number">1.2.</span> <span class="toc-text">Content-based</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Recall"><span class="toc-number">1.2.0.0.1.</span> <span class="toc-text">Recall</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Sorting-by-prob"><span class="toc-number">1.2.0.0.2.</span> <span class="toc-text">Sorting (by prob. )</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Adjustment"><span class="toc-number">1.2.0.0.3.</span> <span class="toc-text">Adjustment</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#"><span class="toc-number">1.2.0.0.4.</span> <span class="toc-text"></span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recall-paths"><span class="toc-number">1.3.</span> <span class="toc-text">Recall paths</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Netflix-case"><span class="toc-number">2.</span> <span class="toc-text">Netflix case</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CF-Collaborative-Filtering"><span class="toc-number">3.</span> <span class="toc-text">CF, Collaborative Filtering</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Word2Vec"><span class="toc-number">4.</span> <span class="toc-text">Word2Vec</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Doc2Vec"><span class="toc-number">5.</span> <span class="toc-text">Doc2Vec</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Cold-Start"><span class="toc-number">6.</span> <span class="toc-text">Cold Start</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Embeddings"><span class="toc-number">7.</span> <span class="toc-text">Embeddings</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CosineDistance-VS-FAISS"><span class="toc-number">8.</span> <span class="toc-text">CosineDistance VS FAISS</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">406</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">73</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">RecSys/1 RecSys Architec</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-10-22</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/RecSys/">RecSys</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>根據用戶的歷史info &amp; 行為，作推薦他感興趣的內容</p>
<h1 id="Recommendation-System"><a href="#Recommendation-System" class="headerlink" title="Recommendation System"></a>Recommendation System</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">	A(Recommendation System)</span><br><span class="line">	B1(Collaborative Filtering)</span><br><span class="line">	B2(Content-Based)</span><br><span class="line">	B3(Hybrid)</span><br><span class="line">	C1(Stat-Based CF)</span><br><span class="line">	C2(Model-Based CF, 矩陣分解)</span><br><span class="line">	A --&gt; B1</span><br><span class="line">	A --&gt; B2</span><br><span class="line">	A --&gt; B3</span><br><span class="line">	B1 --&gt; C1</span><br><span class="line">	B1 --&gt; C2</span><br></pre></td></tr></table></figure>





<h2 id="Behaviour-based"><a href="#Behaviour-based" class="headerlink" title="Behaviour-based"></a>Behaviour-based</h2><p>主要指的是Collaborative Filtering，我的好友、或是跟我做過一樣事的人也喜歡什麼，就推薦過去，例子是電影</p>
<p>另外可用的是用戶聚類推薦</p>
<h2 id="Content-based"><a href="#Content-based" class="headerlink" title="Content-based"></a>Content-based</h2><p>w/ tag，如我做過某些事的標籤，如電影的科幻類別，如python，就可能是big data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	Item --&gt; items(&quot;蜘蛛人: action、scifi; Ironman: action, scifi;..&quot;)</span><br><span class="line">	User --&gt; itemsHistory --&gt; 偏好向量(&quot;偏好向量: [action: 3; scifi: 2] &quot;)</span><br><span class="line">	偏好向量 --&gt; recToUser(&quot;推給User: e.g. Dr. Strange; Batman&quot;) --&gt; User</span><br></pre></td></tr></table></figure>

<ul>
<li><p>優: 不需其他user data</p>
</li>
<li><p>缺: 需人工tagging、侷限在自己世界難挖出「潛在興趣」、cool start</p>
</li>
<li><p>Flow</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">  graph LR</span><br><span class="line">  	A[&quot;內容獲取&lt;br&gt;ID, title, intro&quot;]  </span><br><span class="line">  	B[&quot;中文分詞-提取關鍵詞&lt;br&gt;tool: jieba&quot;]</span><br><span class="line">  	C[&quot;Word2Vec&lt;br&gt;tools: Tencent&#39;s or Spark&#39;s&quot;]	</span><br><span class="line">  	D[&quot;Doc2Vec&lt;br&gt;with 加權平均&quot;]</span><br><span class="line">  	E[&quot;TopK近鄰搜索&lt;br&gt;scipy&#39;s cosine distance&lt;br&gt;LSH局部敏感哈希&quot;]</span><br><span class="line">  	F[&quot;redis&lt;br&gt;item- &gt; list&lt;item&gt;&quot;]</span><br><span class="line">  	G[&quot;Flask&#x2F;Java Web&lt;br&gt;根據item返回列表&quot;]</span><br><span class="line">  	A --&gt; B --&gt; C</span><br><span class="line">  	B --&gt; D</span><br><span class="line">  	C --&gt; D</span><br><span class="line">  	D --&gt; E</span><br><span class="line">  	E --&gt; F</span><br><span class="line">  	F --&gt; G</span><br><span class="line"></span><br><span class="line">​			jieba: 基於tf-idf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## The Solution to Problems </span><br><span class="line"></span><br><span class="line">解決的問題？</span><br><span class="line"></span><br><span class="line">1. 信息過載：商品、視頻等有好幾百萬</span><br><span class="line">   - 用戶：怎樣找到自己感興趣的物品？</span><br><span class="line">   - 系統：怎樣展示幾百萬的物品給用戶，達到自己的商業目標？</span><br><span class="line"></span><br><span class="line">2. 挖掘長尾 The Long Tail Module：</span><br><span class="line">   - 大部分的冷門物品得不到暴露，然而他們的加和價值超過熱門物品</span><br><span class="line">   - 亞馬遜圖書分類57%的收入來自長尾冷門的書籍</span><br><span class="line"></span><br><span class="line">3. 用戶體驗：</span><br><span class="line"></span><br><span class="line">   - 搜索：當明確自己的目標的時候，我們用搜索引擎</span><br><span class="line"></span><br><span class="line">   - 推薦：當不明確的時候，推薦系統推薦我們感興趣的商品</span><br><span class="line"></span><br><span class="line">     一個系統推薦了我很感興趣，但是自己很難發現的物品</span><br><span class="line"></span><br><span class="line">     想一想逛京東、亞馬遜，買了自己不需要物品</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### Steps</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;mermaid</span><br><span class="line">graph LR</span><br><span class="line">	input --&gt; Recall(Recall) --&gt; Sorting(Sorting) --&gt; Adjustment(Adjustment) --&gt; ouptut</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h5><p>從億下沉到萬級別，從海量得到少量的內容</p>
<p>Quick – 50ms ~ 300ms</p>
<ul>
<li>CF</li>
<li>Content-based</li>
<li>Graph</li>
<li>Hot</li>
<li>New</li>
</ul>
<h5 id="Sorting-by-prob"><a href="#Sorting-by-prob" class="headerlink" title="Sorting (by prob. )"></a>Sorting (by prob. )</h5><ul>
<li>Binary<ul>
<li>LR</li>
<li>GBDT</li>
<li>DNN</li>
<li>Wide&amp;Deep (Ggl’s)</li>
</ul>
</li>
</ul>
<h5 id="Adjustment"><a href="#Adjustment" class="headerlink" title="Adjustment"></a>Adjustment</h5><ul>
<li>de-dup<ul>
<li>Bought</li>
<li>Off-line</li>
</ul>
</li>
<li>Hot 補足</li>
<li>Pagination，提一段id呈現出</li>
<li>Merge id w/ other features</li>
</ul>
<h5 id=""><a href="#" class="headerlink" title=""></a></h5><h2 id="Recall-paths"><a href="#Recall-paths" class="headerlink" title="Recall paths"></a>Recall paths</h2><p>推薦系統中的r2i、u2i、u22iu2u2i、u2tag2是什麼意思？</p>
<p>基準邊們</p>
<ul>
<li><p>I2I</p>
<p>如從一篇文章到一篇相似的文章</p>
<p>算法如下，</p>
<ul>
<li>內容相似 (兩篇標題相似的文章)、</li>
<li>協同過濾或關聯規則挖掘等</li>
</ul>
</li>
<li><p>U2I</p>
<p>來源於用戶的直接行為，比如從用戶的播放/點擊/購買等作觀察</p>
<p>如點過耳機，就推你耳機</p>
</li>
</ul>
<p>延伸邊們</p>
<ul>
<li><p>U2I2I</p>
<p>基於item的協同過濾<br>或先得到用戶的行為列表然後查I2I做擴展</p>
</li>
<li><p>U2U2I</p>
<p>基於用戶的協同過濾<br>用戶畫像相似然後推薦<br>用戶聚類推薦</p>
</li>
<li><p>U2Tag2I</p>
<p>先算出用戶的tag偏好然後匹配item列表<br>如，統計戶用看過的書籍，可算出他偏好的tag向量<br>然後書籍已帶tag，所以item反推往tag是有泛化性，如頭條、fb等</p>
</li>
<li><p>U2***2I<br>PersonalRank, 在游走的時候還帶著probability </p>
</li>
</ul>
<p>多路召回時，依算法權重作 1)粗排TopK 2)精排</p>
<h1 id="Netflix-case"><a href="#Netflix-case" class="headerlink" title="Netflix case"></a>Netflix case</h1><h1 id="CF-Collaborative-Filtering"><a href="#CF-Collaborative-Filtering" class="headerlink" title="CF, Collaborative Filtering"></a>CF, Collaborative Filtering</h1><ul>
<li><p>U2U2I 和我興趣相投的人也喜歡 xxx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	subgraph Users</span><br><span class="line">	U1 </span><br><span class="line">	U2 </span><br><span class="line">	U3 </span><br><span class="line">	U4</span><br><span class="line">	end</span><br><span class="line"></span><br><span class="line">	subgraph Items</span><br><span class="line">	I1 </span><br><span class="line">	I2 </span><br><span class="line">	I3 </span><br><span class="line">	I4</span><br><span class="line">	end</span><br><span class="line">	</span><br><span class="line">	U1 --&gt; I1</span><br><span class="line">	U1 --&gt; I2</span><br><span class="line">	U2 --&gt; I1</span><br><span class="line">	U2 --&gt; I2</span><br><span class="line">	U2 --&gt; I4	</span><br><span class="line">	U4 --&gt; I1</span><br><span class="line">	U4 --&gt; I2	</span><br><span class="line">	U4 --&gt; I4</span><br></pre></td></tr></table></figure>

<p>因為U2, U4都喜歡I1, 而U1也喜歡I1，所以推U2、U4喜歡的I4給I1</p>
<ul>
<li>如何找最相似的用戶？Jarccard(聯、交集，沒考慮實際的評分數字)、cosine(ok，不錯用了)、Pierrson(把缺失值用那個人有rating的平均分補上後，作cosine)</li>
<li>問題: U1是否喜歡某樣他未rating過的item呢？從跟他相似的人中找「加權harmonoc平均」</li>
</ul>
</li>
<li><p>U2I2I 基於物品的 – 喜歡這個物品的人也喜歡 xxx<br>如大部份喜歡I2的人也都喜歡I3，所以我們覺I2跟I3有</p>
</li>
</ul>
<ul>
<li>矩陣分解解釋為透過 latent factor (隱含特徵)將user興趣與item特徵作關聯</li>
<li>優缺點<ul>
<li>優點<ul>
<li>解決了sparse 問題</li>
<li>精度高於基於領域的CF以及content-based</li>
</ul>
</li>
<li>缺點<ul>
<li>推薦結果無法解釋，隱空間的維度無法與現實中的概念對應</li>
<li>訓練費時，只能以天粒度offline training</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><ul>
<li>Tencent <a href="https://gitee.com/link?target=https%3A%2F%2Fai.tencent.com%2Failab%2Fnlp%2Fembedding.html">https://ai.tencent.com/ailab/nlp/embedding.html</a><ul>
<li>[03. 使用腾讯开源Word2vec实现内容相似推荐.ipynb · peiss/ant-learn-recsys - 码云 - 开源中国 (gitee.com)](<a href="https://gitee.com/antpython/ant-learn-recsys/blob/master/03" target="_blank" rel="noopener">https://gitee.com/antpython/ant-learn-recsys/blob/master/03</a>. 使用腾讯开源Word2vec实现内容相似推荐.ipynb)</li>
</ul>
</li>
<li>Spark Word2Vec</li>
</ul>
<table>
<thead>
<tr>
<th>屬性/特點</th>
<th>騰訊開源的 <code>word2vec</code> 代碼</th>
<th><code>gensim</code> 的 <code>word2vec</code> &amp; <code>doc2vec</code></th>
</tr>
</thead>
<tbody><tr>
<td><strong>嵌入的來源</strong></td>
<td>使用騰訊預訓練的模型</td>
<td>允許從頭開始或使用預訓練的模型</td>
</tr>
<tr>
<td><strong>文檔表示</strong></td>
<td>單詞嵌入的平均值（忽略順序信息）</td>
<td><code>doc2vec</code>保留單詞的順序信息</td>
</tr>
<tr>
<td><strong>易用性和擴展性</strong></td>
<td>手動處理嵌入文件的格式，可能需要更多手動調整</td>
<td>方便的API，簡單和直觀</td>
</tr>
<tr>
<td><strong>性能</strong></td>
<td>快速，尤其是在不需訓練的情況下</td>
<td>對於大型數據集或訓練模型，可能更適合</td>
</tr>
</tbody></table>
<h1 id="Doc2Vec"><a href="#Doc2Vec" class="headerlink" title="Doc2Vec"></a>Doc2Vec</h1><p><code>gensim</code> 是最受歡迎和廣泛使用的Python庫。它提供了一個很好的實現，使得建模和訓練文檔向量非常直觀。</p>
<p>以下是使用 <code>gensim</code> 來計算 <code>doc2vec</code> 的基本步驟：</p>
<ol>
<li><p><strong>使用</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">pythonCopy code</span><br><span class="line"><span class="keyword">from</span> gensim.models.doc2vec <span class="keyword">import</span> Doc2Vec, TaggedDocument</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假設文檔列表如下</span></span><br><span class="line">documents = [<span class="string">"This is the first document."</span>,</span><br><span class="line">             <span class="string">"This document is the second document."</span>,</span><br><span class="line">             <span class="string">"And this is the third one."</span>,</span><br><span class="line">             <span class="string">"Is this the first document?"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用NLTK進行基本的詞斷詞</span></span><br><span class="line">tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) <span class="keyword">for</span> i, _d <span class="keyword">in</span> enumerate(documents)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 訓練模型</span></span><br><span class="line">model = Doc2Vec(vector_size=<span class="number">20</span>, window=<span class="number">2</span>, min_count=<span class="number">1</span>, workers=<span class="number">4</span>, epochs=<span class="number">100</span>)</span><br><span class="line">model.build_vocab(tagged_data)</span><br><span class="line">model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取得文檔的向量</span></span><br><span class="line">vector = model.infer_vector(word_tokenize(<span class="string">"This is a new sentence."</span>.lower()))</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>除了 <code>gensim</code>，還有其他工具和庫，如<code>spaCy</code>和<code>fastText</code>，也提供了文檔向量的功能，但<code>gensim</code>的<code>doc2vec</code>實現被廣泛認為是此領域的黃金標準。</p>
<h1 id="Cold-Start"><a href="#Cold-Start" class="headerlink" title="Cold Start"></a>Cold Start</h1><ul>
<li>解決物品冷啟動<ul>
<li>方法一: 通過內容相似度計算，把新物品帶出來</li>
<li>方法二: 抖音的多級流量池機制</li>
</ul>
</li>
</ul>
<h1 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h1><p>產出、訓練 user embedding, item embedding</p>
<ul>
<li>Item2Vec</li>
<li>矩陣分解</li>
<li>雙塔DNN</li>
</ul>
<h1 id="CosineDistance-VS-FAISS"><a href="#CosineDistance-VS-FAISS" class="headerlink" title="CosineDistance VS FAISS"></a>CosineDistance VS FAISS</h1><p>場景:</p>
<p>​    Embedding 的近鄰搜索是推薦系統非常重要的一種召回方式，方法有</p>
<ul>
<li>User * Item –&gt; 推薦User感興趣的Items</li>
<li>User * User –&gt;  推薦User感興趣的Users</li>
<li>Item * Item –&gt; 基於Item推薦相關Items</li>
</ul>
<p>FAISS為Facebook AI團隊開源的針對聚類和相似性搜索庫，為dense vectors提供高效相似度搜索和聚類，支持十億級別向量的搜索</p>
<table>
<thead>
<tr>
<th>屬性/方法</th>
<th><code>scipy</code> 的 <code>distance.cosine</code></th>
<th>Facebook AI 的 <code>faiss</code></th>
</tr>
</thead>
<tbody><tr>
<td><strong>效率</strong></td>
<td>較適合小至中型數據集</td>
<td>設計用於大規模數據和高維度向量的高效搜索</td>
</tr>
<tr>
<td><strong>擴展性</strong></td>
<td>適合小型數據集</td>
<td>可輕鬆處理大規模數據（如數十萬或數百萬項目）</td>
</tr>
<tr>
<td><strong>易用性</strong></td>
<td>簡單、直觀</td>
<td>提供更多配置和優化選項，有一定的學習曲線</td>
</tr>
<tr>
<td><strong>硬件加速</strong></td>
<td>不支持</td>
<td>支持GPU加速</td>
</tr>
</tbody></table>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Joe Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/10/22/RecSys/1%20RecSys%20Architec/">http://yoursite.com/2020/10/22/RecSys/1%20RecSys%20Architec/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/10/22/Algo.%20Ult./note/"><i class="fa fa-chevron-left">  </i><span>Algo. Ult./note</span></a></div><div class="next-post pull-right"><a href="/2020/10/22/RecSys/2%20RecSys%20Techs/"><span>RecSys/2 RecSys Techs</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2024 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>