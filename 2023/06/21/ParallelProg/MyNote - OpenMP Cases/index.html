<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="ParallelProg/MyNote - OpenMP Cases"><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>ParallelProg/MyNote - OpenMP Cases | Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Parallel-Regions"><span class="toc-number">1.</span> <span class="toc-text">Parallel Regions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Nested-Parallelism"><span class="toc-number">1.1.</span> <span class="toc-text">Nested Parallelism</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Loop-Parallelism"><span class="toc-number">2.</span> <span class="toc-text">Loop Parallelism</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Nested-Loops"><span class="toc-number">2.1.</span> <span class="toc-text">Nested Loops</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SIMD-Processing"><span class="toc-number">3.</span> <span class="toc-text">SIMD Processing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#"><span class="toc-number">4.</span> <span class="toc-text"></span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">400</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">70</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">ParallelProg/MyNote - OpenMP Cases</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-21</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/ParallelProg/">ParallelProg</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="Parallel-Regions"><a href="#Parallel-Regions" class="headerlink" title="Parallel Regions"></a>Parallel Regions</h2><p>The following example uses parallelism for an actual calculation:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = f(x)+g(x)+h(x)</span><br></pre></td></tr></table></figure>

<p>could parallelize this as</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span> result,fresult,gresult,hresult;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123; <span class="keyword">int</span> num = omp_get_thread_num();</span><br><span class="line">  <span class="keyword">if</span> (num==<span class="number">0</span>)      fresult = f(x);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (num==<span class="number">1</span>) gresult = g(x);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (num==<span class="number">2</span>) hresult = h(x);</span><br><span class="line">&#125;</span><br><span class="line">result = fresult + gresult + hresult;</span><br></pre></td></tr></table></figure>



<p><strong>Remark</strong>  In 5.1 the master construct will be deprecated, and masked (with added functionality) will take its place. </p>
<h3 id="Nested-Parallelism"><a href="#Nested-Parallelism" class="headerlink" title="Nested Parallelism"></a>Nested Parallelism</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">  &#123;</span><br><span class="line">  ...</span><br><span class="line">  func(...)</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="comment">// end of main</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(...)</span> </span>&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">  &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>OMP_MAX_ACTIVE_LEVELS</code> (default: 1) to set the number of levels of parallel nesting. Equivalently, there are functions <code>omp_set_max_active_levels</code> and</li>
</ul>
<h2 id="Loop-Parallelism"><a href="#Loop-Parallelism" class="headerlink" title="Loop Parallelism"></a>Loop Parallelism</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123;</span><br><span class="line">  code1();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp for</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=<span class="number">4</span>*N; i++) &#123;</span><br><span class="line">    code2();</span><br><span class="line">  &#125;</span><br><span class="line">  code3();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="https://p.ipic.vip/juxv0n.png" alt="image-20230621202839429" style="zoom: 50%;" />

<ul>
<li>Loop cannot contain break, return ,exit</li>
<li>OK to have continue </li>
<li>Index should be an increment (or decrement) by a <u>fixed amount</u>, and no changes inside the lo</li>
</ul>
<h3 id="Nested-Loops"><a href="#Nested-Loops" class="headerlink" title="Nested Loops"></a>Nested Loops</h3><ul>
<li><code>collapse(num)</code> can only collapse “perfectly nested loops” – outer loop can consist ONLY of the inner loop;</li>
</ul>
<h2 id="SIMD-Processing"><a href="#SIMD-Processing" class="headerlink" title="SIMD Processing"></a>SIMD Processing</h2><p><strong>Remark</strong> Depending on your compiler, it may be necessary to give an extra option enabling SIMD:</p>
<ul>
<li><code>-fopenmp-simd</code> for <em>GCC</em> / <em>Clang</em> , and</li>
<li><code>-qopenmp-simd</code> for <em>ICC</em> .</li>
</ul>
<p>end of remark</p>
<p>If a loop is both multi-threadable and vectorizable, you can combine directives as <code>pragma omp parallel for simd</code> .</p>
<p>Compilers can be made to report whether a loop was vectorized:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOOP BEGIN at simdf.c(61,15)</span><br><span class="line">   remark #15301: OpenMP SIMD LOOP WAS VECTORIZED</span><br><span class="line">LOOP END</span><br></pre></td></tr></table></figure>

<p>with such options as <code>-Qvec-report=3</code> for the Intel compiler.</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>multi-threading and vectorization are two different optimization concepts, each targeting a different level of parallelism.</p>
<ol>
<li>Multi-threading: Multi-threading is a method of parallel computing that divides a task into multiple independent subtasks, each executed in a separate thread. This allows for the simultaneous utilization of the computational power of multiple cores, resulting in faster overall computation. In the given example, the OpenMP directive <code>pragma omp parallel</code> is used, indicating that the iterations of the loop can be executed in parallel across different threads.</li>
<li>Vectorization: Vectorization is an optimization technique that utilizes vector instructions (SIMD instructions) of the processor to perform operations on multiple data elements simultaneously, enhancing computational efficiency. By packing multiple data operations into a single vector instruction, multiple data elements can be processed in a single instruction execution. In the provided example, the OpenMP directive <code>pragma omp simd</code> is used, indicating that the data operations within the loop can be vectorized.</li>
</ol>
<p>To summarize, multi-threading and vectorization are both optimization techniques for parallel computing, but they target different levels of parallelism. Multi-threading leverages the parallelism capabilities of multi-core processors by distributing tasks among different threads. On the other hand, vectorization exploits vector instructions of the processor to process multiple data elements simultaneously, improving efficiency at the instruction level. In some cases, multi-threading and vectorization can be combined to further enhance computational performance.</p>
<p>ref: </p>
<p><a href="https://theartofhpc.com/pcse/index.html" target="_blank" rel="noopener">The Art of HPC</a></p>
<p><a href="https://hackmd.io/@kosl/week2#21-Welcome-to-Week-2" target="_blank" rel="noopener">https://hackmd.io/@kosl/week2#21-Welcome-to-Week-2</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Joe Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2023/06/21/ParallelProg/MyNote%20-%20OpenMP%20Cases/">http://yoursite.com/2023/06/21/ParallelProg/MyNote%20-%20OpenMP%20Cases/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="next-post pull-right"><a href="/2023/06/21/ParallelProg/MyNote%20-%20OpenMP%20Review/"><span>ParallelProg/MyNote - OpenMP Review</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>