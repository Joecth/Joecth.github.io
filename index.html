<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">401</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">26</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">70</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Awaken Desparado</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/21/ParallelProg/MyNote%20-%20OpenMP%20Cases/">ParallelProg/MyNote - OpenMP Cases</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-21</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/ParallelProg/">ParallelProg</a></span><div class="content"><h2 id="Parallel-Regions"><a href="#Parallel-Regions" class="headerlink" title="Parallel Regions"></a>Parallel Regions</h2><p>The following example uses parallelism for an actual calculation:</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = f(x)+g(x)+h(x)</span><br></pre></td></tr></table></figure>

<p>could parallelize this as</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span> result,fresult,gresult,hresult;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123; <span class="keyword">int</span> num = omp_get_thread_num();</span><br><span class="line">  <span class="keyword">if</span> (num==<span class="number">0</span>)      fresult = f(x);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (num==<span class="number">1</span>) gresult = g(x);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (num==<span class="number">2</span>) hresult = h(x);</span><br><span class="line">&#125;</span><br><span class="line">result = fresult + gresult + hresult;</span><br></pre></td></tr></table></figure>



<p><strong>Remark</strong>  In 5.1 the master construct will be deprecated, and masked (with added functionality) will take its place. </p>
<h3 id="Nested-Parallelism"><a href="#Nested-Parallelism" class="headerlink" title="Nested Parallelism"></a>Nested Parallelism</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">  &#123;</span><br><span class="line">  ...</span><br><span class="line">  func(...)</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="comment">// end of main</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(...)</span> </span>&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">  &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>OMP_MAX_ACTIVE_LEVELS</code> (default: 1) to set the number of levels of parallel nesting. Equivalently, there are functions <code>omp_set_max_active_levels</code> and</li>
</ul>
<h2 id="Loop-Parallelism"><a href="#Loop-Parallelism" class="headerlink" title="Loop Parallelism"></a>Loop Parallelism</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123;</span><br><span class="line">  code1();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp for</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;=<span class="number">4</span>*N; i++) &#123;</span><br><span class="line">    code2();</span><br><span class="line">  &#125;</span><br><span class="line">  code3();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<img src="https://p.ipic.vip/juxv0n.png" alt="image-20230621202839429" style="zoom: 50%;" />

<ul>
<li>Loop cannot contain break, return ,exit</li>
<li>OK to have continue </li>
<li>Index should be an increment (or decrement) by a <u>fixed amount</u>, and no changes inside the lo</li>
</ul>
<h3 id="Nested-Loops"><a href="#Nested-Loops" class="headerlink" title="Nested Loops"></a>Nested Loops</h3><ul>
<li><code>collapse(num)</code> can only collapse “perfectly nested loops” – outer loop can consist ONLY of the inner loop;</li>
</ul>
<h2 id="SIMD-Processing"><a href="#SIMD-Processing" class="headerlink" title="SIMD Processing"></a>SIMD Processing</h2><p><strong>Remark</strong> Depending on your compiler, it may be necessary to give an extra option enabling SIMD:</p>
<ul>
<li><code>-fopenmp-simd</code> for <em>GCC</em> / <em>Clang</em> , and</li>
<li><code>-qopenmp-simd</code> for <em>ICC</em> .</li>
</ul>
<p>end of remark</p>
<p>If a loop is both multi-threadable and vectorizable, you can combine directives as <code>pragma omp parallel for simd</code> .</p>
<p>Compilers can be made to report whether a loop was vectorized:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOOP BEGIN at simdf.c(61,15)</span><br><span class="line">   remark #15301: OpenMP SIMD LOOP WAS VECTORIZED</span><br><span class="line">LOOP END</span><br></pre></td></tr></table></figure>

<p>with such options as <code>-Qvec-report=3</code> for the Intel compiler.</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>multi-threading and vectorization are two different optimization concepts, each targeting a different level of parallelism.</p>
<ol>
<li>Multi-threading: Multi-threading is a method of parallel computing that divides a task into multiple independent subtasks, each executed in a separate thread. This allows for the simultaneous utilization of the computational power of multiple cores, resulting in faster overall computation. In the given example, the OpenMP directive <code>pragma omp parallel</code> is used, indicating that the iterations of the loop can be executed in parallel across different threads.</li>
<li>Vectorization: Vectorization is an optimization technique that utilizes vector instructions (SIMD instructions) of the processor to perform operations on multiple data elements simultaneously, enhancing computational efficiency. By packing multiple data operations into a single vector instruction, multiple data elements can be processed in a single instruction execution. In the provided example, the OpenMP directive <code>pragma omp simd</code> is used, indicating that the data operations within the loop can be vectorized.</li>
</ol>
<p>To summarize, multi-threading and vectorization are both optimization techniques for parallel computing, but they target different levels of parallelism. Multi-threading leverages the parallelism capabilities of multi-core processors by distributing tasks among different threads. On the other hand, vectorization exploits vector instructions of the processor to process multiple data elements simultaneously, improving efficiency at the instruction level. In some cases, multi-threading and vectorization can be combined to further enhance computational performance.</p>
<p>ref: </p>
<p><a href="https://theartofhpc.com/pcse/index.html" target="_blank" rel="noopener">The Art of HPC</a></p>
<p><a href="https://hackmd.io/@kosl/week2#21-Welcome-to-Week-2" target="_blank" rel="noopener">https://hackmd.io/@kosl/week2#21-Welcome-to-Week-2</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/21/ParallelProg/MyNote%20-%20OpenMP%20Review/">ParallelProg/MyNote - OpenMP Review</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-21</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/ParallelProg/">ParallelProg</a></span><div class="content"><p>[toc]</p>
<h1 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h1><p>OpenMP,  is concerned with a single <em>cluster node</em> or <em>motherboard</em> , and getting the most out of the available parallelism available there.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">jo@fossa4gb:~/repo/exp_omp$ gcc -fopenmp main.cpp </span><br><span class="line">/usr/bin/ld: /tmp/cccyI4Oq.o:(.data.rel.local.DW.ref.__gxx_personality_v0[DW.ref.__gxx_personality_v0]+0x0): undefined reference to `__gxx_personality_v0<span class="string">'</span></span><br><span class="line"><span class="string">collect2: error: ld returned 1 exit status</span></span><br><span class="line"><span class="string">jo@fossa4gb:~/repo/exp_omp$ mv main.cpp main.c</span></span><br><span class="line"><span class="string">jo@fossa4gb:~/repo/exp_omp$ gcc -fopenmp main.c  &lt;-- Solved!</span></span><br><span class="line"><span class="string">jo@fossa4gb:~/repo/exp_omp$</span></span><br></pre></td></tr></table></figure>



<p>or PGI</p>
<p>編譯指導語句的格式為：</p>
<p>pragma omp <directive> [clause[[,] clause]…]</p>
<p>directive部分是編譯指導語句的主要指令，用來指導多個CPU共享任務或指導多個</p>
<p>CPU同步；</p>
<p>clause部分是可選的子句，它給出了相應的指令參數，可以影響到編譯指導語句</p>
<p>的具體執行；</p>
<p>注意：換行符是必選項。位於被這個指令包圍的結構塊之前，表示這條編譯指導語向的終止。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp somedirective clause(value,othervalue)</span></span><br><span class="line">  statement;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp somedirective clause(value,othervalue)</span></span><br><span class="line"> &#123;</span><br><span class="line">  statement <span class="number">1</span>;</span><br><span class="line">  statement <span class="number">2</span>;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>with</p>
<ul>
<li>the <code>#pragma omp</code> <em>sentinel</em> to indicate that an OpenMP directive is coming;</li>
<li>a <code>directive</code>, such as <code>parallel</code> ;</li>
<li>and possibly <code>clauses</code> with values.</li>
<li>After the directive comes either a single statement or a block in <em>curly braces</em> .</li>
</ul>
<p>透過clause去告訴compiler 然後compiler去gen出來的</p>
<ul>
<li>might support nested </li>
</ul>
<p>原則上只能一個directive，parallel是個特例</p>
<h1 id="Constructs"><a href="#Constructs" class="headerlink" title="Constructs"></a>Constructs</h1><h2 id="Parallel-Construct"><a href="#Parallel-Construct" class="headerlink" title="Parallel Construct"></a>Parallel Construct</h2><p>clause mainly used to control # of threads</p>
<p>struct –  包起來 w/ curly brackets</p>
<p>只有 <strong><em>Parallel 這個 directive</em></strong> 在建thread，其他的directive是在分配事情</p>
<ul>
<li>If – 只在true時建thread，false壓成一個線程跑</li>
<li>常會跟著看num_thread的作設定</li>
<li>there’s implicit barrier at the end of construct</li>
</ul>
<p>e.g. </p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="comment">// Serial code</span></span><br><span class="line"><span class="keyword">int</span> A[<span class="number">10</span>], B[<span class="number">10</span>], C[<span class="number">10</span>]</span><br><span class="line">  </span><br><span class="line"><span class="comment">// Beginning of parallel section. Fork a team of threads</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for num_threads(10)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++)&#123;</span><br><span class="line">    A[i] = B[i] + C[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;<span class="comment">/* All threads join master thread and terminate */</span></span><br></pre></td></tr></table></figure>



<h2 id="Work-Distribution-Construct"><a href="#Work-Distribution-Construct" class="headerlink" title="Work-Distribution Construct"></a>Work-Distribution Construct</h2><ul>
<li>divides the execution of the enclosed code region among the threads that encounter it</li>
<li>DO NOT launch new threads</li>
<li>there’s iimplicit barrier at the end of construct</li>
</ul>
<p>3 分配方式<img src="https://p.ipic.vip/we83v0.png" alt="image-20230620220318645"></p>
<h3 id="1-Do-For-Directive"><a href="#1-Do-For-Directive" class="headerlink" title="1) Do/For Directive"></a>1) Do/For Directive</h3><ul>
<li><p>shares <strong>iteration</strong> across the team</p>
</li>
<li><p>Represents a type of <strong>data parallelism</strong></p>
</li>
<li><p>Clauses:</p>
<ul>
<li>nowait: don’t wait for other threads </li>
<li><strong>schedule</strong>: it has built-in scheduleing<ul>
<li>STATIC:<br>Look divided into <strong>chunks</strong>, Round-Robin, chunk size big, hard to balance</li>
<li>DYNAMIC:<br>when a thread finishes one chunk(default size:1), its <em>dynamically assigned another</em></li>
<li><strong>★GUIDED</strong>:<br>~DYNAMIC, except chunk size↓ over time (<em>better load balancing</em>)</li>
<li>RUNTIME: w/ env: $OMP_SCHEDULE</li>
<li>AUTO:<br>delegated to the compiler, usually sucks! XD</li>
</ul>
</li>
<li>ordered: Iteration must exec in serial program, usually useless XD</li>
<li>collapses: flatten nested loops into 1D</li>
</ul>
</li>
<li><p>Examples</p>
<ul>
<li><p>General</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#inclue <span class="meta-string">&lt;omp.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUM_THREAD 2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHUNKSIZE 100</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 1000</span></span><br><span class="line">main() &#123;</span><br><span class="line">  <span class="keyword">int</span> a[N], b[N], c[N];</span><br><span class="line">  <span class="comment">/*some Inits*/</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) a[i] = b[i] = i;</span><br><span class="line">  <span class="keyword">int</span> chunk = CHUNKSIZE;</span><br><span class="line">  <span class="keyword">int</span> thread = NUM_THREAD;</span><br><span class="line">  </span><br><span class="line">	<span class="meta">#<span class="meta-keyword">pragma</span> omp parallel num_thread(thread) shared(a, b, c) private(i)</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp for schedule(dynamic, chunk) nowait</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) c[i] = a[i] + b[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Collapse</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel num_thread(6)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp for schedule(dynamic) collapse(2)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++)</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">3</span>; j++)</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"i=%d, j=%d, thread=%d\n"</span>, i, j, omp_get_thread_num());</span><br></pre></td></tr></table></figure>

<ul>
<li><p>better &amp; balance performance</p>
</li>
<li><p>no data dependency among diff layers</p>
</li>
<li><p>in <a href="https://www.openmp.org/wp-content/uploads/OpenMPRefCard-5-2-web.pdf" target="_blank" rel="noopener">Manual</a>, there’s <strong>omp_set_max_active_levels</strong> to set</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-SECTIONS-Directive"><a href="#2-SECTIONS-Directive" class="headerlink" title="2) SECTIONS Directive"></a>2) SECTIONS Directive</h3><ul>
<li><p>a section is a segment of code, which executed by a thread</p>
</li>
<li><p>section 不會被重覆做的</p>
</li>
<li><p>上面應該已經有講了parallel, already created the threads</p>
</li>
<li><p>available thread 會先做，然後看有幾個section就幾個thread被assign過去做事</p>
</li>
<li><p>mapping btw thread &amp; section is not able to control</p>
</li>
<li><p>Examples</p>
<ul>
<li>General<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">int</span> N = <span class="number">1000</span></span><br><span class="line">    <span class="keyword">int</span> a[N], b[N], c[N], d[N]</span><br><span class="line">      </span><br><span class="line">    #pragma omp parallel num_thread(<span class="number">2</span>) shared(a,b,c,d) <span class="keyword">private</span>(i)</span><br><span class="line">    &#123;</span><br><span class="line">      #pragma omp sections	<span class="comment">/*specify sections*/</span></span><br><span class="line">      &#123;</span><br><span class="line">        #pragma omp section	<span class="comment">/* 1st section */</span></span><br><span class="line">        &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) c[i] = a[i] + b[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> omp section	<span class="comment">/* 2nd section */</span></span></span><br><span class="line">        &#123;</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) d[i] = a[i] + b[i];</span><br><span class="line">        &#125;    </span><br><span class="line">      &#125; <span class="comment">/* end of sections */</span></span><br><span class="line">    &#125;	<span class="comment">/* end of parallel section */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### <span class="number">3</span>) SINGLE Directive</span><br><span class="line"></span><br><span class="line">- blocking</span><br><span class="line">- e.g. I/O, only <span class="keyword">requires</span> one thread to write, but I don<span class="number">'</span>t know which thread is assigned the task</span><br><span class="line">- blocking other no-doing threads, unless <span class="string">"`nowait`"</span> is added after <span class="string">"single"</span></span><br><span class="line">- 這樣就不用跳出目前的parallel region 然後再進去到另一個parallel region, 就用個Single 解決，然後code也比較好看</span><br><span class="line"></span><br><span class="line">- Examples</span><br><span class="line"></span><br><span class="line">  - General</span><br><span class="line">    ```cpp</span><br><span class="line">    <span class="keyword">int</span> input;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel num_thread(10) shared(input)</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="comment">// computing code that can be processed in parallel</span></span><br><span class="line">      <span class="meta">#<span class="meta-keyword">pragma</span> omp single	<span class="comment">/*specify section*/</span></span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;input);</span><br><span class="line">      &#125;	<span class="comment">/* end of serialized I/O call*/</span></span><br><span class="line">      </span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">"input is %d"</span>, input);</span><br><span class="line">    &#125;	<span class="comment">/* end of parallel section */</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Synchronization Construct</span><br><span class="line"></span><br><span class="line">pretty similar to Single</span><br><span class="line"></span><br><span class="line">### Directives</span><br><span class="line"></span><br><span class="line">master, barrier, `critical` (gross-grain), `atomic`(fine-grain; which is. like monitor in java, <span class="keyword">using</span> synchornized to a <span class="keyword">protected</span> var)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## LOCK Routines</span><br><span class="line"></span><br><span class="line">void omp_init_lock(), void omp_destroy_lock(), void omp_set_lock(), void tmp_unset_lock()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">omp_test_lock</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span></span><br><span class="line">### Examples Comparison</span><br><span class="line"></span><br><span class="line">The following <span class="number">2</span> segments of code are the same, <span class="keyword">and</span> there<span class="number">'</span>s still advantage of <span class="keyword">using</span> critical over lock:</span><br><span class="line"></span><br><span class="line">- no need to declare, init <span class="keyword">and</span> destroy a lock</span><br><span class="line">- you always have <span class="keyword">explicit</span> control over where your critical section ends</span><br><span class="line">- Less overhead with compiler assist</span><br><span class="line"></span><br><span class="line">#### With OpenMP</span><br><span class="line"></span><br><span class="line">```cpp</span><br><span class="line"><span class="meta">#inlcude <span class="meta-string">&lt;omp.h&gt;</span></span></span><br><span class="line">main()&#123;</span><br><span class="line">  <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel </span></span><br><span class="line">  	<span class="meta">#<span class="meta-keyword">pragma</span> omp critical</span></span><br><span class="line">  		count++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h4 id="With-Manual-Call"><a href="#With-Manual-Call" class="headerlink" title="With Manual Call"></a>With Manual Call</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;omp.h&gt;</span></span></span><br><span class="line">main()&#123;</span><br><span class="line">	<span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">omp_lock_t</span> *lock;</span><br><span class="line">  omp_init_lock(lock);</span><br><span class="line">  <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">  &#123;</span><br><span class="line">    omp_set_lock(lock);</span><br><span class="line">    count++;</span><br><span class="line">    omp_unset_lock(lock);</span><br><span class="line">  &#125;</span><br><span class="line">  omp_destroy_lock(lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h1 id="Clauses"><a href="#Clauses" class="headerlink" title="Clauses"></a>Clauses</h1><ul>
<li><p>因為都是compiler gen的code, 所以openmp所見的code跟實際的差別會在要對data的scope了解</p>
</li>
<li><p>for data data scope</p>
</li>
<li><p>private variable or shared variable?<br><img src="https://p.ipic.vip/zp98n7.png" alt="image-20230621193839393"></p>
</li>
<li><p>by default, a variable is shared-variable(global variable)</p>
</li>
<li><p>Types</p>
<ul>
<li><p>private, shared, </p>
</li>
<li><p>firstprivate: </p>
<ul>
<li><p><strong>Inited</strong> according to the value of their original objects prior to entry into the parallel region</p>
</li>
<li><p>e.g.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> va1 = <span class="number">10</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel firstprivate(var1)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"var1:%d"</span> var1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>all threads see var1 equals to 10, but different memory references, and are inited to 10</p>
</li>
</ul>
</li>
<li><p>lastprivate:</p>
<ul>
<li><p>with a copy from the <strong>LAST</strong> loop iteration or section to the original variable object</p>
</li>
<li><p>e.g.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> var1 = <span class="number">10</span></span><br><span class="line">#pragma omp parallel lastprivate(va1) num_thread(<span class="number">10</span>)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">int</span> id = omp_get_thread_num();</span><br><span class="line">  sleep(id);</span><br><span class="line">  var1 = id;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"var1:%d"</span>, var1);</span><br></pre></td></tr></table></figure>

<p>printed out var1 would be the result of the “slowest” thread</p>
</li>
</ul>
</li>
<li><p>default </p>
<ul>
<li>to specify a default scope for ALL variables in the parallel region</li>
</ul>
</li>
<li><p><code>copyin</code>(var_list) VS <code>copyprivate</code>(var_list)</p>
<ul>
<li>copyin:<br>assigning the same variable value based on the instance from the master thread; as the “broadcast to worker threads from main thread”</li>
<li>copyprivate<br><strong>broadcast values</strong> acquired by a single thread directly to all instances in the other threads; Associated with the SINGLE directive</li>
</ul>
</li>
<li><p><code>reduction</code> (operator: var_list)</p>
<ul>
<li><p>a private copy for each list variable is created for each thread</p>
</li>
<li><p>performs a <strong>reduction on all riable instances</strong></p>
</li>
<li><p>Write the <strong>final result to the global shared copy</strong></p>
</li>
<li><p>e.g.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;omp.h&gt;</span></span></span><br><span class="line">main()&#123;</span><br><span class="line">  <span class="keyword">int</span> i = <span class="number">0</span>, n = <span class="number">10</span>, chunk = <span class="number">2</span>, result = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> a[<span class="number">100</span>], b[<span class="number">100</span>];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) a[i] = b[i] = i;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel default(shared) private(i) schedule(static, chunk) reduction(+:result)</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">      result = result + a[i] * b[i]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Final result = %f\n"</span>, result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>i 定是個local, 因為是for的index，當然是個local</p>
<p>reduction用了，會把result這個default是share的作overwrite成private 的local variable ；<br>就是說這個for loop的結果要針對result這個值去作累加，也等同第9行 <code>result=result+</code>這個動作；但這個result其實是個private的variable ，是沒有share的。我們這邊是希望不同的thread只要負責某些index的乘法，然後各別有一個”partial sum”，然後離開了這個parallel region時候，再把這些partial sum加在一起，變成外面第12行的這個global的total的sum<br>至於怎麼分配的？就去看 schedule的策略以及那個chunk<br>中間也不需要再加critical section<br>ref <strong><a href="https://youtu.be/xk6xpx8HY6s?t=421" target="_blank" rel="noopener">Video</a></strong></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Summary-Table"><a href="#Summary-Table" class="headerlink" title="Summary Table"></a>Summary Table</h2><p><img src="https://p.ipic.vip/kw4gra.png" alt="image-20230621190410743"></p>
<h1 id="Routines"><a href="#Routines" class="headerlink" title="Routines"></a>Routines</h1><p>generally, query infos, 就是一些輔助的fn calls</p>
<p>e.g.<br><img src="https://p.ipic.vip/gk650m.png" alt="image-20230621191328781"></p>
<h1 id="Other-Appendix"><a href="#Other-Appendix" class="headerlink" title="Other Appendix"></a>Other Appendix</h1><ul>
<li><p>when compile scikit-learn</p>
<p><img src="https://p.ipic.vip/g7j59e.png" alt="image-20230619232207661"></p>
</li>
</ul>
<p>omp編程規範</p>
<p>開源的多線程處理器</p>
<p>gcc也是開源的</p>
<p>編譯指導語句，這些表達示有一定的區別</p>
<p><img src="https://p.ipic.vip/dwj1f7.png" alt="image-20230620112406786"></p>
<p><img src="https://p.ipic.vip/qn52kg.png" alt="image-20230620112528350"></p>
<p><img src="https://p.ipic.vip/xexgpx.png" alt="image-20230620112706782"></p>
<h2 id="Prof-to-see-Perf"><a href="#Prof-to-see-Perf" class="headerlink" title="Prof to see Perf"></a>Prof to see Perf</h2><p>ref: </p>
<p>1 <a href="https://theartofhpc.com/pcse/index.html" target="_blank" rel="noopener">https://theartofhpc.com/pcse/index.html</a></p>
<p>2  <a href="https://youtu.be/xk6xpx8HY6s?t=421" target="_blank" rel="noopener">周志遠平行程式 9B</a></p>
<p>3 <a href="https://curc.readthedocs.io/en/latest/programming/coding-best-practices.html" target="_blank" rel="noopener">https://curc.readthedocs.io/en/latest/programming/coding-best-practices.html</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/06/15/ParallelProg/SIMD%20on%20x86_64/">ParallelProg/SIMD on x86_64</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-06-15</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/SIMD/">SIMD</a></span><div class="content"><h1 id="SIMD-on-X86-64"><a href="#SIMD-on-X86-64" class="headerlink" title="SIMD on X86_64"></a>SIMD on X86_64</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">/content/drive/MyDrive/mySIMD<span class="comment"># lscpu </span></span><br><span class="line">Architecture:                    x86_64</span><br><span class="line">CPU op-mode(s):                  32-bit, 64-bit</span><br><span class="line">Byte Order:                      Little Endian</span><br><span class="line">Address sizes:                   46 bits physical, 48 bits virtual</span><br><span class="line">CPU(s):                          2</span><br><span class="line">On-line CPU(s) list:             0,1</span><br><span class="line">Thread(s) per core:              2</span><br><span class="line">Core(s) per socket:              1</span><br><span class="line">Socket(s):                       1</span><br><span class="line">NUMA node(s):                    1</span><br><span class="line">Vendor ID:                       GenuineIntel</span><br><span class="line">CPU family:                      6</span><br><span class="line">Model:                           79</span><br><span class="line">Model name:                      Intel(R) Xeon(R) CPU @ 2.20GHz</span><br><span class="line">Stepping:                        0</span><br><span class="line">CPU MHz:                         2199.998</span><br><span class="line">BogoMIPS:                        4399.99</span><br><span class="line">Hypervisor vendor:               KVM</span><br><span class="line">Virtualization <span class="built_in">type</span>:             full</span><br><span class="line">L1d cache:                       32 KiB</span><br><span class="line">L1i cache:                       32 KiB</span><br><span class="line">L2 cache:                        256 KiB</span><br><span class="line">L3 cache:                        55 MiB</span><br><span class="line">NUMA node0 CPU(s):               0,1</span><br><span class="line">Vulnerability Itlb multihit:     Not affected</span><br><span class="line">Vulnerability L1tf:              Mitigation; PTE Inversion</span><br><span class="line">Vulnerability Mds:               Vulnerable; SMT Host state unknown</span><br><span class="line">Vulnerability Meltdown:          Vulnerable</span><br><span class="line">Vulnerability Mmio stale data:   Vulnerable</span><br><span class="line">Vulnerability Retbleed:          Vulnerable</span><br><span class="line">Vulnerability Spec store bypass: Vulnerable</span><br><span class="line">Vulnerability Spectre v1:        Vulnerable: __user pointer sanitization and usercopy </span><br><span class="line">                                 barriers only; no swapgs barriers</span><br><span class="line">Vulnerability Spectre v2:        Vulnerable, IBPB: disabled, STIBP: disabled, PBRSB-eI</span><br><span class="line">                                 BRS: Not affected</span><br><span class="line">Vulnerability Srbds:             Not affected</span><br><span class="line">Vulnerability Tsx async abort:   Vulnerable</span><br><span class="line">Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge </span><br><span class="line">                                 mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sy</span><br><span class="line">                                 scall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl</span><br><span class="line">                                  xtopology nonstop_tsc cpuid tsc_known_freq pni pclmu</span><br><span class="line">                                 lqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe p</span><br><span class="line">                                 opcnt aes xsave avx f16c rdrand hypervisor lahf_lm ab</span><br><span class="line">                                 m 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp f</span><br><span class="line">                                 sgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpc</span><br><span class="line">                                 id rtm rdseed adx smap xsaveopt arat md_clear arch_ca</span><br><span class="line">                                 pabilities</span><br></pre></td></tr></table></figure>



<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br></pre></td><td class="code"><pre><span class="line">~<span class="comment"># gcc -march=native -c -Q --help=target</span></span><br><span class="line">The following options are target specific:</span><br><span class="line">  -m128bit-long-double                  [enabled]</span><br><span class="line">  -m16                                  [disabled]</span><br><span class="line">  -m32                                  [disabled]</span><br><span class="line">  -m3dnow                               [disabled]</span><br><span class="line">  -m3dnowa                              [disabled]</span><br><span class="line">  -m64                                  [enabled]</span><br><span class="line">  -m80387                               [enabled]</span><br><span class="line">  -m8bit-idiv                           [disabled]</span><br><span class="line">  -m96bit-long-double                   [disabled]</span><br><span class="line">  -mabi=                                sysv</span><br><span class="line">  -mabm                                 [enabled]</span><br><span class="line">  -maccumulate-outgoing-args            [disabled]</span><br><span class="line">  -maddress-mode=                       long</span><br><span class="line">  -madx                                 [enabled]</span><br><span class="line">  -maes                                 [enabled]</span><br><span class="line">  -malign-data=                         compat</span><br><span class="line">  -malign-double                        [disabled]</span><br><span class="line">  -malign-functions=                    0</span><br><span class="line">  -malign-jumps=                        0</span><br><span class="line">  -malign-loops=                        0</span><br><span class="line">  -malign-stringops                     [enabled]</span><br><span class="line">  -mandroid                             [disabled]</span><br><span class="line">  -march=                               broadwell</span><br><span class="line">  -masm=                                att</span><br><span class="line">  -mavx                                 [enabled]</span><br><span class="line">  -mavx2                                [enabled]</span><br><span class="line">  -mavx256-split-unaligned-load         [disabled]</span><br><span class="line">  -mavx256-split-unaligned-store        [disabled]</span><br><span class="line">  -mavx5124fmaps                        [disabled]</span><br><span class="line">  -mavx5124vnniw                        [disabled]</span><br><span class="line">  -mavx512bitalg                        [disabled]</span><br><span class="line">  -mavx512bw                            [disabled]</span><br><span class="line">  -mavx512cd                            [disabled]</span><br><span class="line">  -mavx512dq                            [disabled]</span><br><span class="line">  -mavx512er                            [disabled]</span><br><span class="line">  -mavx512f                             [disabled]</span><br><span class="line">  -mavx512ifma                          [disabled]</span><br><span class="line">  -mavx512pf                            [disabled]</span><br><span class="line">  -mavx512vbmi                          [disabled]</span><br><span class="line">  -mavx512vbmi2                         [disabled]</span><br><span class="line">  -mavx512vl                            [disabled]</span><br><span class="line">  -mavx512vnni                          [disabled]</span><br><span class="line">  -mavx512vpopcntdq                     [disabled]</span><br><span class="line">  -mbionic                              [disabled]</span><br><span class="line">  -mbmi                                 [enabled]</span><br><span class="line">  -mbmi2                                [enabled]</span><br><span class="line">  -mbranch-cost=&lt;0,5&gt;                   3</span><br><span class="line">  -mcall-ms2sysv-xlogues                [disabled]</span><br><span class="line">  -mcet-switch                          [disabled]</span><br><span class="line">  -mcld                                 [disabled]</span><br><span class="line">  -mcldemote                            [disabled]</span><br><span class="line">  -mclflushopt                          [disabled]</span><br><span class="line">  -mclwb                                [disabled]</span><br><span class="line">  -mclzero                              [disabled]</span><br><span class="line">  -mcmodel=                             [default]</span><br><span class="line">  -mcpu=                      </span><br><span class="line">  -mcrc32                               [disabled]</span><br><span class="line">  -mcx16                                [enabled]</span><br><span class="line">  -mdispatch-scheduler                  [disabled]</span><br><span class="line">  -mdump-tune-features                  [disabled]</span><br><span class="line">  -mf16c                                [enabled]</span><br><span class="line">  -mfancy-math-387                      [enabled]</span><br><span class="line">  -mfentry                              [disabled]</span><br><span class="line">  -mfentry-name=              </span><br><span class="line">  -mfentry-section=           </span><br><span class="line">  -mfma                                 [enabled]</span><br><span class="line">  -mfma4                                [disabled]</span><br><span class="line">  -mforce-drap                          [disabled]</span><br><span class="line">  -mforce-indirect-call                 [disabled]</span><br><span class="line">  -mfp-ret-in-387                       [enabled]</span><br><span class="line">  -mfpmath=                             sse</span><br><span class="line">  -mfsgsbase                            [enabled]</span><br><span class="line">  -mfunction-return=                    keep</span><br><span class="line">  -mfused-madd                </span><br><span class="line">  -mfxsr                                [enabled]</span><br><span class="line">  -mgeneral-regs-only                   [disabled]</span><br><span class="line">  -mgfni                                [disabled]</span><br><span class="line">  -mglibc                               [enabled]</span><br><span class="line">  -mhard-float                          [enabled]</span><br><span class="line">  -mhle                                 [enabled]</span><br><span class="line">  -miamcu                               [disabled]</span><br><span class="line">  -mieee-fp                             [enabled]</span><br><span class="line">  -mincoming-stack-boundary=            0</span><br><span class="line">  -mindirect-branch-register            [disabled]</span><br><span class="line">  -mindirect-branch=                    keep</span><br><span class="line">  -minline-all-stringops                [disabled]</span><br><span class="line">  -minline-stringops-dynamically        [disabled]</span><br><span class="line">  -minstrument-return=                  none</span><br><span class="line">  -mintel-syntax              </span><br><span class="line">  -mlarge-data-threshold=&lt;number&gt;       65536</span><br><span class="line">  -mlong-double-128                     [disabled]</span><br><span class="line">  -mlong-double-64                      [disabled]</span><br><span class="line">  -mlong-double-80                      [enabled]</span><br><span class="line">  -mlwp                                 [disabled]</span><br><span class="line">  -mlzcnt                               [enabled]</span><br><span class="line">  -mmanual-endbr                        [disabled]</span><br><span class="line">  -mmemcpy-strategy=          </span><br><span class="line">  -mmemset-strategy=          </span><br><span class="line">  -mmitigate-rop                        [disabled]</span><br><span class="line">  -mmmx                                 [enabled]</span><br><span class="line">  -mmovbe                               [enabled]</span><br><span class="line">  -mmovdir64b                           [disabled]</span><br><span class="line">  -mmovdiri                             [disabled]</span><br><span class="line">  -mmpx                                 [disabled]</span><br><span class="line">  -mms-bitfields                        [disabled]</span><br><span class="line">  -mmusl                                [disabled]</span><br><span class="line">  -mmwaitx                              [disabled]</span><br><span class="line">  -mno-align-stringops                  [disabled]</span><br><span class="line">  -mno-default                          [disabled]</span><br><span class="line">  -mno-fancy-math-387                   [disabled]</span><br><span class="line">  -mno-push-args                        [disabled]</span><br><span class="line">  -mno-red-zone                         [disabled]</span><br><span class="line">  -mno-sse4                             [disabled]</span><br><span class="line">  -mnop-mcount                          [disabled]</span><br><span class="line">  -momit-leaf-frame-pointer             [disabled]</span><br><span class="line">  -mpc32                                [disabled]</span><br><span class="line">  -mpc64                                [disabled]</span><br><span class="line">  -mpc80                                [disabled]</span><br><span class="line">  -mpclmul                              [enabled]</span><br><span class="line">  -mpcommit                             [disabled]</span><br><span class="line">  -mpconfig                             [disabled]</span><br><span class="line">  -mpku                                 [disabled]</span><br><span class="line">  -mpopcnt                              [enabled]</span><br><span class="line">  -mprefer-avx128             </span><br><span class="line">  -mprefer-vector-width=                none</span><br><span class="line">  -mpreferred-stack-boundary=           0</span><br><span class="line">  -mprefetchwt1                         [disabled]</span><br><span class="line">  -mprfchw                              [enabled]</span><br><span class="line">  -mptwrite                             [disabled]</span><br><span class="line">  -mpush-args                           [enabled]</span><br><span class="line">  -mrdpid                               [disabled]</span><br><span class="line">  -mrdrnd                               [enabled]</span><br><span class="line">  -mrdseed                              [enabled]</span><br><span class="line">  -mrecip                               [disabled]</span><br><span class="line">  -mrecip=                    </span><br><span class="line">  -mrecord-mcount                       [disabled]</span><br><span class="line">  -mrecord-return                       [disabled]</span><br><span class="line">  -mred-zone                            [enabled]</span><br><span class="line">  -mregparm=                            6</span><br><span class="line">  -mrtd                                 [disabled]</span><br><span class="line">  -mrtm                                 [enabled]</span><br><span class="line">  -msahf                                [enabled]</span><br><span class="line">  -msgx                                 [disabled]</span><br><span class="line">  -msha                                 [disabled]</span><br><span class="line">  -mshstk                               [disabled]</span><br><span class="line">  -mskip-rax-setup                      [disabled]</span><br><span class="line">  -msoft-float                          [disabled]</span><br><span class="line">  -msse                                 [enabled]</span><br><span class="line">  -msse2                                [enabled]</span><br><span class="line">  -msse2avx                             [disabled]</span><br><span class="line">  -msse3                                [enabled]</span><br><span class="line">  -msse4                                [enabled]</span><br><span class="line">  -msse4.1                              [enabled]</span><br><span class="line">  -msse4.2                              [enabled]</span><br><span class="line">  -msse4a                               [disabled]</span><br><span class="line">  -msse5                      </span><br><span class="line">  -msseregparm                          [disabled]</span><br><span class="line">  -mssse3                               [enabled]</span><br><span class="line">  -mstack-arg-probe                     [disabled]</span><br><span class="line">  -mstack-protector-guard-offset= </span><br><span class="line">  -mstack-protector-guard-reg= </span><br><span class="line">  -mstack-protector-guard-symbol= </span><br><span class="line">  -mstack-protector-guard=              tls</span><br><span class="line">  -mstackrealign                        [disabled]</span><br><span class="line">  -mstringop-strategy=                  [default]</span><br><span class="line">  -mstv                                 [enabled]</span><br><span class="line">  -mtbm                                 [disabled]</span><br><span class="line">  -mtls-dialect=                        gnu</span><br><span class="line">  -mtls-direct-seg-refs                 [enabled]</span><br><span class="line">  -mtune-ctrl=                </span><br><span class="line">  -mtune=                               broadwell</span><br><span class="line">  -muclibc                              [disabled]</span><br><span class="line">  -mvaes                                [disabled]</span><br><span class="line">  -mveclibabi=                          [default]</span><br><span class="line">  -mvect8-ret-in-mem                    [disabled]</span><br><span class="line">  -mvpclmulqdq                          [disabled]</span><br><span class="line">  -mvzeroupper                          [enabled]</span><br><span class="line">  -mwaitpkg                             [disabled]</span><br><span class="line">  -mwbnoinvd                            [disabled]</span><br><span class="line">  -mx32                                 [disabled]</span><br><span class="line">  -mxop                                 [disabled]</span><br><span class="line">  -mxsave                               [enabled]</span><br><span class="line">  -mxsavec                              [disabled]</span><br><span class="line">  -mxsaveopt                            [enabled]</span><br><span class="line">  -mxsaves                              [disabled]</span><br><span class="line"></span><br><span class="line">  Known assembler dialects (<span class="keyword">for</span> use with the -masm= option):</span><br><span class="line">    att intel</span><br><span class="line"></span><br><span class="line">  Known ABIs (<span class="keyword">for</span> use with the -mabi= option):</span><br><span class="line">    ms sysv</span><br><span class="line"></span><br><span class="line">  Known code models (<span class="keyword">for</span> use with the -mcmodel= option):</span><br><span class="line">    32 kernel large medium small</span><br><span class="line"></span><br><span class="line">  Valid arguments to -mfpmath=:</span><br><span class="line">    387 387+sse 387,sse both sse sse+387 sse,387</span><br><span class="line"></span><br><span class="line">  Known indirect branch choices (<span class="keyword">for</span> use with the -mindirect-branch=/-mfunction-return= options):</span><br><span class="line">    keep thunk thunk-extern thunk-inline</span><br><span class="line"></span><br><span class="line">  Known choices <span class="keyword">for</span> <span class="built_in">return</span> instrumentation with -minstrument-return=:</span><br><span class="line">    call none nop5</span><br><span class="line"></span><br><span class="line">  Known data alignment choices (<span class="keyword">for</span> use with the -malign-data= option):</span><br><span class="line">    abi cacheline compat</span><br><span class="line"></span><br><span class="line">  Known vectorization library ABIs (<span class="keyword">for</span> use with the -mveclibabi= option):</span><br><span class="line">    acml svml</span><br><span class="line"></span><br><span class="line">  Known address mode (<span class="keyword">for</span> use with the -maddress-mode= option):</span><br><span class="line">    long short</span><br><span class="line"></span><br><span class="line">  Known preferred register vector length (to use with the -mprefer-vector-width= option):</span><br><span class="line">    128 256 512 none</span><br><span class="line"></span><br><span class="line">  Known stack protector guard (<span class="keyword">for</span> use with the -mstack-protector-guard= option):</span><br><span class="line">    global tls</span><br><span class="line"></span><br><span class="line">  Valid arguments to -mstringop-strategy=:</span><br><span class="line">    byte_loop libcall loop rep_4byte rep_8byte rep_byte unrolled_loop vector_loop</span><br><span class="line"></span><br><span class="line">  Known TLS dialects (<span class="keyword">for</span> use with the -mtls-dialect= option):</span><br><span class="line">    gnu gnu2</span><br><span class="line"></span><br><span class="line">  Known valid arguments <span class="keyword">for</span> -march= option:</span><br><span class="line">    i386 i486 i586 pentium lakemont pentium-mmx winchip-c6 winchip2 c3 samuel-2 c3-2 nehemiah c7 esther i686 pentiumpro pentium2 pentium3 pentium3m pentium-m pentium4 pentium4m prescott nocona core2 nehalem corei7 westmere sandybridge corei7-avx ivybridge core-avx-i haswell core-avx2 broadwell skylake skylake-avx512 cannonlake icelake-client icelake-server cascadelake tigerlake bonnell atom silvermont slm goldmont goldmont-plus tremont knl knm intel geode k6 k6-2 k6-3 athlon athlon-tbird athlon-4 athlon-xp athlon-mp x86-64 eden-x2 nano nano-1000 nano-2000 nano-3000 nano-x2 eden-x4 nano-x4 k8 k8-sse3 opteron opteron-sse3 athlon64 athlon64-sse3 athlon-fx amdfam10 barcelona bdver1 bdver2 bdver3 bdver4 znver1 znver2 btver1 btver2 generic native</span><br><span class="line"></span><br><span class="line">  Known valid arguments <span class="keyword">for</span> -mtune= option:</span><br><span class="line">    generic i386 i486 pentium lakemont pentiumpro pentium4 nocona core2 nehalem sandybridge haswell bonnell silvermont goldmont goldmont-plus tremont knl knm skylake skylake-avx512 cannonlake icelake-client icelake-server cascadelake tigerlake intel geode k6 athlon k8 amdfam10 bdver1 bdver2 bdver3 bdver4 btver1 btver2 znver1 znver2</span><br></pre></td></tr></table></figure>





<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">/content/drive/MyDrive/mySIMD#</span><span class="bash"> g++ -o build_vec_avx2 -mavx2 build_vec.cc</span></span><br><span class="line"><span class="meta">/content/drive/MyDrive/mySIMD#</span><span class="bash"> ./build_vec_avx2 </span></span><br><span class="line">v0: [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ]</span><br><span class="line">v1: [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ]</span><br><span class="line">v0 = v0 + 1: [ 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ]</span><br><span class="line">v1 = v1 + 2: [ 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ]</span><br><span class="line">v0 = v0 + v1: [ 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ]</span><br><span class="line">v1 = v0 * v1: [ 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 ]</span><br><span class="line"></span><br><span class="line">v16si a = &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15&#125;;</span><br><span class="line">v16si b = &#123;0, 2, 4, 6, 8, 1, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15&#125;;</span><br><span class="line">c = a &gt; b: [ 0 0 0 0 0 -1 -1 -1 -1 0 0 0 0 0 0 0 ]</span><br><span class="line">d = (a &gt; b) ? v0 : v1: [ 6 6 6 6 6 3 3 3 3 6 6 6 6 6 6 6 ]</span><br><span class="line"><span class="meta">/content/drive/MyDrive/mySIMD#</span><span class="bash"> g++ -o build_vec_avx512f -mavx512f build_vec.cc</span></span><br><span class="line"><span class="meta">/content/drive/MyDrive/mySIMD#</span><span class="bash"> ./build_vec_avx512f </span></span><br><span class="line">v0: [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ]</span><br><span class="line">v1: [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ]</span><br><span class="line">Illegal instruction (core dumped)</span><br><span class="line"><span class="meta">/content/drive/MyDrive/mySIMD#</span><span class="bash"> </span></span><br><span class="line"></span><br><span class="line">Other options: -mmmx、-msse、-msse2、-msse3、-mssse3、-msse4.1、-msse4.2、-msse4、-mavx、-mavx2、-mavx512f、-mavx512pf、-mavx512er、-mavx512cd、-mavx512vl、-mavx512bw、-mavx512dq、-mavx512ifma、-mavx512vbmi。</span><br></pre></td></tr></table></figure>





<p><a href="https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/intrinsics.html" target="_blank" rel="noopener">Intel Manual</a></p>
<p><img src="https://p.ipic.vip/nblx24.jpg" alt="img"></p>
<h2 id="Hardware-Aspects"><a href="#Hardware-Aspects" class="headerlink" title="Hardware Aspects"></a>Hardware Aspects</h2><p><img src="https://p.ipic.vip/98sfm8.png" alt="image-20230524114039763"></p>
<p><img src="https://p.ipic.vip/0ba5i2.png" alt="image-20230524114127909"></p>
<p><img src="https://p.ipic.vip/4i3ul1.png" alt="image-20230524114230862"></p>
<blockquote>
<p>•性能提升更多依赖体系结构改进<br>•提高流水线效率<br>提高Cache效率<br>向量指令，提高向量长度<br>引入多核<br>以Intel为例<br>MMx 11993<br>MMX (64-bit)<br>wl vector re<br>supports<br>SSE、 SSE2、 (128-bit)<br>indeger ope<br>•<br>AVX. AVx2 (256-bit)<br>AVX-512 (512-bit)<br>ARM Neon指令集<br>当前ARM V8的向量化指令集<br>128-bit向量宽度<br>ARM SVE指令集<br>• ARM下-代向量化指令集<br>向量长度可伸缩，从128-bit 到2048-bit<br>与RISC-V V扩展类似<br>RISC-V ISA指令集架构，<br>精简的基础指令集，RV321 , RV641<br>•扩展指令集<br>• M,A,F,D,QC<br>讨论状态：V，B，J等等<br>RISC-V “V” Vector Extension<br>•当前版本1.0<br><a href="https://github.com/riscv/riscv-V-spec" target="_blank" rel="noopener">https://github.com/riscv/riscv-V-spec</a></p>
</blockquote>
<h2 id="Software-Aspects"><a href="#Software-Aspects" class="headerlink" title="Software Aspects"></a>Software Aspects</h2><p><img src="https://p.ipic.vip/nd1dy4.png" alt="image-20230524114212963"></p>
<p>VS</p>
<h2 id="AVX512-VS-GPU"><a href="#AVX512-VS-GPU" class="headerlink" title="AVX512 VS GPU"></a>AVX512 VS GPU</h2><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>CPU + AVX512</td>
<td>big RAM, low Latency, Cache strong</td>
<td>High Power, Bandwidth low..</td>
</tr>
<tr>
<td>GPU</td>
<td>Scaling! CUDA</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li>Intel want “generalization” + “super high computing power”… many other people instead seek solution in ASIC or more core HW</li>
</ul>
<h2 id="AVX-amp-SSE"><a href="#AVX-amp-SSE" class="headerlink" title="AVX &amp; SSE"></a>AVX &amp; SSE</h2><p><a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm256_loadu_pd&amp;ig_expand=4122" target="_blank" rel="noopener">https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm256_loadu_pd&amp;ig_expand=4122</a></p>
<p>in 2007, AMD announced SSE5 (previously SSE1~SSE4 all announced by Intel), so in 2008, Intel announced AVX, which owns some more distinct features</p>
<p>1 Float length doubled</p>
<p>2 Support 3OPs instruction for old version SSEs</p>
<p><img src="https://p.ipic.vip/qomm14.png" alt="image-20230606224503357"></p>
<p><img src="https://p.ipic.vip/n6fj6m.png" alt="image-20230606224622809"></p>
<blockquote>
<p>誰是最有效率就是軟件遊戲沒有動力學優化軟體覺得我花費大量的人力物理優化提升30%的性能還不如直接等1年後的我根本就沒有用畫的東西很多錢可能會想和背景新市區有直接等過兩天是一個新的提醒我就可能是目前也不好多錢目前來看他用你</p>
</blockquote>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/05/29/AI-System/2%20AI%20Compiler/">AI-System/2 AI Compiler</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-05-29</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/AI-System/">AI-System</a></span><div class="content"><h1 id="Why-we-need-AI-Compiler"><a href="#Why-we-need-AI-Compiler" class="headerlink" title="Why we need AI Compiler"></a>Why we need AI Compiler</h1><ul>
<li>OPs ↑</li>
<li>HW vendors release similar libs, e.g. CuDNN, MKL-DNN for their own chips</li>
<li>Transplanation issue, e.g. CPU &amp; GPU’s existing  Pass hard to be transplanted to NPU</li>
</ul>
<h1 id="AI-Compiler"><a href="#AI-Compiler" class="headerlink" title="AI Compiler"></a>AI Compiler</h1><ul>
<li>auto optimize the process/code</li>
<li>Introduce Pass</li>
<li>FE -&gt; Opt -&gt; BE</li>
<li>Main purpose –&gt; Optiize the performance, and then make coding easier</li>
</ul>
<img src="https://p.ipic.vip/hvdjk2.png" alt="image-20230602171205297" style="zoom:33%;" />



<h3 id="Difference-from-Traditional-Compiler"><a href="#Difference-from-Traditional-Compiler" class="headerlink" title="Difference from Traditional Compiler"></a>Difference from Traditional Compiler</h3><p><img src="https://p.ipic.vip/vsjbeo.png" alt="image-20230602171410674"></p>
<ul>
<li>IR <ul>
<li>for AI<ul>
<li>High-level IR, to describe the computational graph</li>
</ul>
</li>
<li>for Traditional IR<ul>
<li>Low-level IR, e.g. load, store</li>
</ul>
</li>
</ul>
</li>
<li>Pass<ul>
<li>for AI<ul>
<li>OPs fusion</li>
<li>able for Quantization</li>
</ul>
</li>
<li>for Traditional <ul>
<li>no Quantization</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="AI-Compiler-Architecture"><a href="#AI-Compiler-Architecture" class="headerlink" title="AI Compiler Architecture"></a>AI Compiler Architecture</h1><p>Purposes: Inference or Train?!</p>
<ul>
<li>Python as FE interpreter</li>
<li>Multilevel IR, including graph-compilzation, OP compilation, code-gen</li>
<li>for NN</li>
<li>DSA for chips</li>
</ul>
<h3 id="History"><a href="#History" class="headerlink" title="History"></a>History</h3><p><img src="https://p.ipic.vip/o4kzrn.png" alt="image-20230602171958136"></p>
<p>I had experiences in Stage I in 2017~early2019</p>
<p>and now being involved in Stage II</p>
<h4 id="Stage-II"><a href="#Stage-II" class="headerlink" title="Stage II"></a>Stage II</h4><img src="https://p.ipic.vip/6y3qzh.png" alt="image-20230602172529020" style="zoom:67%;" />



<h4 id="Stage-III"><a href="#Stage-III" class="headerlink" title="Stage III"></a>Stage III</h4><p><img src="https://p.ipic.vip/vgjo4j.png" alt="image-20230602172708408"></p>
<p>ref: <a href="https://youtu.be/bW3gsz9AjPY" target="_blank" rel="noopener">AI videos series</a> on YT  </p>
<h3 id="General-Architecture"><a href="#General-Architecture" class="headerlink" title="General Architecture"></a>General Architecture</h3><p><img src="https://p.ipic.vip/gr6gg4.png" alt="image-20230602190537524"></p>
<p>From paper – <u><em>The Deep LearningCompiler: A Comprehensive Survey</em></u></p>
<ul>
<li><p>IR - </p>
<ol>
<li><p>High-level</p>
</li>
<li><p>Low-level</p>
</li>
</ol>
</li>
<li><p>FE Opti.</p>
<p>compose graph with python language</p>
<ol>
<li>Nodes level –  zero-dim-tensor elimination, Nop elimination</li>
<li>Block level – algebraic simplify, constant folding ,op fusion</li>
<li>Data Stream level –  Common sub-expression elimination, DCE(data communcation equip.)</li>
</ol>
</li>
<li><p>BE Opti.</p>
<ol>
<li>Spefific hardware<ul>
<li>low-level IR –&gt; LLVM IR –&gt; GPU/CPU codegen</li>
<li>Domain knowhow</li>
</ul>
</li>
<li>Auto-adjustment<ul>
<li>Halide/TVM allows the <strong>Separatino of Scheduleing and Compute</strong></li>
<li><u>Polyhedral model</u> for param adjustment</li>
</ul>
</li>
<li>Kernel libs<ul>
<li>from libs, e.g. NVidia’s lib</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><img src="https://p.ipic.vip/3orvbk.png" alt="image-20230602191320979"></p>
<h1 id="Challenges-amp-Future"><a href="#Challenges-amp-Future" class="headerlink" title="Challenges &amp; Future"></a>Challenges &amp; Future</h1><ol>
<li><p>Dynamic Shape problems</p>
</li>
<li><p>Python Static<br><img src="https://p.ipic.vip/j07i81.png" alt="image-20230602192507040"></p>
<p><img src="https://p.ipic.vip/agcvp6.png" alt="image-20230602192610709"></p>
</li>
<li><p>Specific Optimization </p>
<ul>
<li>auto parallel<ul>
<li>Scale out </li>
<li>Scale up</li>
</ul>
</li>
<li>HPC for Jacobian matrix, for Hessian matrix</li>
</ul>
</li>
<li><p>Transparency </p>
</li>
<li><p>Compiling cost、Overhead</p>
</li>
</ol>
<ul>
<li>Umifying representation of graph?</li>
<li>Umifying optimization for compilation?</li>
</ul>
<p><img src="https://p.ipic.vip/ypwr0w.png" alt="image-20230602193127645"></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2023/05/27/AI-System/1%20Traditional%20Compilers%20/">AI-System/1 Traditional Compilers </a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2023-05-27</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/AI-System/">AI-System</a></span><div class="content"><p>Interpreter VS Compiler</p>
<p>JIT vs AOT</p>
<p>Pass &amp; IR</p>
<h2 id="History-of-Compilers-–-GCC-VS-LLVM"><a href="#History-of-Compilers-–-GCC-VS-LLVM" class="headerlink" title="History of Compilers – GCC VS LLVM"></a>History of Compilers – GCC VS LLVM</h2><p><img src="https://p.ipic.vip/wjd955.png" alt="image-20230602161322366"></p>
<p>Compiler –  e.g. turn hello.c to hello.o(binary)</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sourcecode --&gt; 		Compiler --&gt; 		exe binary</span><br><span class="line">​						(FE, IR Optimizer, BE)</span><br><span class="line">(to AST)												(MachineCode)</span><br><span class="line">Abstract Syntax Tree</span><br></pre></td></tr></table></figure>





<p>GCC 1.0 @ 1987</p>
<img src="https://p.ipic.vip/5y76rq.png" alt="image-20230602160844823" style="zoom:50%;" />

<p>​                        Free the Free!</p>
<p>(Richard Matthew Stallman)</p>
<p>Apple – Free! but OS kernel pretty closed</p>
<p><img src="https://p.ipic.vip/mxxzdg.png" alt="image-20230602161010238"></p>
<h3 id="Apple-met-LLVM"><a href="#Apple-met-LLVM" class="headerlink" title="Apple met LLVM"></a>Apple met LLVM</h3><img src="https://p.ipic.vip/lm33h3.png" alt="image-20230602161146709" style="zoom: 25%;" />





<h3 id="GCC"><a href="#GCC" class="headerlink" title="GCC"></a>GCC</h3><img src="https://p.ipic.vip/bcso75.png" alt="image-20230602161456787" style="zoom: 50%;" />

<img src="https://p.ipic.vip/eht8wd.png" alt="image-20230602161738949" style="zoom:67%;" />





<h3 id="LLVM"><a href="#LLVM" class="headerlink" title="LLVM"></a>LLVM</h3><p>low level VM</p>
<p>Compiler Toolchain</p>
<img src="https://p.ipic.vip/wwjwth.png" alt="image-20230602161604175" style="zoom: 67%;" />





<p>Introduced IR! bettern than GCC</p>
<img src="https://p.ipic.vip/4jgjjm.png" alt="image-20230602161815300" style="zoom:67%;" />





<h2 id="CLANG-VS-GCC"><a href="#CLANG-VS-GCC" class="headerlink" title="CLANG VS GCC"></a>CLANG VS GCC</h2><p><img src="https://p.ipic.vip/cqugk4.png" alt="image-20230602162331702"></p>
<p><img src="https://p.ipic.vip/304pgi.png" alt="image-20230602162406871"></p>
<p><img src="https://p.ipic.vip/n0rsd7.png" alt="image-20230602162448009"></p>
<p><img src="https://p.ipic.vip/rtj8ia.png" alt="image-20230602162529839"></p>
<p>​    - *.ll  – huan readable</p>
<ul>
<li><pre><code class="bash">&gt; clang -emit-llvm hello.i -c -o hello.bc
&gt; code hello.bc
&gt; od -b hello.bc

$ clang -ccc-print-phases hello.cpp
               +- 0: input, <span class="string">"hello.cpp"</span>, c++
            +- 1: preprocessor, {0}, c++-cpp-output
         +- 2: compiler, {1}, ir
      +- 3: backend, {2}, assembler
   +- 4: assembler, {3}, object
+- 5: linker, {4}, image
6: <span class="built_in">bind</span>-arch, <span class="string">"arm64"</span>, {5}, image

(base)
<span class="comment"># joe @ J-M1-Pro-16 in ~/exp [16:35:49]</span>
$ cat hello.s | less
    .cfi_endproc
                                        ; -- End <span class="keyword">function</span>
    .p2align    2                               ; -- Begin <span class="keyword">function</span> _ZNSt3__18ios_base8setstateEj
__ZNSt3__18ios_base8setstateEj:         ; @_ZNSt3__18ios_base8setstateEj
    .cfi_startproc
; %bb.0:
    sub    sp, sp, <span class="comment">#32</span>
    stp    x29, x30, [sp, <span class="comment">#16]             ; 16-byte Folded Spill</span>
        .section        __TEXT,__text,regular,pure_instructions
        .build_version macos, 12, 0     sdk_version 12, 3
        .globl  _main                           ; -- Begin <span class="keyword">function</span> main
        .p2align        2
_main:                                  ; @main
        .cfi_startproc
; %bb.0:
        stp     x29, x30, [sp, <span class="comment">#-16]!           ; 16-byte Folded Spill</span>
        mov     x29, sp
        .cfi_def_cfa w29, 16
        .cfi_offset w30, -8
        .cfi_offset w29, -16
        adrp    x0, l_.str@PAGE
        add     x0, x0, l_.str@PAGEOFF
        bl      _printf
        adrp    x0, __ZNSt3__14coutE@GOTPAGE
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### LLVM IR★</span><br><span class="line"></span><br><span class="line">![image-20230602163418928](https:&#x2F;&#x2F;p.ipic.vip&#x2F;e85fsn.png)</span><br><span class="line"></span><br><span class="line">- SSA - Static Single Assignment </span><br><span class="line">  - ~  RISC ISA</span><br><span class="line">  - 3-address-code</span><br><span class="line">    - &lt;img src&#x3D;&quot;https:&#x2F;&#x2F;p.ipic.vip&#x2F;jwvvo5.png&quot; alt&#x3D;&quot;image-20230602163826992&quot; style&#x3D;&quot;zoom:33%;&quot; &#x2F;&gt;</span><br><span class="line">  - inf registers</span><br><span class="line">- Structure</span><br><span class="line">  - Module -&gt; Function -&gt; Basicblock -&gt; Instruction</span><br><span class="line">- Concepts</span><br><span class="line">  - Value, Use, User, </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### LLVM FE</span><br><span class="line"></span><br><span class="line">&lt;img src&#x3D;&quot;https:&#x2F;&#x2F;p.ipic.vip&#x2F;qtr860.png&quot; alt&#x3D;&quot;image-20230602164519532&quot; style&#x3D;&quot;zoom: 50%;&quot; &#x2F;&gt;</span><br><span class="line"></span><br><span class="line">- Lexical Analysis --&gt; Syntatical Analysis --&gt; Semantic Analysis</span><br><span class="line"></span><br><span class="line">  - &#96;&#96;&#96;&#96;bash</span><br><span class="line">    10018  clang -cc1 -dump-tokens hello.cpp</span><br><span class="line">    10019  clang -fsyntax-only -Xclang -ast-dump hello.cpp</span><br><span class="line">    10020  clang -c hello.cpp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### LLVM Optimizer</span><br><span class="line"></span><br><span class="line">- Finding PASS</span><br><span class="line"></span><br><span class="line">  - Analysis Pass</span><br><span class="line"></span><br><span class="line">  - Transform pass</span><br><span class="line"></span><br><span class="line">  - &#96;&#96;&#96;	bash</span><br><span class="line">    &gt; opt hello.bc -instcount -time-passes -domtree -o hello-tmp.bc -stats</span><br></pre></td></tr></table></figure>

- [LLVM’s Analysis and Transform Passes — LLVM 17.0.0git documentation](https://llvm.org/docs/Passes.html)

  - e.g. -adce: Aggressive Dead Code Elimination
  - e.g.  -constmerge: Merge Duplicate Global Constants

- ModulePass, FunctionPass, BasicBlockPass


</code></pre>
</li>
</ul>
<h3 id="LLVM-BE"><a href="#LLVM-BE" class="headerlink" title="LLVM BE"></a>LLVM BE</h3><img src="/Users/joe/Library/Application Support/typora-user-images/image-20230602165508513.png" alt="image-20230602165508513" style="zoom: 40%;" />



<h4 id="SelectionDAG-gt-Scheduling"><a href="#SelectionDAG-gt-Scheduling" class="headerlink" title="SelectionDAG -&gt; Scheduling"></a>SelectionDAG -&gt; Scheduling</h4><p><img src="https://p.ipic.vip/3r23t5.png" alt="image-20230602165708989"></p>
<p>Topological sort to know nodes that are able to run parallelly</p>
<h4 id="MCInst-gt-Code-Emission"><a href="#MCInst-gt-Code-Emission" class="headerlink" title="MCInst -&gt; Code Emission"></a>MCInst -&gt; Code Emission</h4><h4 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h4><p><img src="https://p.ipic.vip/gtnep5.png" alt="image-20230602165926323"></p>
<h2 id="OnGoing-History"><a href="#OnGoing-History" class="headerlink" title="OnGoing History"></a>OnGoing History</h2><p>Chris start his bizness at “Modular”</p>
<h2 id="LLVM-Related-AI-Compilers"><a href="#LLVM-Related-AI-Compilers" class="headerlink" title="LLVM Related AI Compilers"></a>LLVM Related AI Compilers</h2><p>built on LLVM, including</p>
<ul>
<li>XLA in TF,  by Google</li>
<li>JAX, autograd + XLA, by Google</li>
<li>TensorFlow, on XLA, then on LLVM</li>
<li>TVM for different hardwares</li>
<li>Julia, for HPC, using LLVM JIT</li>
</ul>
<p>ref to </p>
<ul>
<li>series of <a href="https://youtu.be/i5_BptwCBHA" target="_blank" rel="noopener">AI videos</a> on YT</li>
</ul>
</div><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/81/">81</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2023 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>