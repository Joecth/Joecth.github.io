<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.1.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="false"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">249</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">24</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">36</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="site-info"><div id="site-title">Awaken Desparado</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2020/03/28/NLP/2020-03-28-NLP_nltk_0/">NLP/2020-03-28-NLP_nltk_0</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-28</time><div class="content"><h3 id="Text-Preprocessing"><a href="#Text-Preprocessing" class="headerlink" title="Text Preprocessing"></a>Text Preprocessing</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># regex for removing punctuation!</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># nltk preprocessing magic</span></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> PorterStemmer</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="comment"># grabbing a part of speech function:</span></span><br><span class="line"><span class="keyword">from</span> part_of_speech <span class="keyword">import</span> get_part_of_speech</span><br><span class="line"></span><br><span class="line">text = <span class="string">"So many squids are jumping out of suitcases these days that you can barely go anywhere without seeing one burst forth from a tightly packed valise. I went to the dentist the other day, and sure enough I saw an angry one jump out of my dentist's bag within minutes of arriving. She hardly even noticed."</span></span><br><span class="line"></span><br><span class="line">cleaned = re.sub(<span class="string">'\W+'</span>, <span class="string">' '</span>, text)</span><br><span class="line">tokenized = word_tokenize(cleaned)</span><br><span class="line"></span><br><span class="line">stemmer = PorterStemmer()</span><br><span class="line">stemmed = [stemmer.stem(token) <span class="keyword">for</span> token <span class="keyword">in</span> tokenized]</span><br><span class="line"></span><br><span class="line"><span class="comment">## -- CHANGE these -- ##</span></span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line">lemmatized = [lemmatizer.lemmatize(token, get_part_of_speech(token)) <span class="keyword">for</span> token <span class="keyword">in</span> tokenized]</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Stemmed text:"</span>)</span><br><span class="line">print(stemmed)</span><br><span class="line">print(<span class="string">"\nLemmatized text:"</span>)</span><br><span class="line">print(lemmatized)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Stemmed text:</span><br><span class="line">[<span class="string">'So'</span>, <span class="string">'mani'</span>, <span class="string">'squid'</span>, <span class="string">'are'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'suitcas'</span>, <span class="string">'these'</span>, <span class="string">'day'</span>, <span class="string">'that'</span>, <span class="string">'you'</span>, <span class="string">'can'</span>, <span class="string">'bare'</span>, <span class="string">'go'</span>, <span class="string">'anywher'</span>, <span class="string">'without'</span>, <span class="string">'see'</span>, <span class="string">'one'</span>, <span class="string">'burst'</span>, <span class="string">'forth'</span>, <span class="string">'from'</span>, <span class="string">'a'</span>, <span class="string">'tightli'</span>, <span class="string">'pack'</span>, <span class="string">'valis'</span>, <span class="string">'I'</span>, <span class="string">'went'</span>, <span class="string">'to'</span>, <span class="string">'the'</span>, <span class="string">'dentist'</span>, <span class="string">'the'</span>, <span class="string">'other'</span>, <span class="string">'day'</span>, <span class="string">'and'</span>, <span class="string">'sure'</span>, <span class="string">'enough'</span>, <span class="string">'I'</span>, <span class="string">'saw'</span>, <span class="string">'an'</span>, <span class="string">'angri'</span>, <span class="string">'one'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'my'</span>, <span class="string">'dentist'</span>, <span class="string">'s'</span>, <span class="string">'bag'</span>, <span class="string">'within'</span>, <span class="string">'minut'</span>, <span class="string">'of'</span>, <span class="string">'arriv'</span>, <span class="string">'she'</span>, <span class="string">'hardli'</span>, <span class="string">'even'</span>, <span class="string">'notic'</span>]</span><br><span class="line"></span><br><span class="line">Lemmatized text:</span><br><span class="line">[<span class="string">'So'</span>, <span class="string">'many'</span>, <span class="string">'squid'</span>, <span class="string">'be'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'suitcase'</span>, <span class="string">'these'</span>, <span class="string">'day'</span>, <span class="string">'that'</span>, <span class="string">'you'</span>, <span class="string">'can'</span>, <span class="string">'barely'</span>, <span class="string">'go'</span>, <span class="string">'anywhere'</span>, <span class="string">'without'</span>, <span class="string">'see'</span>, <span class="string">'one'</span>, <span class="string">'burst'</span>, <span class="string">'forth'</span>, <span class="string">'from'</span>, <span class="string">'a'</span>, <span class="string">'tightly'</span>, <span class="string">'pack'</span>, <span class="string">'valise'</span>, <span class="string">'I'</span>, <span class="string">'go'</span>, <span class="string">'to'</span>, <span class="string">'the'</span>, <span class="string">'dentist'</span>, <span class="string">'the'</span>, <span class="string">'other'</span>, <span class="string">'day'</span>, <span class="string">'and'</span>, <span class="string">'sure'</span>, <span class="string">'enough'</span>, <span class="string">'I'</span>, <span class="string">'saw'</span>, <span class="string">'an'</span>, <span class="string">'angry'</span>, <span class="string">'one'</span>, <span class="string">'jump'</span>, <span class="string">'out'</span>, <span class="string">'of'</span>, <span class="string">'my'</span>, <span class="string">'dentist'</span>, <span class="string">'s'</span>, <span class="string">'bag'</span>, <span class="string">'within'</span>, <span class="string">'minute'</span>, <span class="string">'of'</span>, <span class="string">'arrive'</span>, <span class="string">'She'</span>, <span class="string">'hardly'</span>, <span class="string">'even'</span>, <span class="string">'notice'</span>]</span><br></pre></td></tr></table></figure>



<h3 id="Parsing-Text"><a href="#Parsing-Text" class="headerlink" title="Parsing Text"></a>Parsing Text</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> Tree</span><br><span class="line"><span class="keyword">from</span> squids <span class="keyword">import</span> squids_text</span><br><span class="line"></span><br><span class="line">dependency_parser = spacy.load(<span class="string">'en'</span>)</span><br><span class="line"></span><br><span class="line">parsed_squids = dependency_parser(squids_text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assign my_sentence a new value:</span></span><br><span class="line">my_sentence = <span class="string">"Your sentence goes here!"</span></span><br><span class="line">my_parsed_sentence = dependency_parser(my_sentence)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_nltk_tree</span><span class="params">(node)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> node.n_lefts + node.n_rights &gt; <span class="number">0</span>:</span><br><span class="line">    parsed_child_nodes = [to_nltk_tree(child) <span class="keyword">for</span> child <span class="keyword">in</span> node.children]</span><br><span class="line">    <span class="keyword">return</span> Tree(node.orth_, parsed_child_nodes)</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> node.orth_</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> parsed_squids.sents:</span><br><span class="line">  to_nltk_tree(sent.root).pretty_print()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> sent <span class="keyword">in</span> my_parsed_sentence.sents:</span><br><span class="line"> to_nltk_tree(sent.root).pretty_print()</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">        jumping                       </span><br><span class="line">  _________|_______________________    </span><br><span class="line"> |   |     |      |       out      |  </span><br><span class="line"> |   |     |      |        |       |   </span><br><span class="line"> |   |     |    squids     of     days</span><br><span class="line"> |   |     |      |        |       |   </span><br><span class="line"> So are    .     many  suitcases these</span><br><span class="line"></span><br><span class="line">          go                       </span><br><span class="line">  ________|____________________     </span><br><span class="line"> |   |    |       |      |  without</span><br><span class="line"> |   |    |       |      |     |    </span><br><span class="line"> |   |    |       |      |   seeing</span><br><span class="line"> |   |    |       |      |     |    </span><br><span class="line">You can barely anywhere  .    one  </span><br><span class="line"></span><br><span class="line">          went               </span><br><span class="line">  _________|_________         </span><br><span class="line"> |   |     to        |       </span><br><span class="line"> |   |     |         |        </span><br><span class="line"> |   |  dentist     day      </span><br><span class="line"> |   |     |      ___|____    </span><br><span class="line"> I   .    the   the     other</span><br><span class="line"></span><br><span class="line">             saw                                     </span><br><span class="line">  ____________|___________________                    </span><br><span class="line"> |   |   |    |                  jump                </span><br><span class="line"> |   |   |    |          _________|__________         </span><br><span class="line"> |   |   |    |         |                   out      </span><br><span class="line"> |   |   |    |         |                    |        </span><br><span class="line"> |   |   |    |         |                    of      </span><br><span class="line"> |   |   |    |         |                    |        </span><br><span class="line"> |   |   |    |         |                   bag      </span><br><span class="line"> |   |   |    |         |                    |        </span><br><span class="line"> |   |   |  enough     one                dentist    </span><br><span class="line"> |   |   |    |      ___|____           _____|_____   </span><br><span class="line"> ,   I   .   Sure   an     angry       my          <span class="string">'s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    noticed         </span></span><br><span class="line"><span class="string">  _____|__________   </span></span><br><span class="line"><span class="string">She  hardly even  . </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">     goes         </span></span><br><span class="line"><span class="string">  ____|______      </span></span><br><span class="line"><span class="string"> |    |   sentence</span></span><br><span class="line"><span class="string"> |    |      |     </span></span><br><span class="line"><span class="string">here  !     Your</span></span><br></pre></td></tr></table></figure>



<h3 id="Language-Models-Bag-of-Words-Approach"><a href="#Language-Models-Bag-of-Words-Approach" class="headerlink" title="Language Models - Bag-of-Words Approach"></a>Language Models - Bag-of-Words Approach</h3><p>When grammar and word order are irrelevant, this is probably a good model to use.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># importing regex and nltk</span></span><br><span class="line"><span class="keyword">import</span> re, nltk</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="comment"># importing Counter to get word counts for bag of words</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="comment"># importing a passage from Through the Looking Glass</span></span><br><span class="line"><span class="keyword">from</span> looking_glass <span class="keyword">import</span> looking_glass_text</span><br><span class="line"><span class="comment"># importing part-of-speech function for lemmatization</span></span><br><span class="line"><span class="keyword">from</span> part_of_speech <span class="keyword">import</span> get_part_of_speech</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change text to another string:</span></span><br><span class="line"><span class="comment"># text = looking_glass_text</span></span><br><span class="line">text = <span class="string">"hello world i miss you"</span></span><br><span class="line"></span><br><span class="line">cleaned = re.sub(<span class="string">'\W+'</span>, <span class="string">' '</span>, text).lower()</span><br><span class="line">tokenized = word_tokenize(cleaned)</span><br><span class="line"></span><br><span class="line">stop_words = stopwords.words(<span class="string">'english'</span>)</span><br><span class="line">filtered = [word <span class="keyword">for</span> word <span class="keyword">in</span> tokenized <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stop_words]</span><br><span class="line"></span><br><span class="line">normalizer = WordNetLemmatizer()</span><br><span class="line">normalized = [normalizer.lemmatize(token, get_part_of_speech(token)) <span class="keyword">for</span> token <span class="keyword">in</span> filtered]</span><br><span class="line"><span class="comment"># Comment out the print statement below</span></span><br><span class="line">print(normalized)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define bag_of_looking_glass_words &amp; print:</span></span><br><span class="line">bag_of_looking_glass_words = Counter(normalized)</span><br><span class="line">print(bag_of_looking_glass_words)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'hello'</span>, <span class="string">'world'</span>, <span class="string">'miss'</span>]</span><br><span class="line">Counter(&#123;<span class="string">'hello'</span>: 1, <span class="string">'world'</span>: 1, <span class="string">'miss'</span>: 1&#125;)</span><br></pre></td></tr></table></figure>



<h3 id="Language-Models-N-Grams-and-NLM"><a href="#Language-Models-N-Grams-and-NLM" class="headerlink" title="Language Models - N-Grams and NLM"></a>Language Models - N-Grams and NLM</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk, re</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="comment"># importing ngrams module from nltk</span></span><br><span class="line"><span class="keyword">from</span> nltk.util <span class="keyword">import</span> ngrams</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">from</span> looking_glass <span class="keyword">import</span> looking_glass_full_text</span><br><span class="line"></span><br><span class="line">cleaned = re.sub(<span class="string">'\W+'</span>, <span class="string">' '</span>, looking_glass_full_text).lower()</span><br><span class="line">tokenized = word_tokenize(cleaned)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the n value to 2:</span></span><br><span class="line">looking_glass_bigrams = ngrams(tokenized, <span class="number">2</span>)</span><br><span class="line">looking_glass_bigrams_frequency = Counter(looking_glass_bigrams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the n value to 3:</span></span><br><span class="line">looking_glass_trigrams = ngrams(tokenized, <span class="number">3</span>)</span><br><span class="line">looking_glass_trigrams_frequency = Counter(looking_glass_trigrams)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the n value to a number greater than 3:</span></span><br><span class="line">looking_glass_ngrams = ngrams(tokenized, <span class="number">4</span>)</span><br><span class="line">looking_glass_ngrams_frequency = Counter(looking_glass_ngrams)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Looking Glass Bigrams:"</span>)</span><br><span class="line">print(looking_glass_bigrams_frequency.most_common(<span class="number">10</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\nLooking Glass Trigrams:"</span>)</span><br><span class="line">print(looking_glass_trigrams_frequency.most_common(<span class="number">10</span>), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">3</span></span><br><span class="line">print(<span class="string">"\nLooking Glass n-grams:"</span>)</span><br><span class="line">print(looking_glass_ngrams_frequency.most_common(<span class="number">10</span>), <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Looking Glass Bigrams:</span><br><span class="line">[((<span class="string">'of'</span>, <span class="string">'the'</span>), 101), ((<span class="string">'said'</span>, <span class="string">'the'</span>), 98), ((<span class="string">'in'</span>, <span class="string">'a'</span>), 97), ((<span class="string">'in'</span>, <span class="string">'the'</span>), 90), ((<span class="string">'as'</span>, <span class="string">'she'</span>), 82), ((<span class="string">'you'</span>, <span class="string">'know'</span>), 72), ((<span class="string">'a'</span>, <span class="string">'little'</span>), 68), ((<span class="string">'the'</span>, <span class="string">'queen'</span>), 67), ((<span class="string">'said'</span>, <span class="string">'alice'</span>), 67), ((<span class="string">'to'</span>, <span class="string">'the'</span>), 66)] 2</span><br><span class="line"></span><br><span class="line">Looking Glass Trigrams:</span><br><span class="line">[((<span class="string">'the'</span>, <span class="string">'red'</span>, <span class="string">'queen'</span>), 54), ((<span class="string">'the'</span>, <span class="string">'white'</span>, <span class="string">'queen'</span>), 31), ((<span class="string">'said'</span>, <span class="string">'in'</span>, <span class="string">'a'</span>), 21), ((<span class="string">'she'</span>, <span class="string">'went'</span>, <span class="string">'on'</span>), 18), ((<span class="string">'said'</span>, <span class="string">'the'</span>, <span class="string">'red'</span>), 17), ((<span class="string">'thought'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 16), ((<span class="string">'the'</span>, <span class="string">'queen'</span>, <span class="string">'said'</span>), 16), ((<span class="string">'said'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 14), ((<span class="string">'said'</span>, <span class="string">'humpty'</span>, <span class="string">'dumpty'</span>), 14), ((<span class="string">'the'</span>, <span class="string">'knight'</span>, <span class="string">'said'</span>), 14)] 3</span><br><span class="line"></span><br><span class="line">Looking Glass n-grams:</span><br><span class="line">[((<span class="string">'said'</span>, <span class="string">'the'</span>, <span class="string">'red'</span>, <span class="string">'queen'</span>), 15), ((<span class="string">'she'</span>, <span class="string">'said'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 11), ((<span class="string">'alice'</span>, <span class="string">'thought'</span>, <span class="string">'to'</span>, <span class="string">'herself'</span>), 9), ((<span class="string">'to'</span>, <span class="string">'herself'</span>, <span class="string">'as'</span>, <span class="string">'she'</span>), 9), ((<span class="string">'one'</span>, <span class="string">'and'</span>, <span class="string">'one'</span>, <span class="string">'and'</span>), 8), ((<span class="string">'and'</span>, <span class="string">'one'</span>, <span class="string">'and'</span>, <span class="string">'one'</span>), 8), ((<span class="string">'alice'</span>, <span class="string">'said'</span>, <span class="string">'in'</span>, <span class="string">'a'</span>), 6), ((<span class="string">'for'</span>, <span class="string">'a'</span>, <span class="string">'minute'</span>, <span class="string">'or'</span>), 6), ((<span class="string">'a'</span>, <span class="string">'minute'</span>, <span class="string">'or'</span>, <span class="string">'two'</span>), 6), ((<span class="string">'in'</span>, <span class="string">'a'</span>, <span class="string">'tone'</span>, <span class="string">'of'</span>), 6)] 5</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk, re</span><br><span class="line"><span class="keyword">from</span> sherlock_holmes <span class="keyword">import</span> bohemia_ch1, bohemia_ch2, bohemia_ch3, boscombe_ch1, boscombe_ch2, boscombe_ch3</span><br><span class="line"><span class="keyword">from</span> preprocessing <span class="keyword">import</span> preprocess_text</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer, TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> LatentDirichletAllocation</span><br><span class="line"></span><br><span class="line"><span class="comment"># preparing the text</span></span><br><span class="line">corpus = [bohemia_ch1, bohemia_ch2, bohemia_ch3, boscombe_ch1, boscombe_ch2, boscombe_ch3]</span><br><span class="line">preprocessed_corpus = [preprocess_text(chapter) <span class="keyword">for</span> chapter <span class="keyword">in</span> corpus]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update stop_list:</span></span><br><span class="line">stop_list = []</span><br><span class="line"><span class="comment"># filtering topics for stop words</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter_out_stop_words</span><span class="params">(corpus)</span>:</span></span><br><span class="line">  no_stops_corpus = []</span><br><span class="line">  <span class="keyword">for</span> chapter <span class="keyword">in</span> corpus:</span><br><span class="line">    no_stops_chapter = <span class="string">" "</span>.join([word <span class="keyword">for</span> word <span class="keyword">in</span> chapter.split(<span class="string">" "</span>) <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> stop_list])</span><br><span class="line">    no_stops_corpus.append(no_stops_chapter)</span><br><span class="line">  <span class="keyword">return</span> no_stops_corpus</span><br><span class="line">filtered_for_stops = filter_out_stop_words(preprocessed_corpus)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the bag of words model</span></span><br><span class="line">bag_of_words_creator = CountVectorizer()</span><br><span class="line">bag_of_words = bag_of_words_creator.fit_transform(filtered_for_stops)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the tf-idf model</span></span><br><span class="line">tfidf_creator = TfidfVectorizer(min_df = <span class="number">0.2</span>)</span><br><span class="line">tfidf = tfidf_creator.fit_transform(preprocessed_corpus)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the bag of words LDA model</span></span><br><span class="line">lda_bag_of_words_creator = LatentDirichletAllocation(learning_method=<span class="string">'online'</span>, n_components=<span class="number">10</span>)</span><br><span class="line">lda_bag_of_words = lda_bag_of_words_creator.fit_transform(bag_of_words)</span><br><span class="line"></span><br><span class="line"><span class="comment"># creating the tf-idf LDA model</span></span><br><span class="line">lda_tfidf_creator = LatentDirichletAllocation(learning_method=<span class="string">'online'</span>, n_components=<span class="number">10</span>)</span><br><span class="line">lda_tfidf = lda_tfidf_creator.fit_transform(tfidf)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"~~~ Topics found by bag of words LDA ~~~"</span>)</span><br><span class="line"><span class="keyword">for</span> topic_id, topic <span class="keyword">in</span> enumerate(lda_bag_of_words_creator.components_):</span><br><span class="line">  message = <span class="string">"Topic #&#123;&#125;: "</span>.format(topic_id + <span class="number">1</span>)</span><br><span class="line">  message += <span class="string">" "</span>.join([bag_of_words_creator.get_feature_names()[i] <span class="keyword">for</span> i <span class="keyword">in</span> topic.argsort()[:<span class="number">-5</span> :<span class="number">-1</span>]])</span><br><span class="line">  print(message)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"\n\n~~~ Topics found by tf-idf LDA ~~~"</span>)</span><br><span class="line"><span class="keyword">for</span> topic_id, topic <span class="keyword">in</span> enumerate(lda_tfidf_creator.components_):</span><br><span class="line">  message = <span class="string">"Topic #&#123;&#125;: "</span>.format(topic_id + <span class="number">1</span>)</span><br><span class="line">  message += <span class="string">" "</span>.join([tfidf_creator.get_feature_names()[i] <span class="keyword">for</span> i <span class="keyword">in</span> topic.argsort()[:<span class="number">-5</span> :<span class="number">-1</span>]])</span><br><span class="line">  print(message)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">~~~ Topics found by bag of words LDA ~~~</span><br><span class="line">Topic <span class="comment">#1: holmes say little upon</span></span><br><span class="line">Topic <span class="comment">#2: house come could man</span></span><br><span class="line">Topic <span class="comment">#3: holmes say know come</span></span><br><span class="line">Topic <span class="comment">#4: holmes would say know</span></span><br><span class="line">Topic <span class="comment">#5: say holmes know see</span></span><br><span class="line">Topic <span class="comment">#6: say holmes man could</span></span><br><span class="line">Topic <span class="comment">#7: say upon mccarthy man</span></span><br><span class="line">Topic <span class="comment">#8: make holmes cry majesty</span></span><br><span class="line">Topic <span class="comment">#9: holmes say man upon</span></span><br><span class="line">Topic <span class="comment">#10: upon holmes see say</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">~~~ Topics found by tf-idf LDA ~~~</span><br><span class="line">Topic <span class="comment">#1: merely upon boot catch</span></span><br><span class="line">Topic <span class="comment">#2: boot save holmes mccarthy</span></span><br><span class="line">Topic <span class="comment">#3: norton resolve help refer</span></span><br><span class="line">Topic <span class="comment">#4: leave remove three lodge</span></span><br><span class="line">Topic <span class="comment">#5: say neck resolute stone</span></span><br><span class="line">Topic <span class="comment">#6: holmes king majesty photograph</span></span><br><span class="line">Topic <span class="comment">#7: fear together heavy upon</span></span><br><span class="line">Topic <span class="comment">#8: holmes say know man</span></span><br><span class="line">Topic <span class="comment">#9: figure surround definite heel</span></span><br><span class="line">Topic <span class="comment">#10: know many swiftly scotland</span></span><br></pre></td></tr></table></figure>



<h3 id="Text-Similarity"><a href="#Text-Similarity" class="headerlink" title="Text Similarity"></a>Text Similarity</h3><p>Most of us have a good autocorrect story. Our phone’s messenger quietly swaps one letter for another as we type and suddenly the meaning of our message has changed (to our horror or pleasure). However, addressing <strong><em>text similarity\</em></strong> — including spelling correction — is a major challenge within natural language processing.</p>
<p>Addressing word similarity and misspelling for spellcheck or autocorrect often involves considering the <strong><em>Levenshtein distance\</em></strong> or minimal edit distance between two words. The distance is calculated through the minimum number of insertions, deletions, and substitutions that would need to occur for one word to become another. For example, turning “bees” into “beans” would require one substitution (“a” for “e”) and one insertion (“n”), so the Levenshtein distance would be two.</p>
<p>Phonetic similarity is also a major challenge within speech recognition. English-speaking humans can easily tell from context whether someone said “euthanasia” or “youth in Asia,” but it’s a far more challenging task for a machine! More advanced autocorrect and spelling correction technology additionally considers key distance on a keyboard and <strong><em>phonetic similarity\</em></strong> (how much two words or phrases sound the same).</p>
<p>It’s also helpful to find out if texts are the same to guard against plagiarism, which we can identify through <strong><em>lexical similarity\</em></strong> (the degree to which texts use the same vocabulary and phrases). Meanwhile, <strong><em>semantic similarity\</em></strong> (the degree to which documents contain similar meaning or topics) is useful when you want to find (or recommend) an article or book similar to one you recently finished.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="comment"># NLTK has a built-in function</span></span><br><span class="line"><span class="comment"># to check Levenshtein distance:</span></span><br><span class="line"><span class="keyword">from</span> nltk.metrics <span class="keyword">import</span> edit_distance</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_levenshtein</span><span class="params">(string1, string2)</span>:</span></span><br><span class="line">  print(<span class="string">"The Levenshtein distance from '&#123;0&#125;' to '&#123;1&#125;' is &#123;2&#125;!"</span>.format(string1, string2, edit_distance(string1, string2)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the distance between</span></span><br><span class="line"><span class="comment"># any two words here!</span></span><br><span class="line">print_levenshtein(<span class="string">"fart"</span>, <span class="string">"target"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Assign passing strings here:</span></span><br><span class="line">three_away_from_code = <span class="string">"cat"</span></span><br><span class="line"></span><br><span class="line">two_away_from_chunk = <span class="string">"cheek"</span></span><br><span class="line"></span><br><span class="line">print_levenshtein(<span class="string">"code"</span>, three_away_from_code)</span><br><span class="line">print_levenshtein(<span class="string">"chunk"</span>, two_away_from_chunk)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The Levenshtein distance from <span class="string">'fart'</span> to <span class="string">'target'</span> is 3!</span><br><span class="line">The Levenshtein distance from <span class="string">'code'</span> to <span class="string">'cat'</span> is 3!</span><br><span class="line">The Levenshtein distance from <span class="string">'chunk'</span> to <span class="string">'cheek'</span> is 2!</span><br></pre></td></tr></table></figure>



<h3 id="Language-Prediction-amp-Text-Generation"><a href="#Language-Prediction-amp-Text-Generation" class="headerlink" title="Language Prediction &amp; Text Generation"></a>Language Prediction &amp; Text Generation</h3><p>How does your favorite search engine complete your search queries? How does your phone’s keyboard know what you want to type next? <strong><em>Language prediction\</em></strong> is an application of NLP concerned with predicting text given preceding text. Autosuggest, autocomplete, and suggested replies are common forms of language prediction.</p>
<p>Your first step to language prediction is picking a language model. Bag of words alone is generally not a great model for language prediction; no matter what the preceding word was, you will just get one of the most commonly used words from your training corpus.</p>
<p>If you go the <em>n</em>-gram route, you will most likely rely on <strong><em>Markov chains\</em></strong> to predict the statistical likelihood of each following word (or character) based on the training corpus. Markov chains are memory-less and make statistical predictions based entirely on the current <em>n</em>-gram on hand.</p>
<p>For example, let’s take a sentence beginning, “I ate so many grilled cheese”. Using a trigram model (where <em>n</em> is 3), a Markov chain would predict the following word as “sandwiches” based on the number of times the sequence “grilled cheese sandwiches” has appeared in the training data out of all the times “grilled cheese” has appeared in the training data.</p>
<p>A more advanced approach, using a neural language model, is the <strong><em>Long Short Term Memory (LSTM)\</em></strong> model. LSTM uses deep learning with a network of artificial “cells” that manage memory, making them better suited for text prediction than traditional neural networks.</p>
<p><strong>1.</strong></p>
<p>Add three short stories by your favorite author or the lyrics to three songs by your favorite artist to <strong>document1.py</strong>, <strong>document2.py</strong>, and <strong>document3.py</strong>. Then run <strong>script.py</strong> to see a short example of text prediction.</p>
<p>Does it look like something by your favorite author or artist?</p>
<p>If you accidentally close one of the files, just click the file folder in the top left corner of the code editor to find the file and re-open it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk, re, random</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict, deque</span><br><span class="line"><span class="keyword">from</span> document1 <span class="keyword">import</span> training_doc1</span><br><span class="line"><span class="keyword">from</span> document2 <span class="keyword">import</span> training_doc2</span><br><span class="line"><span class="keyword">from</span> document3 <span class="keyword">import</span> training_doc3</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MarkovChain</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.lookup_dict = defaultdict(list)</span><br><span class="line">    self._seeded = <span class="literal">False</span></span><br><span class="line">    self.__seed_me()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__seed_me</span><span class="params">(self, rand_seed=None)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> self._seeded <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">True</span>:</span><br><span class="line">      <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> rand_seed <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          random.seed(rand_seed)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          random.seed()</span><br><span class="line">        self._seeded = <span class="literal">True</span></span><br><span class="line">      <span class="keyword">except</span> NotImplementedError:</span><br><span class="line">        self._seeded = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">add_document</span><span class="params">(self, str)</span>:</span></span><br><span class="line">    preprocessed_list = self._preprocess(str)</span><br><span class="line">    pairs = self.__generate_tuple_keys(preprocessed_list)</span><br><span class="line">    <span class="keyword">for</span> pair <span class="keyword">in</span> pairs:</span><br><span class="line">      self.lookup_dict[pair[<span class="number">0</span>]].append(pair[<span class="number">1</span>])</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_preprocess</span><span class="params">(self, str)</span>:</span></span><br><span class="line">    cleaned = re.sub(<span class="string">r'\W+'</span>, <span class="string">' '</span>, str).lower()</span><br><span class="line">    tokenized = word_tokenize(cleaned)</span><br><span class="line">    <span class="keyword">return</span> tokenized</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__generate_tuple_keys</span><span class="params">(self, data)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(data) &lt; <span class="number">1</span>:</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data) - <span class="number">1</span>):</span><br><span class="line">      <span class="keyword">yield</span> [ data[i], data[i + <span class="number">1</span>] ]</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">generate_text</span><span class="params">(self, max_length=<span class="number">50</span>)</span>:</span></span><br><span class="line">    context = deque()</span><br><span class="line">    output = []</span><br><span class="line">    <span class="keyword">if</span> len(self.lookup_dict) &gt; <span class="number">0</span>:</span><br><span class="line">      self.__seed_me(rand_seed=len(self.lookup_dict))</span><br><span class="line">      chain_head = [list(self.lookup_dict)[<span class="number">0</span>]]</span><br><span class="line">      context.extend(chain_head)</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">while</span> len(output) &lt; (max_length - <span class="number">1</span>):</span><br><span class="line">        next_choices = self.lookup_dict[context[<span class="number">-1</span>]]</span><br><span class="line">        <span class="keyword">if</span> len(next_choices) &gt; <span class="number">0</span>:</span><br><span class="line">          next_word = random.choice(next_choices)</span><br><span class="line">          context.append(next_word)</span><br><span class="line">          output.append(context.popleft())</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">          <span class="keyword">break</span></span><br><span class="line">      output.extend(list(context))</span><br><span class="line">    <span class="keyword">return</span> <span class="string">" "</span>.join(output)</span><br><span class="line"></span><br><span class="line">my_markov = MarkovChain()</span><br><span class="line">my_markov.add_document(training_doc1)</span><br><span class="line">my_markov.add_document(training_doc2)</span><br><span class="line">my_markov.add_document(training_doc3)</span><br><span class="line">generated_text = my_markov.generate_text()</span><br><span class="line">print(generated_text)</span><br></pre></td></tr></table></figure>

</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/03/28/Web/2020-03-28-Full%20Stack%20review/">Web/2020-03-28-Full Stack review</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-28</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/Web/">Web</a></span><div class="content"><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd8e8h8nvzj317g0g6n9s.jpg" alt="image-20200327125348804" style="zoom:67%;" /></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/03/23/System-Design/Abstraction/2020-03-15-System%20Design%20Abstraction%201/">System-Design/Abstraction/2020-03-15-System Design Abstraction 1</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-23</time><div class="content"><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p><a href="https://aojajena.wordpress.com/2012/04/19/abstraction-in-design/" target="_blank" rel="noopener">https://aojajena.wordpress.com/2012/04/19/abstraction-in-design/</a></p>
<p><a href="http://web.stanford.edu/~ouster/CS349W/lectures/abstraction.html" target="_blank" rel="noopener">http://web.stanford.edu/~ouster/CS349W/lectures/abstraction.html</a></p>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd3y9agjg2j30sc0iu0w9.jpg" alt="image-20200323163855008"></p>
<h2 id="2-UI-amp-UX"><a href="#2-UI-amp-UX" class="headerlink" title="2 UI &amp; UX"></a>2 UI &amp; UX</h2><p><a href="https://99designs.com/blog/tips/7-unbreakable-laws-of-user-interface-design/" target="_blank" rel="noopener">https://99designs.com/blog/tips/7-unbreakable-laws-of-user-interface-design/</a></p>
<h3 id="User-Experience"><a href="#User-Experience" class="headerlink" title="User Experience"></a>User Experience</h3></div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/03/18/Books/2020-03-23-Lifes%20in%20English/">Books/2020-03-23-Lifes in English</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-18</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/English-Life/">English &amp; Life</a></span><div class="content"><blockquote>
<p>Ross: Probably. But you know, I’ll tell you something. Passion is way overrated.</p>
<p>Rachel: Yeah right.</p>
<p>Ross: It is… eventually… kind of… <strong>burns out</strong>. But hopefully, what you’re left with is trust, and security, and… well, in the case of my ex-wife, lesbianism. So, you know, for all of those people who <strong>miss out</strong> on that passion… thing, there’s all that other good stuff.</p>
</blockquote>
<p>Ref: <a href="http://www.tingroom.com/print_35336.html" target="_blank" rel="noopener">http://www.tingroom.com/print_35336.html</a></p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2020/03/18/Web/2020-03-27-Design%20User%20System%20DB%20&amp;%20Cache/">Web/2020-03-27-Design User System DB &amp; Cache</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-18</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/SystemDesign/">SystemDesign</a></span><div class="content"><h1 id="Design-User-System"><a href="#Design-User-System" class="headerlink" title="Design User System"></a>Design User System</h1><p>註冊、登錄、查詢 (看別的好友之類)、修改info</p>
<blockquote>
<h5 id="单选题-以下四个操作哪个最频繁？"><a href="#单选题-以下四个操作哪个最频繁？" class="headerlink" title="[单选题]以下四个操作哪个最频繁？"></a>[单选题]以下四个操作哪个最频繁？</h5><p>A.注册3.36% 选择</p>
<p>B.登录44.02% 选择</p>
<p>C.用户信息查询50.67% 选择</p>
<p>D.用户信息修改1.94% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是B</p>
<p><strong>正确答案:</strong>C</p>
</blockquote>
<h3 id="Scenario"><a href="#Scenario" class="headerlink" title="Scenario"></a>Scenario</h3><h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><ul>
<li>Authentication Service</li>
<li>UserService</li>
<li>FriendshipService</li>
</ul>
<h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p>check SQL &amp; NoSQL &amp; Redis 對 QPS數的支持</p>
<blockquote>
<h5 id="多选题-注册，登录，信息修改使用哪种数据库可以满足？"><a href="#多选题-注册，登录，信息修改使用哪种数据库可以满足？" class="headerlink" title="[多选题]注册，登录，信息修改使用哪种数据库可以满足？"></a>[多选题]注册，登录，信息修改使用哪种数据库可以满足？</h5><p>A.MySQL60.32% 选择</p>
<p>B.Cassandra18.05% 选择</p>
<p>C.Redis13.46% 选择</p>
<p>D.Memcached8.18% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是ACD</p>
<p><strong>正确答案:</strong>ABC</p>
<p><strong>解析:</strong></p>
<p>Memcached 不能持久化存储数据，不适合用来存储用户信息</p>
</blockquote>
<blockquote>
<ul>
<li><p>Q: 10k ~ 100k QPS?</p>
<ul>
<li>看需求。可以使用单台redis或者使用多台Cassandra的集群，又或者如果你的场景需要高可靠性的事务支持，但是读多写少，那就MySQL做持久化+memcached做cache优化。不同的数据库有不同的功能，这里列出的QPS只是为了告诉你各个数据库的承载能力，不是说xxxQPS就一定要用xxx数据库，QPS不是唯一决定因素，需要结合实际需求分析。</li>
</ul>
</li>
<li><p>为什么Mysql只支持1k 的QPS,但facebook 依然会选择。 facebook的QPS应该远高于1k吧</p>
<ul>
<li>单机1k左右，但是facebook的是mysql集群，QPS肯定不是这个量级的</li>
</ul>
</li>
<li><p>redis，memcached会比普通的存储贵吗</p>
<ul>
<li>redis memcached 用 memory 多，肯定比主要用 disk 的机器要贵的。</li>
</ul>
</li>
</ul>
</blockquote>
<p>讀多寫少，代表經常不會變！</p>
<blockquote>
<h5 id="多选题-文件系统可以用作缓存么？如果可以，可以做什么的缓存？"><a href="#多选题-文件系统可以用作缓存么？如果可以，可以做什么的缓存？" class="headerlink" title="[多选题]文件系统可以用作缓存么？如果可以，可以做什么的缓存？"></a>[多选题]文件系统可以用作缓存么？如果可以，可以做什么的缓存？</h5><p>A.不可以1.22% 选择</p>
<p>B.用来做网络请求的缓存。30.30% 选择</p>
<p>C.用来做计算结果的缓存34.45% 选择</p>
<p>D.用来做数据库的缓存34.04% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是BD</p>
<p><strong>正确答案:</strong>BC</p>
<p><strong>解析:</strong></p>
<p>缓存的目的是让访问变得更快。文件系统的访问比网络访问快，一些耗时很长的计算得到的结果也可以缓存在文件中，但是文件系统的访问速度和数据库的访问速度基本上是差不多，所以一般不会用文件系统来做数据库的缓存，意义不大。</p>
</blockquote>
<blockquote>
<h5 id="多选题-下面哪些写法是“不对”的？"><a href="#多选题-下面哪些写法是“不对”的？" class="headerlink" title="[多选题]下面哪些写法是“不对”的？"></a>[多选题]下面哪些写法是“不对”的？</h5><p>哪些写法可能造成数据的不一致？也就是数据库和缓存中存储的数据不一样。</p>
<p>A.db.set; cache.set29.67% 选择</p>
<p>B.db.set; cache.delete29.48% 选择</p>
<p>C.cache.set; db.set29.83% 选择</p>
<p>D.cache.delete; db.set11.02% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTM0MTgxMjgxODM5IiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjM3NjIiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMzIiIGhlaWdodD0iMzIiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxOC4xMiA1MTYuMTZtLTQ5MCAwYTQ5MCA0OTAgMCAxIDAgOTgwIDAgNDkwIDQ5MCAwIDEgMC05ODAgMFoiIGZpbGw9IiM1NkI0MzIiIHAtaWQ9IjM3NjMiPjwvcGF0aD48cGF0aCBkPSJNMzkzLjIxMzYxOSA2NjQuMzM1NDk1bTI4LjI4NDI3MS0yOC4yODQyNzFsMjk2Ljk4NDg0OS0yOTYuOTg0ODQ4cTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBsMCAwcTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDJsLTI5Ni45ODQ4NDggMjk2Ljk4NDg0OHEtMjguMjg0MjcxIDI4LjI4NDI3MS01Ni41Njg1NDMgMGwwIDBxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDJaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY0Ij48L3BhdGg+PHBhdGggZD0iTTI4OS40Njk4NCA0NTIuODQ3ODgzbTI4LjI4NDI3MSAyOC4yODQyNzFsMTU1LjU2MzQ5MiAxNTUuNTYzNDkycTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDNsMCAwcS0yOC4yODQyNzEgMjguMjg0MjcxLTU2LjU2ODU0MyAwbC0xNTUuNTYzNDkxLTE1NS41NjM0OTJxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDNsMCAwcTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY1Ij48L3BhdGg+PC9zdmc+" alt="img">答对了，您选择的答案是ABCD</p>
<p><strong>正确答案:</strong>ABCD</p>
</blockquote>
<blockquote>
<h5 id="单选题-有没有可能第一个执行失败，第二个执行成功？"><a href="#单选题-有没有可能第一个执行失败，第二个执行成功？" class="headerlink" title="[单选题]有没有可能第一个执行失败，第二个执行成功？"></a>[单选题]有没有可能第一个执行失败，第二个执行成功？</h5><p>A.可能，会造成数据不一致55.52% 选择</p>
<p>B.可能，不会造成数据不一致12.52% 选择</p>
<p>C.不可能，不会造成数据不一致31.96% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是A</p>
<p><strong>正确答案:</strong>C</p>
<p><strong>解析:</strong></p>
<p>不可能。程序的执行是顺序执行的，第一个语句执行出错以后，第二个语句就不会执行了，用户会收到整个 setUser 操作失败的信息。</p>
</blockquote>
<blockquote>
<h5 id="多选题-cache-delete-db-set-什么情况下会造成数据不一致？"><a href="#多选题-cache-delete-db-set-什么情况下会造成数据不一致？" class="headerlink" title="[多选题]cache.delete + db.set 什么情况下会造成数据不一致？"></a>[多选题]cache.delete + db.set 什么情况下会造成数据不一致？</h5><p>A.多线程38.22% 选择</p>
<p>B.多进程28.27% 选择</p>
<p>C.多机器28.65% 选择</p>
<p>D.cache.delete 成功但 db.set 失败4.87% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是D</p>
<p><strong>正确答案:</strong>ABC</p>
<p><strong>解析:</strong></p>
<p>多机器的话自然而然也是多进程的。</p>
</blockquote>
<blockquote>
<h5 id="单选题-能否给数据库和缓存的操作加锁来保证数据一致性？"><a href="#单选题-能否给数据库和缓存的操作加锁来保证数据一致性？" class="headerlink" title="[单选题]能否给数据库和缓存的操作加锁来保证数据一致性？"></a>[单选题]能否给数据库和缓存的操作加锁来保证数据一致性？</h5><p>A.可以加锁47.11% 选择</p>
<p>B.加不了锁52.89% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTM0MTgxMjgxODM5IiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjM3NjIiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMzIiIGhlaWdodD0iMzIiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxOC4xMiA1MTYuMTZtLTQ5MCAwYTQ5MCA0OTAgMCAxIDAgOTgwIDAgNDkwIDQ5MCAwIDEgMC05ODAgMFoiIGZpbGw9IiM1NkI0MzIiIHAtaWQ9IjM3NjMiPjwvcGF0aD48cGF0aCBkPSJNMzkzLjIxMzYxOSA2NjQuMzM1NDk1bTI4LjI4NDI3MS0yOC4yODQyNzFsMjk2Ljk4NDg0OS0yOTYuOTg0ODQ4cTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBsMCAwcTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDJsLTI5Ni45ODQ4NDggMjk2Ljk4NDg0OHEtMjguMjg0MjcxIDI4LjI4NDI3MS01Ni41Njg1NDMgMGwwIDBxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDJaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY0Ij48L3BhdGg+PHBhdGggZD0iTTI4OS40Njk4NCA0NTIuODQ3ODgzbTI4LjI4NDI3MSAyOC4yODQyNzFsMTU1LjU2MzQ5MiAxNTUuNTYzNDkycTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDNsMCAwcS0yOC4yODQyNzEgMjguMjg0MjcxLTU2LjU2ODU0MyAwbC0xNTUuNTYzNDkxLTE1NS41NjM0OTJxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDNsMCAwcTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY1Ij48L3BhdGg+PC9zdmc+" alt="img">答对了，您选择的答案是B</p>
<p><strong>正确答案:</strong>B</p>
<p><strong>解析:</strong></p>
<p>加锁以后只能保证在同一个数据上的操作顺序执行，但是无法执行“回滚”，也就是说如果第一个操作成功，第二个操作失败了，也会导致数据的不一致。<br>另外互斥锁（mutex）是多线程内共享的，多进程内无法共享。如果要加锁，只能使用分布式锁，比如 Zookeeper，但是这会导致读取效率急剧降低。得不偿失。</p>
</blockquote>
<blockquote>
<h5 id="单选题-User-Table-的-Cache-Hit-Rate-一般有多少？"><a href="#单选题-User-Table-的-Cache-Hit-Rate-一般有多少？" class="headerlink" title="[单选题]User Table 的 Cache Hit Rate 一般有多少？"></a>[单选题]User Table 的 Cache Hit Rate 一般有多少？</h5><p>A.20%5.16% 选择</p>
<p>B.50%8.32% 选择</p>
<p>C.95%24.54% 选择</p>
<p>D.98%61.98% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTM0MTgxMjgxODM5IiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjM3NjIiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMzIiIGhlaWdodD0iMzIiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxOC4xMiA1MTYuMTZtLTQ5MCAwYTQ5MCA0OTAgMCAxIDAgOTgwIDAgNDkwIDQ5MCAwIDEgMC05ODAgMFoiIGZpbGw9IiM1NkI0MzIiIHAtaWQ9IjM3NjMiPjwvcGF0aD48cGF0aCBkPSJNMzkzLjIxMzYxOSA2NjQuMzM1NDk1bTI4LjI4NDI3MS0yOC4yODQyNzFsMjk2Ljk4NDg0OS0yOTYuOTg0ODQ4cTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBsMCAwcTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDJsLTI5Ni45ODQ4NDggMjk2Ljk4NDg0OHEtMjguMjg0MjcxIDI4LjI4NDI3MS01Ni41Njg1NDMgMGwwIDBxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDJaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY0Ij48L3BhdGg+PHBhdGggZD0iTTI4OS40Njk4NCA0NTIuODQ3ODgzbTI4LjI4NDI3MSAyOC4yODQyNzFsMTU1LjU2MzQ5MiAxNTUuNTYzNDkycTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDNsMCAwcS0yOC4yODQyNzEgMjguMjg0MjcxLTU2LjU2ODU0MyAwbC0xNTUuNTYzNDkxLTE1NS41NjM0OTJxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDNsMCAwcTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY1Ij48L3BhdGg+PC9zdmc+" alt="img">答对了，您选择的答案是D</p>
<p><strong>正确答案:</strong>D</p>
<p><strong>解析:</strong></p>
<p>hit rate = cache hit / (cache hit + cache miss)</p>
</blockquote>
<ul>
<li>我们允许数据库和缓存有“短时间”内的不一致，但最终会一致。</li>
</ul>
<blockquote>
<ul>
<li>database.set(key, user);cache.set(key)我觉得没有脏数据啊。当第一个线程1执行到15-16行之间的时候。假如有另一个线程2进入setUser这个函数。线程2的cache.set也会覆盖线程1的cache.set结果的啊，所以旧数据就被覆盖了啊。没有脏数据啊，求解释？</li>
</ul>
<p>假设执行顺序如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread 1 line 15: database.set(user) &#x2F;&#x2F; old data</span><br><span class="line">thread 2 line 15: database.set(user) &#x2F;&#x2F; new data</span><br><span class="line">thread 2 line 16: cache.set(user) &#x2F;&#x2F; new data</span><br><span class="line">thread 1 line 15: cache.set(user) &#x2F;&#x2F; old data</span><br></pre></td></tr></table></figure>

<p>最后 cache 里是 old data, database 里是 new data</p>
<p>线程2的cache.set也会覆盖线程1的cache.set结果的啊<br>在上面列举的情况中，是 thread 1 覆盖了 thread 2。要注意 user 是一个局部变量。thread 2 里的 user 和 thread 1 里的 user 的内容是不同的。</p>
</blockquote>
<p>如果寫真的太多太多了，在Cache Aside下，就是加DB啊。</p>
<blockquote>
<ul>
<li>redis包含cache和一个db，是说redis里面包含了relational database management system , rdbms么？ 我记得redis只是缓存，没mysql的呢。<ul>
<li>redis可以跟mysql配合使用，redis会完全接管mysql，自己从mysql里面load数据，所以在外界<strong>看起来</strong>就像是redis里面包了一个mysql一样。并不是说redis里面有一个mysql。</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="Authentication-Service"><a href="#Authentication-Service" class="headerlink" title="Authentication Service"></a>Authentication Service</h2><h3 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h3><p>可以用uuid()算這個hash值</p>
<p>通常用UUID来作为Session Key(Session Token)，UUID(Universal Unique ID): UUID是由一组32位数的16进制数字所构成，所以UUID理论上的总数为16^32=2^128，约等于3.4 x 10^38。也就是说若每纳秒产生1兆个UUID，要花100亿年才会将所有UUID用完。所以通俗的称之为宇宙爆炸都不会出现重复的ID字段。</p>
<blockquote>
<ul>
<li>cookie 存在browser 的哪里？<ul>
<li>browser 就是一个 client 就是一个客户端软件，是一个 application 是一个 software，一个程序，一段代码。一个 software 要持久化的存储一个东西，最终都是存储在操作系统的文件系统上的。</li>
</ul>
</li>
<li>session key一般有效期多久？<ul>
<li>取决于网站的安全等级，比如银行类的一般浏览器关掉 session key就过期了。社交类的一般就三个月甚至更长。这个可以由网站开发人员自行定义。</li>
</ul>
</li>
<li>any security problems regarding to session key?<ul>
<li>如果你的 session key 被盗，比如你拿了你男朋友女朋友的电脑，悄悄的记录下了 session key，你就可以以你男朋友女朋友的身份登录了。所以通常一些安全性较高的网站，如银行，session key 几分钟就会失效。</li>
</ul>
</li>
<li>session table 是存在数据库里， 还是存在In memory db 里面?<ul>
<li>都是可以的。不过一般都是存在 数据库里，否则memory数据丢了所有用户都会被logout 这个体验并不好。</li>
</ul>
</li>
<li>what if i never log in again? my session will live forever?<ul>
<li>通常网站的逻辑都是最多3个月。session table 里有 expire_at 这个 field，记录了什么时候会过期。一般用户登陆以后，这一项设置为 3 个月。当然你可以根据你网站的安全性要求来设置不同的过期时间，安全性越高的网站过期时间越短。一般不会设置为永久不过期。</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h3><ul>
<li>用户 Login 以后，为他创建一个 session 对象</li>
<li>并把 session_key 返回给浏览器，让浏览器存储起来</li>
<li>浏览器将该值记录在浏览器的 cookie 中</li>
<li>用户每次向服务器发送的访问，都会自动带上该网站所有的 cookie</li>
<li>此时服务器拿到 cookie 中的 session_key，在 Session Table 中检测是否存在，是否过期</li>
<li>Cookie:HTTP协议中浏览器和服务器的沟通机制，服务器把一些用于标记用户身份的信息，传递给 浏览器，浏览器每次访问任何网页链接的时候，都会在 HTTP 请求中带上所有的该网站相关的 Cookie 信息。Cookie 可以理解为一个 Client 端的 hash table。</li>
</ul>
<blockquote>
<h5 id="单选题-Cookie-里存的东西是越多越好么？"><a href="#单选题-Cookie-里存的东西是越多越好么？" class="headerlink" title="[单选题]Cookie 里存的东西是越多越好么？"></a>[单选题]Cookie 里存的东西是越多越好么？</h5><p>A.是的3.13% 选择</p>
<p>B.不是96.87% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTM0MTgxMjgxODM5IiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjM3NjIiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMzIiIGhlaWdodD0iMzIiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxOC4xMiA1MTYuMTZtLTQ5MCAwYTQ5MCA0OTAgMCAxIDAgOTgwIDAgNDkwIDQ5MCAwIDEgMC05ODAgMFoiIGZpbGw9IiM1NkI0MzIiIHAtaWQ9IjM3NjMiPjwvcGF0aD48cGF0aCBkPSJNMzkzLjIxMzYxOSA2NjQuMzM1NDk1bTI4LjI4NDI3MS0yOC4yODQyNzFsMjk2Ljk4NDg0OS0yOTYuOTg0ODQ4cTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBsMCAwcTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDJsLTI5Ni45ODQ4NDggMjk2Ljk4NDg0OHEtMjguMjg0MjcxIDI4LjI4NDI3MS01Ni41Njg1NDMgMGwwIDBxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDJaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY0Ij48L3BhdGg+PHBhdGggZD0iTTI4OS40Njk4NCA0NTIuODQ3ODgzbTI4LjI4NDI3MSAyOC4yODQyNzFsMTU1LjU2MzQ5MiAxNTUuNTYzNDkycTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDNsMCAwcS0yOC4yODQyNzEgMjguMjg0MjcxLTU2LjU2ODU0MyAwbC0xNTUuNTYzNDkxLTE1NS41NjM0OTJxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDNsMCAwcTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY1Ij48L3BhdGg+PC9zdmc+" alt="img">答对了，您选择的答案是B</p>
<p><strong>正确答案:</strong>B</p>
<p><strong>解析:</strong></p>
<p>首先 Cookie 的大小 HTTP 协议是有限制的。其次因为每次 Request 都要带上 Cookie 里的内容，因此 Cookie 里存的东西是越少越好而不是越多越好。</p>
</blockquote>
<p>一般就是放個session key表明用戶身份，如掛在胸前的牌，代表授權訪問的用戶。然後去session table查是不是過期了，查uuid(就是session key), 然後知道 user_id，就是client端的hash table。</p>
<blockquote>
<h5 id="单选题-服务器需要主动删除掉过期的-Session-么？"><a href="#单选题-服务器需要主动删除掉过期的-Session-么？" class="headerlink" title="[单选题]服务器需要主动删除掉过期的 Session 么？"></a>[单选题]服务器需要主动删除掉过期的 Session 么？</h5><p>A.需要34.19% 选择</p>
<p>B.不需要65.81% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是A</p>
<p><strong>正确答案:</strong>B</p>
<p><strong>解析:</strong></p>
<p>做 lazy loading 就好了。因为有 expire_at，无需主动删除，被动删除即可，即在用户登陆的时候发现过期了再删。</p>
</blockquote>
<blockquote>
<ul>
<li>session table 是存在数据库里， 还是存在In memory db 里面?<ul>
<li>都是可以的。不过一般都是存在 数据库里，否则memory数据丢了所有用户都会被logout 这个体验并不好。</li>
</ul>
</li>
</ul>
</blockquote>
<p>device token 也可紀錄在 session table, </p>
<blockquote>
<h5 id="单选题-Session-Table-适合存储在什么数据库里？"><a href="#单选题-Session-Table-适合存储在什么数据库里？" class="headerlink" title="[单选题]Session Table 适合存储在什么数据库里？"></a>[单选题]Session Table 适合存储在什么数据库里？</h5><p>A.Memcached21.64% 选择</p>
<p>B.MySQL22.46% 选择</p>
<p>C.Memcached + MySQL55.90% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTQxNzAwNjYyNTQzIiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjEwODgiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iNjQiIGhlaWdodD0iNjQiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxMiAwYTUxMiA1MTIgMCAxIDAgMCAxMDI0QTUxMiA1MTIgMCAwIDAgNTEyIDB6IG0xNjUuOTUyIDYzNy43NmwxNS4wNCAxNC45NzZhMjguNDE2IDI4LjQxNiAwIDEgMS00MC4yNTYgNDAuMjU2bC0xNC45NzYtMTUuMDRMNTA5LjUwNCA1NDkuNzYgMzcxLjIgNjg4YTI4LjQxNiAyOC40MTYgMCAxIDEtNDAuMjU2LTQwLjI1NmwxMzguMzA0LTEzOC4yNC0xMjMuMi0xMjMuMi0xNS4xMDQtMTUuMTA0YTI4LjU0NCAyOC41NDQgMCAwIDEgMC00MC4yNTYgMjguNTQ0IDI4LjU0NCAwIDAgMSA0MC4yNTYgMGwxNS4wNCAxNS4xMDRMNTA5LjQ0IDQ2OS4yNDhsMTQzLjIzMi0xNDMuMjk2YTI4LjQxNiAyOC40MTYgMCAxIDEgNDAuMjU2IDQwLjI1Nkw1NDkuNzYgNTA5LjUwNGwxMjguMTkyIDEyOC4yNTZ6IiBmaWxsPSIjRjY1RTVFIiBwLWlkPSIxMDg5Ij48L3BhdGg+PC9zdmc+" alt="img">答错了，您选择的答案是B</p>
<p><strong>正确答案:</strong>C</p>
</blockquote>
<p>如果自己建個網站，用戶不多，放在Memcache裡也Ok, 就算斷了，用戶就是再重登一次，不會怎樣，畢竟不是用戶信息的不能丟的。</p>
<p>大網站就最好撐久點，讓體驗好，訪問效率高</p>
<blockquote>
<ul>
<li>那个device id那一块，如何实现？有点模糊。<ul>
<li>就是在每个device第一次登录的时候给他分配一个id，然后把这个id放到该设备的cookie中，每次访问网站的时候都要带上这个id，这样根据id就能知道当前活动的是哪台设备了。</li>
</ul>
</li>
<li>db如何设计呢？如何判断这个session 是这个user，然后把之前的ipad的session logout，再让这个iphone的session建立？<ul>
<li>如果用NoSQL，那么表中的每一行可以是{user_id, session, expire_at，其中user_id是foreign key并且建立了index方便快速查找，session在生成的时候可以encode进去user_id的信息，方便直接从session中识别出当前用户。如果是key-value NoSQL，那就直接把上述结构改为user_id ==&gt; {session, expire_at}就行了。<br>当用户登录的时候直接生成一个新的session替换掉原来的。<br>当旧设备的session再次尝试请求数据的时候，先从session中decode出user_id，然后去查表，然后会发现表中的session跟当前的session不是同一个，那就强制logout。</li>
</ul>
</li>
<li>每个device 都会有一个 session key 吗？<ul>
<li>session key 和 device 不是绑定的关系。 session key 是记录某次登录后所形成的客户端与服务器端的保持通话的记录的 key。同一台机器上的不同的浏览器登录以后的 session key一般就是不同的。像 Google Chrome 这种支持多用户的浏览器，切换用户以后，就相当于切换浏览器一样，session 记录也是不同的。</li>
</ul>
</li>
<li>如果一个ipad来登陆来了，如何把iphone的session key给expire还是删除呢？如何判断，这2个device是一个user？如果问，如何回答。<ul>
<li>用同一个账号登录肯定就是同一个user。如果登录之后发现在session table中该账号有一个active的session，就可以把这个session 给expire了然后写一个新的进去。</li>
</ul>
</li>
<li>登陆之后，发现该账号已经有一个active user，就可以把这个session给expire了。这个“expire”操作具体是怎样进行的？<ul>
<li>这种情况可以直接删除该行记录。</li>
</ul>
</li>
<li>想问一下RESTful API里面比如POST一个新blog的请求会用session_key来验证user吗？<ul>
<li>也会的，只要是需要authorization的操作都需要验证当前用户的session.</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="Friendship-Storage-amp-Query"><a href="#Friendship-Storage-amp-Query" class="headerlink" title="Friendship Storage &amp; Query"></a>Friendship Storage &amp; Query</h2><p>單向：Twitter, Ins, Weibo</p>
<p>雙向：WeChat, FB, WhatsApp</p>
<blockquote>
<h5 id="单选题-为什么要区分-smaller-user-id-和-bigger-user-id？"><a href="#单选题-为什么要区分-smaller-user-id-和-bigger-user-id？" class="headerlink" title="[单选题]为什么要区分 smaller_user_id 和 bigger_user_id？"></a>[单选题]为什么要区分 smaller_user_id 和 bigger_user_id？</h5><p>A.否则查询 A 和 B 是否为好友的时候会变慢55.84% 选择</p>
<p>B.否则查询 A 的所有好友的时候会变慢32.22% 选择</p>
<p>C.猜不到11.94% 选择</p>
<p><img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI/PjwhRE9DVFlQRSBzdmcgUFVCTElDICItLy9XM0MvL0RURCBTVkcgMS4xLy9FTiIgImh0dHA6Ly93d3cudzMub3JnL0dyYXBoaWNzL1NWRy8xLjEvRFREL3N2ZzExLmR0ZCI+PHN2ZyB0PSIxNTM0MTgxMjgxODM5IiBjbGFzcz0iaWNvbiIgc3R5bGU9IiIgdmlld0JveD0iMCAwIDEwMjQgMTAyNCIgdmVyc2lvbj0iMS4xIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHAtaWQ9IjM3NjIiIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB3aWR0aD0iMzIiIGhlaWdodD0iMzIiPjxkZWZzPjxzdHlsZSB0eXBlPSJ0ZXh0L2NzcyI+PC9zdHlsZT48L2RlZnM+PHBhdGggZD0iTTUxOC4xMiA1MTYuMTZtLTQ5MCAwYTQ5MCA0OTAgMCAxIDAgOTgwIDAgNDkwIDQ5MCAwIDEgMC05ODAgMFoiIGZpbGw9IiM1NkI0MzIiIHAtaWQ9IjM3NjMiPjwvcGF0aD48cGF0aCBkPSJNMzkzLjIxMzYxOSA2NjQuMzM1NDk1bTI4LjI4NDI3MS0yOC4yODQyNzFsMjk2Ljk4NDg0OS0yOTYuOTg0ODQ4cTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBsMCAwcTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDJsLTI5Ni45ODQ4NDggMjk2Ljk4NDg0OHEtMjguMjg0MjcxIDI4LjI4NDI3MS01Ni41Njg1NDMgMGwwIDBxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDJaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY0Ij48L3BhdGg+PHBhdGggZD0iTTI4OS40Njk4NCA0NTIuODQ3ODgzbTI4LjI4NDI3MSAyOC4yODQyNzFsMTU1LjU2MzQ5MiAxNTUuNTYzNDkycTI4LjI4NDI3MSAyOC4yODQyNzEgMCA1Ni41Njg1NDNsMCAwcS0yOC4yODQyNzEgMjguMjg0MjcxLTU2LjU2ODU0MyAwbC0xNTUuNTYzNDkxLTE1NS41NjM0OTJxLTI4LjI4NDI3MS0yOC4yODQyNzEgMC01Ni41Njg1NDNsMCAwcTI4LjI4NDI3MS0yOC4yODQyNzEgNTYuNTY4NTQyIDBaIiBmaWxsPSIjRkZGRkZGIiBwLWlkPSIzNzY1Ij48L3BhdGg+PC9zdmc+" alt="img">答对了，您选择的答案是A</p>
<p><strong>正确答案:</strong>A</p>
<p><strong>解析:</strong></p>
<p>查询 A 的所有好友不会变慢，因为依然是 select * from friendship where user_id1=A or user_id2=A。</p>
</blockquote>
</div><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/50/">50</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>