<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="BigData_java/2021-1-3 Structured Streaming Continue"><meta name="keywords" content=""><meta name="author" content="Joe Huang"><meta name="copyright" content="Joe Huang"><title>BigData_java/2021-1-3 Structured Streaming Continue | Awaken Desparado</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://www.google-analytics.com"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-180692466-1', 'auto');
ga('send', 'pageview');</script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kafka-Consumer"><span class="toc-number">1.</span> <span class="toc-text">Kafka Consumer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Structure-streaming-Consumer"><span class="toc-number">2.</span> <span class="toc-text">Structure-streaming Consumer</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Twitter-Consumer-的問題們"><span class="toc-number"></span> <span class="toc-text">Twitter Consumer 的問題們</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Structured-Streaming-Cont"><span class="toc-number"></span> <span class="toc-text">Structured Streaming Cont</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#Watermark-API很好用-TODO"><span class="toc-number">0.0.0.1.</span> <span class="toc-text">Watermark API很好用, TODO!</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tweeter-Consumer"><span class="toc-number">1.</span> <span class="toc-text">Tweeter Consumer</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Joe Huang</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">363</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">25</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">60</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Awaken Desparado</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">BigData_java/2021-1-3 Structured Streaming Continue</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-01-03</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/BigData-java/">BigData_java</a></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><ul>
<li>Default: Micro-batch != Real-Time</li>
</ul>
<p>如何trigger-steaming job &lt;== depends, 我是可以define trigger模式的。</p>
<p>每次的batch特別小，這個就是micro-batch, 我想實時看到結果</p>
<ul>
<li>Fixed interval: still micro-batch, with user-defined interval, 如就是hdfs，我就配合30分鐘就好啦！<ul>
<li>是上個開始和下個開始的時間之間的差別<ul>
<li>要是上個特長呢？做完上個超時完後，再接著下個job</li>
<li>我設interval一定是知道freq 很低了，大概率，我做research的，就是知道10分鐘不會進來太多，就是我這個micro-batch能搞完的</li>
</ul>
</li>
<li>用的人可能會出錯…</li>
</ul>
</li>
<li>Once mode: 做一次而已，就是Batch Spark job, 做完就自己關掉了！</li>
</ul>
<ul>
<li>Continuous mode:  別用…Latency: 100ms，雖然不是真的實時，但已經滿足大多數的scenario；Flink可以真的實時。。。近乎0<ul>
<li>兩年前開始實驗此一持續性模式，但support 功能還很陽春，因為底層還是batch。不然就是全翻掉重做了。。</li>
</ul>
</li>
</ul>
<ul>
<li>WINDOW! <ul>
<li>要維護的不僅僅是當下的window,  還有之前的也要記得維護著；更像是一個Window History, 會去紀錄下來我上個interval、這個interval的WINDOWs各出現了什麼</li>
<li>變深的就是當前的data frame裡我更改的變化</li>
<li>在res table不斷地update 的；res 就是要統計、計算過的所有數據所生成的結果是什麼，而這結果都是存去disk上</li>
<li><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38aa4tyksj21em0p6td1.jpg" alt="image-20210315164555094" style="zoom:67%;" />



</li>
</ul>
</li>
</ul>
<ul>
<li><p>很久如兩天前的要維護嗎？</p>
<ul>
<li>要是用戶選了complete mode，他還有個下游，他的下游把最後return的complete數據再extract出來最新的 time window，我當然還是維護</li>
<li>但要是 append/update mode，就不需要維護了…</li>
</ul>
</li>
<li><p>不理想的狀態下，什麼情況我還要去維護已經處理過的window 呢？</p>
<ul>
<li>如需要排序這類的時候，這時候就要用到舊的data；<ul>
<li>同理我還是會有個window，只要去處理window裡的排序，對window外的就不去CARE, 但是↓<ul>
<li>很常見的一個現象跟問題就是希望Streaming app可以去解決的，這個問題就是</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>理想狀態定義：</p>
<ul>
<li>沒有 Late Data, 就是 8:10 event time的會如時過來<ul>
<li>但是！Spark 有 Fault Tolerance特性，要是有個executor掛了，要有另個executor快去頂上，把還沒搞完的data快速搞完</li>
<li>要是user要groupby time-window, 對structure-streaming而言，他就是要groupby, 他只關心這一個小時裡的topk的增量</li>
</ul>
</li>
<li>手機上被trigger了10/1，到kafka是10/30! Why? 有些地方網路差，過了半小時一小時後才出現；手機上操作很多今天蒐了地址，手機就發了很多個log去kfk，又不想打車了，就划掉了app，手機把payload cache著，半年後又想打車時，所有東西就重新發送。。就late了半年。。。<ul>
<li>但我又想保證正確性，意味，過去的state完全保存在memory當中，result table一直增長，但是distributed，就一直存在disk很ok., 但state很危險！＜＝＝ input table有個state, 紀當前增量到了哪個位置，記一個增量的卡點；window也有state也全是在memory裡．</li>
<li>要是所有的window都存在memory裡，就很容易OOM</li>
</ul>
</li>
<li><strong>Watermark 解決 OOM – late data</strong><ul>
<li>並保證最終結果的穩定</li>
<li>memory裡只保存 watermark所指定的時間範圍內的data</li>
</ul>
</li>
<li>就是只維護要的window，而不是維護所有的windows在memory裡</li>
</ul>
</li>
<li><p>最後寫去的，還是那三個地方</p>
<ul>
<li>kfk &lt;== update complete模式都很好，就是無限append的操作，就是無腦intsert, 無腦update</li>
<li>hdfs &lt;== 不建議；讀是沒問題的，但寫的話。。。就是複雜，它的data就是不能update的，只能replace就是重寫了，不然就是append當前data<ul>
<li>如我要write到當前的folder時，我不會update當前folder的文件所對應的data，而只會去無腦append；這樣我這樣用hdfs跟用kfk就沒有區別，因為我也沒有按col作更新，我就只是寫入一組data，然後我又來了新的data，就生出新的文件說什麼又更新了一下，hdfs它的small file會很多，name space就會out of quota, (HDFS 就是一個namespace 下就是20w個文件)；這時要是batch又沒有設置interval，這樣namespace很快就會用完。</li>
<li>就是要先想清楚用的場景、跟怎麼用</li>
<li>所以最好是「流對流」、「batch 對 batch」</li>
<li>Kfk retention時間 default是一週，很多公司會縮到２、３天。大多數都是 log</li>
<li>然後一般再按照data partition dump去HDFS上，HDFS上還可以設一個retention<ul>
<li>好處一：一次地dump，文件的大小、個數是由injection job決定的，就是很長時間內都不會有 small file問題, 如就每天200個文件</li>
<li>好處二: HDFS可以設retention；分析用的data，也不可能去存十年陳年老data。一般就是２年。所以就是可以 date partition + retention</li>
</ul>
</li>
</ul>
</li>
<li>console</li>
</ul>
</li>
</ul>
<ul>
<li>Input 不再是words, 而是我在模擬機器發送一個完整的log, 就是要有event time，是event time，不是land到kfk的時間；kfk會給land到kfk的時間。所以手機上發去的時間戳是payload過去的。</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38aa87dnvj20sy02kq2y.jpg" alt="image-20210316154559107" style="zoom:67%;" />





<h3 id="Kafka-Consumer"><a href="#Kafka-Consumer" class="headerlink" title="Kafka Consumer"></a>Kafka Consumer</h3><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1golui5db3fj21480am0z1.jpg" alt="image-20210316165252703"></p>
<p>那時用了很多kfk的API做了kfk的consumer</p>
<h3 id="Structure-streaming-Consumer"><a href="#Structure-streaming-Consumer" class="headerlink" title="Structure-streaming Consumer"></a>Structure-streaming Consumer</h3><p>取代了kfk consumer，這傢伙有自己的consumer，只是跟kfk自帶的api不同，</p>
<p>不再用之前說的kfk自帶的api, 如kfk consumer的pull , offset, commit這類的</p>
<p>structured-streaming有自己的流程</p>
<h2 id="Twitter-Consumer-的問題們"><a href="#Twitter-Consumer-的問題們" class="headerlink" title="Twitter Consumer 的問題們"></a>Twitter Consumer 的問題們</h2><ol>
<li>Itempotency<ul>
<li>kfk 以前可以保證exactly once，前提是得用kfk streaming，其他的第三方的application，都只能保證 <strong><em>at most</em> or <em>at least</em>　once</strong> , 就是無法保證 exactly once；<ul>
<li>所以，導致，要是我模型不能保證itempotency，我就設at most once，因為我不怕丟data丟失</li>
<li>我要是怕丟失，它重複讀了進來或retry 很多次，就… 一直加到爆</li>
</ul>
</li>
</ul>
</li>
<li>之前不想rely on 自己的commit offset，我自己做得過程出問題了，雖然它覺得已經commit成功了，我不想要自己的auto commit –&gt; 實時處理 process_id，手動的同步操作，只能blocking，等做完，才能commit 這個offset。</li>
</ol>
<p>我展示的還是batch process，只有我把它integrate到一個streaming app，才能保證我真的<strong>實時</strong></p>
<p>實時處理完的很可能有下游要用，所以餵給kfk，讓下游去聆聽我output sink丟去的kfk</p>
<p>實時蒐集完，然後展示</p>
<p>在selective時作bias而不是造假ＸＤ．．．　就是個流式分析！</p>
<p>分布式計算：都已經是分布式機器，每個機器有自己的executor，每個executor有自己的core, 每個core會執行一個task，只是它不是個multi-thread, 而是一個multi-process的操作；自己已經是個多線程操作，我沒必要再自己去開一堆。</p>
<h1 id="Structured-Streaming-Cont"><a href="#Structured-Streaming-Cont" class="headerlink" title="Structured Streaming Cont"></a>Structured Streaming Cont</h1><ul>
<li>streaming</li>
<li>fault tolerance</li>
</ul>
<p>Window: 就是個GroupBy操作；2mins的window, 30secs step</p>
<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gmaw01fw7mj30l607yn16.jpg" alt="image-20210103224247930" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38aacy3a7j213c0fawi9.jpg" alt="image-20210103224231269" style="zoom:50%;" />





<img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gmaw6jljiij31jo0tgk9z.jpg" alt="image-20210103224902437" style="zoom:50%;" />

<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38aaf8h03j21as0pu0v6.jpg" alt="image-20210103224919270" style="zoom:50%;" />



<h6 id="Watermark-API很好用-TODO"><a href="#Watermark-API很好用-TODO" class="headerlink" title="Watermark API很好用, TODO!"></a>Watermark API很好用, TODO!</h6><h3 id="Tweeter-Consumer"><a href="#Tweeter-Consumer" class="headerlink" title="Tweeter Consumer"></a>Tweeter Consumer</h3><ul>
<li>Itempotency!</li>
<li>紀錄 process_id, 不要 auto-commit；得要是個blocking thread；不可一邊commit，這要手動搞</li>
</ul>
<p>自己維護靜態的內容，然後自己groupby</p>
<ul>
<li>Create_time 就是event_time, 它和我去拉下來的trigger的時間可能差很大的</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h38aaiwwoxj20p00jodgt.jpg" alt="image-20210103231100449" style="zoom:50%;" />

<p>MCN公司建網紅，公司付錢用Ins, or Twitter, FB APIs把data service出去，第三方的software抓來做dashboard, 以達到data driven，知道話題，如健身的時間、quanrantine、workout … ==&gt; build homegym</p>
<p>網紅的流量，訂閱看我的流量，知道我的view；我知道我相對去年的view、like、如何</p>
<p>個人的影響就可以分析</p>
<p>我不需要生數據，也不用創新只要用現有數據去建model、精準metrics、推廣app!</p>
<p>Consumer: 從普通的java app變成了 structure-streaming app, 是比較強的framework</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Joe Huang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2021/01/03/BigData_java/2021-1-3%20Structured%20Streaming%20Continue/">http://yoursite.com/2021/01/03/BigData_java/2021-1-3%20Structured%20Streaming%20Continue/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/01/08/BigData_java/2021-1-8%20Watermark%20in%20Structure-streaming%20&amp;%20Kafka%20as%20output%20sink/"><i class="fa fa-chevron-left">  </i><span>BigData_java/2021-1-8 Watermark in Structure-streaming &amp; Kafka as output sink</span></a></div><div class="next-post pull-right"><a href="/2021/01/02/BigData_java/2021-1-2%20LAB4:%20/"><span>BigData_java/2021-1-2 LAB4: </span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2022 By Joe Huang</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>